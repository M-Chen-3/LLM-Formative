Skip to content
You said:
Please generate a Python function that does the following with only the code box and no example usage:
Extracts video ID from URL. 
ChatGPT said:
import re

def extract_video_id(url):
    """
    Extracts the video ID from a YouTube URL.

    Supports standard, shortened, and embedded YouTube URL formats.
    Returns the video ID as a string if found, else None.
    """
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11})',  # standard or embedded
        r'youtu\.be\/([0-9A-Za-z_-]{11})' # shortened
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str->list
    Convert XML to URL List.
    From Biligrab. 
ChatGPT said:
import xml.etree.ElementTree as ET

def xml_to_url_list(xml_str):
    """
    Converts an XML string from Biligrab format to a list of URLs.

    Args:
        xml_str (str): The XML content as a string.

    Returns:
        list: A list of extracted URL strings.
    """
    urls = []
    root = ET.fromstring(xml_str)
    for durl in root.findall('.//durl'):
        url_elem = durl.find('url')
        if url_elem is not None and url_elem.text:
            urls.append(url_elem.text.strip())
    return urls
You said:
Please generate a Python function that does the following with only the code box and no example usage:

From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js
    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal
    L110 
ChatGPT said:
import re

def extract_video_id(url):
    """
    Extracts the video ID from a given URL.

    Args:
        url (str): The URL from which to extract the video ID.

    Returns:
        str: The extracted video ID if found, otherwise None.
    """
    match = re.search(r'(?<=/videos/)(\d+)', url)
    if match:
        return match.group(1)
    return None

Sources
You said:
Please generate a Python function that does the following with only the code box and no example usage:

wrapper 
ChatGPT said:
def wrapper(func):
    """
    A simple decorator that wraps a function and logs its call.

    Args:
        func (callable): The function to wrap.

    Returns:
        callable: The wrapped function.
    """
    def wrapped(*args, **kwargs):
        print(f"Calling function '{func.__name__}' with args={args}, kwargs={kwargs}")
        result = func(*args, **kwargs)
        print(f"Function '{func.__name__}' returned {result}")
        return result
    return wrapped
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Downloads Dailymotion videos by URL. 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def download_dailymotion_video(url, output_filename):
    """
    Downloads a Dailymotion video by URL.

    Args:
        url (str): The Dailymotion video URL.
        output_filename (str): The name of the file to save the video as.
    """
    # Get the page HTML
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find the video source URL in the page
    video_tag = soup.find('meta', {'property': 'og:video:url'})
    if not video_tag or 'content' not in video_tag.attrs:
        raise ValueError("Video URL not found on the page.")

    video_url = video_tag['content']

    # Download the video content
    video_response = requests.get(video_url, stream=True)
    with open(output_filename, 'wb') as file:
        for chunk in video_response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

http://stackoverflow.com/a/30923963/2946714 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def get_stackoverflow_answer(url):
    """
    Fetches and returns the answer text from a StackOverflow answer URL.

    Args:
        url (str): The URL of the StackOverflow answer.

    Returns:
        str: The text content of the answer.
    """
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find the answer element
    answer = soup.find('div', {'class': 'answer'})
    if answer:
        # Get the answer text
        answer_text = answer.find('div', {'class': 's-prose'}).get_text()
        return answer_text.strip()
    return "Answer not found."
You said:
Please generate a Python function that does the following with only the code box and no example usage:

video page 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def fetch_video_page(url):
    """
    Fetches the video page content from the given URL.

    Args:
        url (str): The URL of the video page.

    Returns:
        str: The HTML content of the video page.
    """
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    else:
        raise Exception(f"Failed to retrieve the video page, status code: {response.status_code}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

course page 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def fetch_course_page(url):
    """
    Fetches the course page content from the given URL.

    Args:
        url (str): The URL of the course page.

    Returns:
        str: The HTML content of the course page.
    """
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    else:
        raise Exception(f"Failed to retrieve the course page, status code: {response.status_code}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Downloads a Sina video by its unique vid.
    http://video.sina.com.cn/ 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def download_sina_video(vid, output_filename):
    """
    Downloads a Sina video by its unique vid.

    Args:
        vid (str): The unique video ID (vid) from Sina video URL.
        output_filename (str): The name of the file to save the video as.
    """
    url = f"http://video.sina.com.cn/v/b/vid={vid}.html"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find the video source URL
    video_tag = soup.find('meta', {'property': 'og:video:url'})
    if not video_tag or 'content' not in video_tag.attrs:
        raise ValueError("Video URL not found on the page.")

    video_url = video_tag['content']

    # Download the video content
    video_response = requests.get(video_url, stream=True)
    with open(output_filename, 'wb') as file:
        for chunk in video_response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Downloads a Sina video by its unique vkey.
    http://video.sina.com/ 
ChatGPT said:
import requests

def download_sina_video_by_vkey(vkey, output_filename):
    """
    Downloads a Sina video by its unique vkey.

    Args:
        vkey (str): The unique video key (vkey) from the Sina video URL.
        output_filename (str): The name of the file to save the video as.
    """
    url = f"http://video.sina.com.cn/vkey/{vkey}.html"
    response = requests.get(url)
    if response.status_code != 200:
        raise ValueError("Failed to retrieve the video page.")

    # The video URL extraction method depends on how Sina stores the video URL in the page.
    # We'll assume the video URL can be found in a meta tag or another standard way.
    # For this example, we are directly retrieving a video URL from a typical page setup.
    video_url = extract_video_url_from_page(response.text)
    
    if not video_url:
        raise ValueError("Video URL not found on the page.")

    # Download the video content
    video_response = requests.get(video_url, stream=True)
    with open(output_filename, 'wb') as file:
        for chunk in video_response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)

def extract_video_url_from_page(page_content):
    """
    Extracts the video URL from the Sina video page content.
    
    Args:
        page_content (str): The HTML content of the Sina video page.
        
    Returns:
        str: The video URL if found, else None.
    """
    # This function should be customized to extract the video URL based on how Sina structures their page.
    # As an example, we would parse the page for a known tag or structure.
    # For now, we return None, assuming that the real logic will depend on the actual HTML structure.
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Downloads Sina videos by URL. 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def download_sina_video_by_url(url, output_filename):
    """
    Downloads a Sina video by its URL.

    Args:
        url (str): The URL of the Sina video.
        output_filename (str): The name of the file to save the video as.
    """
    response = requests.get(url)
    if response.status_code != 200:
        raise ValueError("Failed to retrieve the video page.")

    soup = BeautifulSoup(response.text, 'html.parser')

    # Find the video URL in the page (typically in a meta tag or embedded script)
    video_tag = soup.find('meta', {'property': 'og:video:url'})
    if not video_tag or 'content' not in video_tag.attrs:
        raise ValueError("Video URL not found on the page.")

    video_url = video_tag['content']

    # Download the video content
    video_response = requests.get(video_url, stream=True)
    with open(output_filename, 'wb') as file:
        for chunk in video_response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

wrapper 
ChatGPT said:
def wrapper(func):
    """
    A simple decorator that wraps a function to log its arguments, execution, and result.

    Args:
        func (callable): The function to be wrapped.

    Returns:
        callable: The wrapped function that logs execution details.
    """
    def wrapped(*args, **kwargs):
        print(f"Function '{func.__name__}' called with args={args}, kwargs={kwargs}")
        result = func(*args, **kwargs)
        print(f"Function '{func.__name__}' returned {result}")
        return result
    return wrapped
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get item_id 
ChatGPT said:
import re

def get_item_id(url):
    """
    Extracts the item ID from a given URL.

    Args:
        url (str): The URL from which to extract the item ID.

    Returns:
        str: The extracted item ID if found, otherwise None.
    """
    match = re.search(r'item/(\d+)', url)
    if match:
        return match.group(1)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Source: Android mobile 
ChatGPT said:
import platform

def is_android_mobile():
    """
    Checks if the current system is an Android mobile device.

    Returns:
        bool: True if the system is Android mobile, False otherwise.
    """
    return platform.system() == "Android" and platform.machine().startswith("arm")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

self, str->None
        
        Keyword arguments:
        self: self
        vid: The video ID for BokeCC cloud, something like
        FE3BB999594978049C33DC5901307461
        
        Calls the prepare() to download the video.
        
        If no title is provided, this method shall try to find a proper title
        with the information providin within the
        returned content of the API. 
ChatGPT said:
import requests

class VideoDownloader:
    def __init__(self, api_url):
        self.api_url = api_url

    def prepare(self, vid):
        """
        Prepares the video for downloading by fetching its data from the API.
        
        Args:
            vid (str): The video ID for BokeCC cloud.
        """
        response = requests.get(f"{self.api_url}/get_video_info?vid={vid}")
        if response.status_code == 200:
            video_data = response.json()
            title = video_data.get('title', None)
            if not title:
                title = self._extract_title_from_data(video_data)
            self.download_video(vid, title)
        else:
            raise Exception(f"Failed to fetch video info: {response.status_code}")

    def download_video(self, vid, title):
        """
        Downloads the video with the given video ID and title.

        Args:
            vid (str): The video ID.
            title (str): The video title.
        """
        video_url = f"{self.api_url}/download_video?vid={vid}"
        response = requests.get(video_url, stream=True)
        with open(f"{title}.mp4", 'wb') as file:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    file.write(chunk)

    def _extract_title_from_data(self, data):
        """
        Extracts a proper title from the API response data if no title is provided.
        
        Args:
            data (dict): The data returned from the API.
        
        Returns:
            str: A title extracted from the API data.
        """
        return data.get('video_name', 'Untitled')
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Extracts video ID from live.qq.com. 
ChatGPT said:
import re

def extract_video_id_from_qq(url):
    """
    Extracts the video ID from a live.qq.com URL.

    Args:
        url (str): The URL from which to extract the video ID.

    Returns:
        str: The extracted video ID if found, otherwise None.
    """
    match = re.search(r'live\.qq\.com/(\d+)', url)
    if match:
        return match.group(1)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Format text with color or other effects into ANSI escaped string. 
ChatGPT said:
def format_ansi_text(text, color=None, bold=False, underline=False):
    """
    Formats text with color or other effects into an ANSI escaped string.

    Args:
        text (str): The text to be formatted.
        color (str, optional): The color to apply. Options: 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'. Default is None.
        bold (bool, optional): Whether the text should be bold. Default is False.
        underline (bool, optional): Whether the text should be underlined. Default is False.

    Returns:
        str: The formatted ANSI string.
    """
    color_codes = {
        'black': '30', 'red': '31', 'green': '32', 'yellow': '33',
        'blue': '34', 'magenta': '35', 'cyan': '36', 'white': '37'
    }
    
    style_codes = []
    if color and color in color_codes:
        style_codes.append(color_codes[color])
    if bold:
        style_codes.append('1')  # Bold
    if underline:
        style_codes.append('4')  # Underline

    style_start = f"\033[{'m;'.join(style_codes)}m" if style_codes else ''
    style_end = "\033[0m"
    
    return f"{style_start}{text}{style_end}"
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Print a log message to standard error. 
ChatGPT said:
import sys

def print_log_message(message):
    """
    Prints a log message to standard error.

    Args:
        message (str): The log message to print.
    """
    print(message, file=sys.stderr)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Print an error log message. 
ChatGPT said:
import sys

def print_error_log(message):
    """
    Prints an error log message to standard error.

    Args:
        message (str): The error message to print.
    """
    print(f"ERROR: {message}", file=sys.stderr)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

What a Terrible Failure! 
ChatGPT said:
def what_a_terrible_failure():
    """
    Prints a message: 'What a Terrible Failure!' to standard error.
    """
    print("What a Terrible Failure!", file=sys.stderr)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Detect operating system. 
ChatGPT said:
import platform

def detect_operating_system():
    """
    Detects and returns the name of the operating system.

    Returns:
        str: The name of the operating system.
    """
    return platform.system()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Source: Android mobile 
ChatGPT said:
import platform

def is_android_mobile():
    """
    Checks if the current system is an Android mobile device.

    Returns:
        bool: True if the system is Android mobile, False otherwise.
    """
    return platform.system() == "Android"
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str->None 
ChatGPT said:
def string_to_none(input_str):
    """
    Accepts a string and returns None.

    Args:
        input_str (str): The input string.

    Returns:
        None
    """
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str/int->None 
ChatGPT said:
def process_input(input_data):
    """
    Accepts either a string or an integer and returns None.

    Args:
        input_data (str or int): The input data.

    Returns:
        None
    """
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

try:
        # normal Vimeo video
        html = get_content('https://vimeo.com/' + id)
        cfg_patt = r'clip_page_config\s*=\s*(\{.+?\});'
        cfg = json.loads(match1(html, cfg_patt))
        video_page = get_content(cfg['player']['config_url'], headers=fake_headers)
        title = cfg['clip']['title']
        info = loads(video_page)
    except:
        # embedded player - referer may be required
        if 'referer' in kwargs:
            fake_headers['Referer'] = kwargs['referer']

        video_page = get_content('http://player.vimeo.com/video/%s' % id, headers=fake_headers)
        title = r1(r'<title>([^<]+)</title>', video_page)
        info = loads(match1(video_page, r'var t=(\{.+?\});'))

    streams = info['request']['files']['progressive']
    streams = sorted(streams, key=lambda i: i['height'])
    url = streams[-1]['url']

    type, ext, size = url_info(url, faker=True)

    print_info(site_info, title, type, size)
    if not info_only:
        download_urls([url], title, ext, size, output_dir, merge=merge, faker=True) 
ChatGPT said:
import json

def download_vimeo_video(id, **kwargs):
    try:
        # normal Vimeo video
        html = get_content('https://vimeo.com/' + id)
        cfg_patt = r'clip_page_config\s*=\s*(\{.+?\});'
        cfg = json.loads(match1(html, cfg_patt))
        video_page = get_content(cfg['player']['config_url'], headers=fake_headers)
        title = cfg['clip']['title']
        info = loads(video_page)
    except:
        # embedded player - referer may be required
        if 'referer' in kwargs:
            fake_headers['Referer'] = kwargs['referer']

        video_page = get_content('http://player.vimeo.com/video/%s' % id, headers=fake_headers)
        title = r1(r'<title>([^<]+)</title>', video_page)
        info = loads(match1(video_page, r'var t=(\{.+?\});'))

    streams = info['request']['files']['progressive']
    streams = sorted(streams, key=lambda i: i['height'])
    url = streams[-1]['url']

    type, ext, size = url_info(url, faker=True)

    print_info(site_info, title, type, size)
    if not info_only:
        download_urls([url], title, ext, size, output_dir, merge=merge, faker=True)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str->dict
    Information for CKPlayer API content. 
ChatGPT said:
import json

def get_ckplayer_info(content_str):
    """
    Converts CKPlayer API content (in string format) into a dictionary.

    Args:
        content_str (str): The CKPlayer API content as a string.

    Returns:
        dict: The content as a dictionary.
    """
    try:
        return json.loads(content_str)
    except json.JSONDecodeError:
        return {}
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Splicing URLs according to video ID to get video details 
ChatGPT said:
def get_video_details_url(video_id):
    """
    Splices a base URL with the given video ID to get the video details URL.

    Args:
        video_id (str): The unique ID of the video.

    Returns:
        str: The complete URL to fetch video details.
    """
    base_url = "https://example.com/video/details/"
    return f"{base_url}{video_id}"
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Extracts video ID from URL. 
ChatGPT said:
import re

def extract_video_id(url):
    """
    Extracts the video ID from a URL.

    Args:
        url (str): The URL from which to extract the video ID.

    Returns:
        str: The extracted video ID if found, otherwise None.
    """
    match = re.search(r'\/(\d+)$', url)
    if match:
        return match.group(1)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str->list of str
        Give you the real URLs. 
ChatGPT said:
import re

def extract_urls_from_string(text):
    """
    Extracts all real URLs from a given string.

    Args:
        text (str): The input string containing URLs.

    Returns:
        list: A list of URLs extracted from the string.
    """
    url_pattern = r'https?://[^\s,"]+'
    return re.findall(url_pattern, text)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get (branch, commit) from HEAD of a git repo. 
ChatGPT said:
import subprocess

def get_git_head_info():
    """
    Gets the branch and commit from the HEAD of a git repository.

    Returns:
        tuple: A tuple containing the branch name and the commit hash.
    """
    try:
        branch = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).strip().decode()
        commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).strip().decode()
        return branch, commit
    except subprocess.CalledProcessError:
        return None, None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Converts a string to a valid filename. 
ChatGPT said:
import re
import os

def string_to_valid_filename(input_string):
    """
    Converts a string to a valid filename by removing invalid characters.

    Args:
        input_string (str): The input string to be converted.

    Returns:
        str: A valid filename.
    """
    valid_filename = re.sub(r'[<>:"/\\|?*\x00-\x1F]', '_', input_string)
    return valid_filename.strip()  # Remove any leading/trailing spaces
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get (width, height) of the current terminal. 
ChatGPT said:
import os

def get_terminal_size():
    """
    Gets the width and height of the current terminal.

    Returns:
        tuple: A tuple containing the width and height of the terminal.
    """
    try:
        columns, lines = os.get_terminal_size()
        return columns, lines
    except OSError:
        # Return default values in case of error (e.g., not running in a terminal)
        return 80, 24
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Downloads CBS videos by URL. 
ChatGPT said:
import requests
from bs4 import BeautifulSoup

def download_cbs_video(url, output_filename):
    """
    Downloads a CBS video by URL.

    Args:
        url (str): The URL of the CBS video.
        output_filename (str): The name of the file to save the video as.
    """
    response = requests.get(url)
    if response.status_code != 200:
        raise ValueError("Failed to retrieve the video page.")

    soup = BeautifulSoup(response.text, 'html.parser')

    # Find the video URL in the page (this depends on CBS video page structure)
    video_tag = soup.find('meta', {'property': 'og:video:url'})
    if not video_tag or 'content' not in video_tag.attrs:
        raise ValueError("Video URL not found on the page.")

    video_url = video_tag['content']

    # Download the video content
    video_response = requests.get(video_url, stream=True)
    with open(output_filename, 'wb') as file:
        for chunk in video_response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Override the original one
        Ugly ugly dirty hack 
ChatGPT said:
def override_original_function():
    """
    An example of overriding the original function with a 'hack'.
    This is a placeholder function to demonstrate the override concept.
    """
    print("Ugly, ugly, dirty hack applied!")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str, str, str, bool, bool ->None

    Download Acfun video by vid.

    Call Acfun API, decide which site to use, and pass the job to its
    extractor. 
ChatGPT said:
import requests

def download_acfun_video(vid, api_url, site_url, use_fallback, info_only):
    """
    Download Acfun video by vid, using the appropriate site and extractor.

    Args:
        vid (str): The video ID for the Acfun video.
        api_url (str): The Acfun API URL to retrieve video details.
        site_url (str): The base URL of the site for extracting the video.
        use_fallback (bool): Whether to use the fallback site if necessary.
        info_only (bool): Whether to only retrieve video information without downloading.
    """
    try:
        # Fetch video information from Acfun API
        api_response = requests.get(f"{api_url}/{vid}")
        api_response.raise_for_status()
        video_info = api_response.json()

        # Determine which site to use based on API response
        video_site = site_url if not use_fallback else video_info.get('fallback_url', site_url)
        
        # Retrieve video page and process extraction
        video_page = requests.get(f"{video_site}/video/{vid}")
        video_page.raise_for_status()

        # If only information is needed, return the data
        if info_only:
            print(f"Video Title: {video_info['title']}")
            print(f"Video URL: {video_info['video_url']}")
            return

        # Download the video
        video_url = video_info['video_url']
        video_response = requests.get(video_url, stream=True)
        with open(f"{video_info['title']}.mp4", 'wb') as file:
            for chunk in video_response.iter_content(chunk_size=1024):
                if chunk:
                    file.write(chunk)

    except requests.RequestException as e:
        print(f"Error fetching video: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Main entry point.
    you-get-dev 
ChatGPT said:
import sys
import subprocess

def main_entry_point():
    """
    Main entry point for running 'you-get-dev' tool.
    This function simulates invoking the you-get video downloader from the command line.
    """
    try:
        # Check if 'you-get' is installed
        subprocess.check_call(['you-get', '--help'])
        
        # Running the 'you-get-dev' command with arguments passed to the script
        args = sys.argv[1:] if len(sys.argv) > 1 else []
        subprocess.run(['you-get-dev'] + args, check=True)
        
    except subprocess.CalledProcessError as e:
        print(f"Error running 'you-get-dev': {e}")
    except FileNotFoundError:
        print("The 'you-get' tool is not installed. Please install it first.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str, str->True
    WARNING: NOT THE SAME PARMS AS OTHER FUNCTIONS!!!!!!
    You can basicly download anything with this function
    but better leave it alone with 
ChatGPT said:
def download_anything(url, filename):
    """
    Downloads anything from a given URL and saves it to a specified filename.
    WARNING: NOT THE SAME PARAMETERS AS OTHER FUNCTIONS!
    This function can be used to download any content, but use it cautiously.

    Args:
        url (str): The URL to download from.
        filename (str): The name of the file to save the content as.

    Returns:
        bool: True if the download is successful, False otherwise.
    """
    try:
        import requests
        response = requests.get(url, stream=True)
        response.raise_for_status()  # Raise an error for bad responses

        with open(filename, 'wb') as file:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    file.write(chunk)

        return True
    except Exception as e:
        print(f"Error downloading content: {e}")
        return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Scans through a string for substrings matched some patterns (first-subgroups only).

    Args:
        text: A string to be scanned.
        patterns: Arbitrary number of regex patterns.

    Returns:
        When only one pattern is given, returns a string (None if no match found).
        When more than one pattern are given, returns a list of strings ([] if no match found). 
ChatGPT said:
import re

def scan_patterns(text, *patterns):
    """
    Scans through a string for substrings matched by the given patterns (first-subgroups only).

    Args:
        text (str): The string to be scanned.
        patterns (str): One or more regex patterns.

    Returns:
        str or list: When only one pattern is given, returns a string (None if no match found).
                     When more than one pattern is given, returns a list of strings ([] if no match found).
    """
    results = []
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            results.append(match.group(1))
        else:
            results.append(None)

    if len(patterns) == 1:
        return results[0]
    return [result for result in results if result is not None]
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Scans through a string for substrings matched some patterns.

    Args:
        text: A string to be scanned.
        patterns: a list of regex pattern.

    Returns:
        a list if matched. empty if not. 
ChatGPT said:
import re

def scan_patterns(text, patterns):
    """
    Scans through a string for substrings matched by the given patterns.

    Args:
        text (str): The string to be scanned.
        patterns (list): A list of regex patterns.

    Returns:
        list: A list of matched substrings. An empty list if no matches are found.
    """
    matches = []
    for pattern in patterns:
        matches.extend(re.findall(pattern, text))
    return matches
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Parses the query string of a URL and returns the value of a parameter.

    Args:
        url: A URL.
        param: A string representing the name of the parameter.

    Returns:
        The value of the parameter. 
ChatGPT said:
from urllib.parse import urlparse, parse_qs

def get_query_param(url, param):
    """
    Parses the query string of a URL and returns the value of a parameter.

    Args:
        url (str): A URL.
        param (str): A string representing the name of the parameter.

    Returns:
        str: The value of the parameter, or None if the parameter is not found.
    """
    query = urlparse(url).query
    params = parse_qs(query)
    return params.get(param, [None])[0]
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Decompresses data for Content-Encoding: gzip. 
ChatGPT said:
import gzip
from io import BytesIO

def decompress_gzip_data(compressed_data):
    """
    Decompresses data for Content-Encoding: gzip.

    Args:
        compressed_data (bytes): The compressed data.

    Returns:
        bytes: The decompressed data.
    """
    with gzip.GzipFile(fileobj=BytesIO(compressed_data), mode='rb') as f:
        return f.read()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Decompresses data for Content-Encoding: deflate.
    (the zlib compression is used.) 
ChatGPT said:
import zlib

def decompress_deflate_data(compressed_data):
    """
    Decompresses data for Content-Encoding: deflate (using zlib compression).

    Args:
        compressed_data (bytes): The compressed data.

    Returns:
        bytes: The decompressed data.
    """
    return zlib.decompress(compressed_data)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets the content of a URL via sending a HTTP GET request.

    Args:
        url: A URL.
        headers: Request headers used by the client.
        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.

    Returns:
        The content as a string. 
ChatGPT said:
import requests

def get_url_content(url, headers=None, decoded=True):
    """
    Gets the content of a URL via sending an HTTP GET request.

    Args:
        url (str): A URL.
        headers (dict, optional): Request headers used by the client.
        decoded (bool, optional): Whether to decode the response body using UTF-8 or the charset specified in Content-Type.

    Returns:
        str: The content of the response as a string.
    """
    response = requests.get(url, headers=headers)
    response.raise_for_status()

    if decoded:
        return response.text
    return response.content.decode(response.encoding or 'utf-8')
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Post the content of a URL via sending a HTTP POST request.

    Args:
        url: A URL.
        headers: Request headers used by the client.
        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.

    Returns:
        The content as a string. 
ChatGPT said:
import requests

def post_url_content(url, headers=None, decoded=True, data=None):
    """
    Posts the content of a URL via sending an HTTP POST request.

    Args:
        url (str): A URL.
        headers (dict, optional): Request headers used by the client.
        decoded (bool, optional): Whether to decode the response body using UTF-8 or the charset specified in Content-Type.
        data (dict, optional): The data to be sent in the POST request.

    Returns:
        str: The content of the response as a string.
    """
    response = requests.post(url, headers=headers, data=data)
    response.raise_for_status()

    if decoded:
        return response.text
    return response.content.decode(response.encoding or 'utf-8')
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Parses host name and port number from a string. 
ChatGPT said:
import re

def parse_host_and_port(url):
    """
    Parses the host name and port number from a string.

    Args:
        url (str): The URL containing the host and port.

    Returns:
        tuple: A tuple containing the host name and port number.
               If no port is specified, the default port (None) is returned.
    """
    match = re.match(r'^(?:https?://)?([^:/]+)(?::(\d+))?$', url)
    if match:
        host = match.group(1)
        port = match.group(2) if match.group(2) else None
        return host, port
    return None, None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Overload default print function as py (<3.3) does not support 'flush' keyword.
    Although the function name can be same as print to get itself overloaded automatically,
    I'd rather leave it with a different name and only overload it when importing to make less confusion. 
ChatGPT said:
import sys

def print_flush(*args, **kwargs):
    """
    Overloads the default print function to support flushing the output,
    since Python < 3.3 doesn't support the 'flush' keyword in the print function.
    
    Args:
        *args: Arguments to be printed.
        **kwargs: Additional keyword arguments, including 'end' and 'file'.
    """
    if 'flush' in kwargs:
        del kwargs['flush']
    
    # Print the content
    print(*args, **kwargs)
    
    # Manually flush the output if necessary
    sys.stdout.flush()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

str->str 
ChatGPT said:
def identity_function(input_str):
    """
    Returns the input string as the output.

    Args:
        input_str (str): The input string.

    Returns:
        str: The same input string.
    """
    return input_str
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Source: Android mobile 
ChatGPT said:
def get_from_android_mobile(source):
    """
    Processes the given source as if it came from an Android mobile device.

    Args:
        source (str): The source data or URL from the Android mobile device.

    Returns:
        str: The processed content or data.
    """
    # Simulate processing the source data specific to Android mobile
    return f"Processed content from Android mobile source: {source}"
You said:
Please generate a Python function that does the following with only the code box and no example usage:

JSON, int, int, int->str
    
    Get a proper title with courseid+topicID+partID. 
ChatGPT said:
import json

def get_course_title(json_data, courseid, topicID, partID):
    """
    Get a proper title by combining courseid, topicID, and partID.

    Args:
        json_data (str): JSON string containing course details.
        courseid (int): The ID of the course.
        topicID (int): The ID of the topic within the course.
        partID (int): The ID of the part within the topic.

    Returns:
        str: A title formed by combining the courseid, topicID, and partID.
    """
    data = json.loads(json_data)
    
    course_title = data.get("courses", {}).get(str(courseid), {}).get("title", "Unknown Course")
    topic_title = data.get("topics", {}).get(str(topicID), {}).get("title", "Unknown Topic")
    part_title = data.get("parts", {}).get(str(partID), {}).get("title", "Unknown Part")
    
    return f"{course_title} - {topic_title} - {part_title}"
You said:
Please generate a Python function that does the following with only the code box and no example usage:

int->None
    
    Download a WHOLE course.
    Reuse the API call to save time. 
ChatGPT said:
import requests

def download_whole_course(course_id):
    """
    Downloads a whole course by using the course ID.
    Reuses API calls to save time by retrieving the course's contents and downloading each part.

    Args:
        course_id (int): The ID of the course to download.
    
    Returns:
        None
    """
    api_url = f"https://api.example.com/courses/{course_id}/content"
    response = requests.get(api_url)
    response.raise_for_status()

    course_data = response.json()
    for part in course_data['parts']:
        part_url = part['download_url']
        part_title = part['title']

        print(f"Downloading part: {part_title}")
        part_response = requests.get(part_url, stream=True)
        part_response.raise_for_status()

        with open(f"{part_title}.zip", 'wb') as file:
            for chunk in part_response.iter_content(chunk_size=1024):
                if chunk:
                    file.write(chunk)
    
    print(f"Course {course_id} download completed.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

int, int, int->None
    
    Download ONE PART of the course. 
ChatGPT said:
import requests

def download_course_part(course_id, topic_id, part_id):
    """
    Downloads a specific part of a course using course_id, topic_id, and part_id.

    Args:
        course_id (int): The ID of the course.
        topic_id (int): The ID of the topic.
        part_id (int): The ID of the part to download.
    
    Returns:
        None
    """
    api_url = f"https://api.example.com/courses/{course_id}/topics/{topic_id}/parts/{part_id}"
    response = requests.get(api_url)
    response.raise_for_status()

    part_data = response.json()
    part_url = part_data['download_url']
    part_title = part_data['title']

    print(f"Downloading part: {part_title}")
    part_response = requests.get(part_url, stream=True)
    part_response.raise_for_status()

    with open(f"{part_title}.zip", 'wb') as file:
        for chunk in part_response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
    
    print(f"Download of part {part_title} completed.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

int, int->list
        
        Get the height of the videos.
        
        Since brightcove is using 3 kinds of links: rtmp, http and https,
        we will be using the HTTPS one to make it secure.
        
        If somehow akamaihd.net is blocked by the Great Fucking Wall,
        change the "startswith https" to http. 
ChatGPT said:
import requests

def get_video_height(course_id, video_id):
    """
    Get the height of the videos using the given course_id and video_id.

    Args:
        course_id (int): The ID of the course.
        video_id (int): The ID of the video.

    Returns:
        list: A list of video heights (e.g., [720, 1080, 1440]) based on available streams.
    """
    api_url = f"https://api.brightcove.com/v1/videos/{video_id}"
    response = requests.get(api_url)
    response.raise_for_status()

    video_data = response.json()
    video_streams = video_data.get('streams', [])
    heights = []

    for stream in video_streams:
        url = stream.get('url')
        if url:
            # Check if the URL starts with 'https' for secure connection
            if url.startswith("https://akamaicdn.net"):
                url = url.replace("https://", "http://", 1)  # Change to HTTP if blocked
            if url.startswith("https://"):
                height = stream.get('height')
                if height:
                    heights.append(height)

    return heights
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Checks if a task is either queued or running in this executor

        :param task_instance: TaskInstance
        :return: True if the task is known to this executor 
ChatGPT said:
def is_task_queued_or_running(task_instance):
    """
    Checks if a task is either queued or running in this executor.

    Args:
        task_instance: TaskInstance

    Returns:
        bool: True if the task is known to this executor (queued or running).
    """
    # Assuming `task_instance.executor` holds the current executor state
    if task_instance.executor and task_instance.executor.task_queue_state.get(task_instance.task_id):
        return True
    return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns and flush the event buffer. In case dag_ids is specified
        it will only return and flush events for the given dag_ids. Otherwise
        it returns and flushes all

        :param dag_ids: to dag_ids to return events for, if None returns all
        :return: a dict of events  
ChatGPT said:
def fetch_connection_params(dag_ids=None):
    """
    Returns and flushes the event buffer. If dag_ids is specified, it will only return and flush events for the given dag_ids.
    Otherwise, it returns and flushes all events.

    Args:
        dag_ids (list, optional): List of dag_ids to return events for. If None, returns all events.

    Returns:
        dict: A dictionary of events.
    """
    event_buffer = get_event_buffer()
    
    if dag_ids:
        events = {dag_id: event_buffer.get(dag_id) for dag_id in dag_ids if dag_id in event_buffer}
    else:
        events = event_buffer
    
    flush_event_buffer(events)
    return events

You said:
Please generate a Python function that does the following with only the code box and no example usage:

one method to fetch connection params as a dict
        used in get_uri() and get_connection()

ChatGPT said:
def get_connection_params():
    """
    Fetches connection parameters as a dictionary used in `get_uri()` and `get_connection()`.

    Returns:
        dict: A dictionary of connection parameters.
    """
    connection_params = {
        'host': 'localhost',
        'port': 5432,
        'user': 'admin',
        'password': 'password',
        'database': 'example_db'
    }
    return connection_params
You said:
Please generate a Python function that does the following with only the code box and no example usage:

override DbApiHook get_uri method for get_sqlalchemy_engine() 
ChatGPT said:
from airflow.hooks.dbapi_hook import DbApiHook
from sqlalchemy import create_engine

class CustomDbApiHook(DbApiHook):
    """
    Custom hook that overrides the get_uri method to provide a SQLAlchemy engine.
    """

    def get_uri(self):
        """
        Override the get_uri method to generate a SQLAlchemy engine URI.

        Returns:
            str: The SQLAlchemy engine URI.
        """
        conn_params = self.get_connection(self.conn_id)
        return f"{conn_params.get('conn_type')}://{conn_params.get('user')}:{conn_params.get('password')}@{conn_params.get('host')}:{conn_params.get('port')}/{conn_params.get('schema')}"

    def get_sqlalchemy_engine(self):
        """
        Returns the SQLAlchemy engine based on the connection URI.

        Returns:
            sqlalchemy.engine.base.Engine: The SQLAlchemy engine.
        """
        engine_uri = self.get_uri()
        return create_engine(engine_uri)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a snowflake.connection object 

ChatGPT said:
import snowflake.connector

def get_snowflake_connection():
    """
    Returns a snowflake.connection object using connection parameters.

    Returns:
        snowflake.connector.connect: A Snowflake connection object.
    """
    connection_params = {
        'user': 'your_user',
        'password': 'your_password',
        'account': 'your_account',
        'warehouse': 'your_warehouse',
        'database': 'your_database',
        'schema': 'your_schema'
    }
    
    return snowflake.connector.connect(**connection_params)

You said:
Please generate a Python function that does the following with only the code box and no example usage:

returns aws_access_key_id, aws_secret_access_key
        from extra

        intended to be used by external import and export statements

ChatGPT said:

def get_aws_credentials_from_extra(extra):
    """
    Returns AWS access key and secret access key from the extra parameter.

    Args:
        extra (dict): A dictionary containing the extra configuration.

    Returns:
        tuple: A tuple containing AWS access key and secret access key.
    """
    aws_access_key_id = extra.get('aws_access_key_id')
    aws_secret_access_key = extra.get('aws_secret_access_key')
    
    return aws_access_key_id, aws_secret_access_key
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Fetches a field from extras, and returns it. This is some Airflow
        magic. The grpc hook type adds custom UI elements
        to the hook page, which allow admins to specify scopes, credential pem files, etc.
        They get formatted as shown below. 

ChatGPT said:
import psycopg2

def fetch_field_from_extras(extras, field):
    """
    Fetches a field from extras and returns it.

    Args:
        extras (dict): A dictionary containing extra configuration.
        field (str): The field name to fetch from the extras.

    Returns:
        str: The value of the specified field in extras.
    """
    return extras.get(field)

You said:
Please generate a Python function that does the following with only the code box and no example usage:

Executes SQL using psycopg2 copy_expert method.
        Necessary to execute COPY command without access to a superuser.

        Note: if this method is called with a "COPY FROM" statement and
        the specified input file does not exist, it creates an empty
        file and no data is loaded, but the operation succeeds.
        So if users want to be aware when the input file does not exist,
        they have to check its existence by themselves. 

ChatGPT said:

def execute_copy_sql(conn, sql, file_path):
    """
    Executes SQL using psycopg2 copy_expert method.
    This is necessary to execute the COPY command without access to a superuser.

    Args:
        conn (psycopg2.connection): The database connection.
        sql (str): The SQL COPY command to execute.
        file_path (str): The path to the input file for the COPY command.

    Returns:
        None
    """
    with conn.cursor() as cursor:
        # Check if the file exists
        try:
            with open(file_path, 'r') as f:
                cursor.copy_expert(sql, f)
        except FileNotFoundError:
            # If file doesn't exist, create an empty file and proceed with the COPY command
            with open(file_path, 'w') as f:
                pass  # Create an empty file
            cursor.copy_expert(sql, open(file_path, 'r'))
        conn.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Loads a tab-delimited file into a database table 
ChatGPT said:
import psycopg2
import csv

def load_tab_delimited_file_to_db(conn, table_name, file_path):
    """
    Loads a tab-delimited file into a database table.

    Args:
        conn (psycopg2.connection): The database connection.
        table_name (str): The name of the target table.
        file_path (str): The path to the tab-delimited file.

    Returns:
        None
    """
    with conn.cursor() as cursor:
        with open(file_path, 'r') as f:
            # Using the COPY command to load the tab-delimited file into the table
            cursor.copy_expert(f"COPY {table_name} FROM stdin WITH DELIMITER E'\t' CSV HEADER", f)
        conn.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Dumps a database table into a tab-delimited file 
ChatGPT said:
import psycopg2

def dump_db_table_to_tab_delimited_file(conn, table_name, file_path):
    """
    Dumps a database table into a tab-delimited file.

    Args:
        conn (psycopg2.connection): The database connection.
        table_name (str): The name of the source table.
        file_path (str): The path to save the tab-delimited file.

    Returns:
        None
    """
    with conn.cursor() as cursor:
        with open(file_path, 'w') as f:
            # Using the COPY command to dump the table content into the tab-delimited file
            cursor.copy_expert(f"COPY {table_name} TO stdout WITH DELIMITER E'\t' CSV HEADER", f)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Uploads the file to Google cloud storage 
ChatGPT said:
from google.cloud import storage

def upload_file_to_gcs(bucket_name, file_path, destination_blob_name):
    """
    Uploads a file to Google Cloud Storage.

    Args:
        bucket_name (str): The name of the GCS bucket.
        file_path (str): The local file path to the file to be uploaded.
        destination_blob_name (str): The destination name for the file in GCS.

    Returns:
        None
    """
    # Initialize a storage client
    client = storage.Client()

    # Get the GCS bucket
    bucket = client.bucket(bucket_name)

    # Create a blob (file object) in the GCS bucket
    blob = bucket.blob(destination_blob_name)

    # Upload the file to GCS
    blob.upload_from_filename(file_path)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets the max partition for a table.

    :param schema: The hive schema the table lives in
    :type schema: str
    :param table: The hive table you are interested in, supports the dot
        notation as in "my_database.my_table", if a dot is found,
        the schema param is disregarded
    :type table: str
    :param metastore_conn_id: The hive connection you are interested in.
        If your default is set you don't need to use this parameter.
    :type metastore_conn_id: str
    :param filter_map: partition_key:partition_value map used for partition filtering,
                       e.g. {'key1': 'value1', 'key2': 'value2'}.
                       Only partitions matching all partition_key:partition_value
                       pairs will be considered as candidates of max partition.
    :type filter_map: map
    :param field: the field to get the max value from. If there's only
        one partition field, this will be inferred
    :type field: str

    >>> max_partition('airflow.static_babynames_partitioned')
    '2015-01-01' 
ChatGPT said:
from pyhive import hive

def get_max_partition(schema, table, metastore_conn_id=None, filter_map=None, field=None):
    """
    Gets the max partition for a table in Hive.

    Args:
        schema (str): The hive schema the table lives in.
        table (str): The hive table you are interested in (supports dot notation).
        metastore_conn_id (str, optional): The Hive connection you are interested in.
        filter_map (dict, optional): A map of partition_key:partition_value pairs for filtering.
        field (str, optional): The field to get the max value from.

    Returns:
        str: The max partition value.
    """
    if '.' in table:
        schema, table = table.split('.', 1)
    
    # Establish Hive connection
    conn = hive.Connection(host='your_hive_host', port=10000, username='your_username')

    # Construct the partition filter clause
    partition_filter = ""
    if filter_map:
        partition_filter = " AND ".join([f"{k}='{v}'" for k, v in filter_map.items()])

    # Construct the SQL query to fetch the max partition
    query = f"SHOW PARTITIONS {schema}.{table}"
    if partition_filter:
        query += f" WHERE {partition_filter}"

    cursor = conn.cursor()
    cursor.execute(query)

    # Fetch partitions and find the max partition based on the field
    partitions = cursor.fetchall()
    if field:
        # Assuming partitions are in a format like 'field=value' and selecting the max field
        partition_values = [p.split('=')[1] for p in partitions if p]
        return max(partition_values)
    else:
        # If no field is provided, assume the partitions are the value itself
        return max(partitions)[0]
You said:
Please generate a Python function that does the following with only the code box and no example usage:

This function finds the date in a list closest to the target date.
    An optional parameter can be given to get the closest before or after.

    :param target_dt: The target date
    :type target_dt: datetime.date
    :param date_list: The list of dates to search
    :type date_list: list[datetime.date]
    :param before_target: closest before or after the target
    :type before_target: bool or None
    :returns: The closest date
    :rtype: datetime.date or None

ChatGPT said:
from datetime import datetime
from pyhive import hive

def find_closest_date(target_dt, date_list, before_target=None):
    """
    This function finds the date in a list closest to the target date.
    An optional parameter can be given to get the closest before or after.

    Args:
        target_dt (datetime.date): The target date.
        date_list (list[datetime.date]): The list of dates to search.
        before_target (bool or None): Whether to find the closest date before (True), after (False), or either side (None).

    Returns:
        datetime.date or None: The closest date, or None if no match is found.
    """
    if before_target is not None:
        if before_target:
            # Find the closest date before the target
            closest_date = max([d for d in date_list if d < target_dt], default=None)
        else:
            # Find the closest date after the target
            closest_date = min([d for d in date_list if d > target_dt], default=None)
    else:
        # Find the closest date in general (either before or after)
        closest_date = min(date_list, key=lambda d: abs(d - target_dt), default=None)
    
    return closest_date

You said:
Please generate a Python function that does the following with only the code box and no example usage:

This function finds the date in a list closest to the target date.
    An optional parameter can be given to get the closest before or after.

    :param table: A hive table name
    :type table: str
    :param ds: A datestamp ``%Y-%m-%d`` e.g. ``yyyy-mm-dd``
    :type ds: list[datetime.date]
    :param before: closest before (True), after (False) or either side of ds
    :type before: bool or None
    :returns: The closest date
    :rtype: str or None

    >>> tbl = 'airflow.static_babynames_partitioned'
    >>> closest_ds_partition(tbl, '2015-01-02')
    '2015-01-01' 

ChatGPT said:
def closest_ds_partition(table, ds, before=None):
    """
    This function finds the date in a Hive partition list closest to the target date.

    Args:
        table (str): The Hive table name.
        ds (str): A datestamp in the format "%Y-%m-%d" (e.g., "yyyy-mm-dd").
        before (bool or None): Whether to get the closest partition before (True), after (False), or either side (None).

    Returns:
        str or None: The closest partition date or None.
    """
    # Convert ds to datetime.date
    target_dt = datetime.strptime(ds, '%Y-%m-%d').date()

    # Establish Hive connection
    conn = hive.Connection(host='your_hive_host', port=10000, username='your_username')

    # Query the partitions from Hive
    query = f"SHOW PARTITIONS {table}"
    cursor = conn.cursor()
    cursor.execute(query)

    # Fetch the partitions and convert them to datetime.date
    partitions = [datetime.strptime(p[0].split('=')[1], '%Y-%m-%d').date() for p in cursor.fetchall()]

    # Find the closest partition
    closest_partition = find_closest_date(target_dt, partitions, before_target=before)

    # Return the closest partition date as a string
    return closest_partition.strftime('%Y-%m-%d') if closest_partition else None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a mysql connection object 
ChatGPT said:
import mysql.connector

def get_mysql_connection(host, user, password, database):
    """
    Returns a MySQL connection object.

    Args:
        host (str): The host of the MySQL server.
        user (str): The MySQL username.
        password (str): The password for the MySQL user.
        database (str): The database to connect to.

    Returns:
        mysql.connector.connection.MySQLConnection: The MySQL connection object.
    """
    connection = mysql.connector.connect(
        host=host,
        user=user,
        password=password,
        database=database
    )
    return connection
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Loads a tab-delimited file into a database table 
ChatGPT said:
import pandas as pd
import mysql.connector

def load_tab_delimited_to_db(file_path, host, user, password, database, table_name):
    """
    Loads a tab-delimited file into a MySQL database table.

    Args:
        file_path (str): The path to the tab-delimited file.
        host (str): The host of the MySQL server.
        user (str): The MySQL username.
        password (str): The password for the MySQL user.
        database (str): The database to connect to.
        table_name (str): The name of the table to load data into.

    Returns:
        None
    """
    # Read the tab-delimited file into a DataFrame
    df = pd.read_csv(file_path, delimiter='\t')

    # Establish MySQL connection
    connection = mysql.connector.connect(
        host=host,
        user=user,
        password=password,
        database=database
    )

    # Create a cursor object
    cursor = connection.cursor()

    # Create the INSERT query template
    columns = ', '.join(df.columns)
    values_placeholder = ', '.join(['%s'] * len(df.columns))
    insert_query = f"INSERT INTO {table_name} ({columns}) VALUES ({values_placeholder})"

    # Insert the data into the table
    for row in df.itertuples(index=False, name=None):
        cursor.execute(insert_query, row)

    # Commit the transaction and close the connection
    connection.commit()
    cursor.close()
    connection.close()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Checks whether new objects have been uploaded and the inactivity_period
        has passed and updates the state of the sensor accordingly.

        :param current_num_objects: number of objects in bucket during last poke.
        :type current_num_objects: int 
ChatGPT said:
import time

def check_new_objects_and_inactivity_period(current_num_objects, last_poke_time, inactivity_period, current_num_objects_now):
    """
    Checks whether new objects have been uploaded and the inactivity period has passed,
    and updates the state of the sensor accordingly.

    Args:
        current_num_objects (int): Number of objects in the bucket during last poke.
        last_poke_time (float): The time of the last poke (in seconds since the epoch).
        inactivity_period (int): The inactivity period threshold in seconds.
        current_num_objects_now (int): The current number of objects in the bucket.

    Returns:
        str: The state of the sensor ('updated', 'no_update', 'inactivity_timeout').
    """
    current_time = time.time()
    
    # Check if inactivity period has passed
    if current_time - last_poke_time > inactivity_period:
        return 'inactivity_timeout'
    
    # Check if new objects have been uploaded
    if current_num_objects_now > current_num_objects:
        return 'updated'
    
    return 'no_update'

You said:
Please generate a Python function that does the following with only the code box and no example usage:

Helps debug deadlocks by printing stacktraces when this gets a SIGQUIT
    e.g. kill -s QUIT <PID> or CTRL+\ 
ChatGPT said:
import faulthandler
import signal
import sys

def enable_deadlock_debugging():
    """Enables printing of stack traces for all threads on SIGQUIT (e.g., CTRL+\ or kill -s QUIT <PID>)."""
    faulthandler.register(signal.SIGQUIT, file=sys.__stderr__, all_threads=True)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a dag run for the specified dag
    :param args:
    :return: 
ChatGPT said:
from airflow.models import DagBag, DagRun
from airflow.utils.state import State
from airflow.utils import timezone
from airflow.utils.session import provide_session

@provide_session
def trigger_dag_run(args, session=None):
    """
    Creates a DAG run for the specified DAG.
    :param args: Arguments containing 'dag_id' and optional 'run_id' and 'conf'
    :param session: SQLAlchemy session (provided automatically)
    :return: The created DagRun object
    """
    dag_id = args.get('dag_id')
    run_id = args.get('run_id', f"manual__{timezone.utcnow().isoformat()}")
    conf = args.get('conf', {})

    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)

    if not dag:
        raise ValueError(f"DAG with dag_id '{dag_id}' not found")

    dag_run = dag.create_dagrun(
        run_id=run_id,
        execution_date=timezone.utcnow(),
        start_date=timezone.utcnow(),
        state=State.RUNNING,
        conf=conf,
        external_trigger=True,
        session=session
    )
    return dag_run
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes all DB records related to the specified dag
    :param args:
    :return: 
ChatGPT said:
from airflow.models import DagModel, DagRun, TaskInstance, Log
from airflow.utils.session import provide_session

@provide_session
def delete_dag_records(args, session=None):
    """
    Deletes all DB records related to the specified DAG.
    :param args: Arguments containing 'dag_id'
    :param session: SQLAlchemy session (provided automatically)
    :return: None
    """
    dag_id = args.get('dag_id')
    if not dag_id:
        raise ValueError("Missing 'dag_id' in args")

    session.query(TaskInstance).filter(TaskInstance.dag_id == dag_id).delete(synchronize_session=False)
    session.query(DagRun).filter(DagRun.dag_id == dag_id).delete(synchronize_session=False)
    session.query(Log).filter(Log.dag_id == dag_id).delete(synchronize_session=False)
    session.query(DagModel).filter(DagModel.dag_id == dag_id).delete(synchronize_session=False)
    session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the unmet dependencies for a task instance from the perspective of the
    scheduler (i.e. why a task instance doesn't get scheduled and then queued by the
    scheduler, and then run by an executor).
    >>> airflow task_failed_deps tutorial sleep 2015-01-01
    Task instance dependencies not met:
    Dagrun Running: Task instance's dagrun did not exist: Unknown reason
    Trigger Rule: Task's trigger rule 'all_success' requires all upstream tasks
    to have succeeded, but found 1 non-success(es). 
ChatGPT said:
from airflow.models import DagBag, TaskInstance
from airflow.utils.session import provide_session
from airflow.utils.state import State
from airflow.utils.dates import parse_execution_date
from airflow.utils.db import create_session

@provide_session
def get_unmet_task_instance_dependencies(args, session=None):
    """
    Returns the unmet dependencies for a task instance from the scheduler's perspective.
    :param args: Arguments containing 'dag_id', 'task_id', and 'execution_date'
    :param session: SQLAlchemy session (provided automatically)
    :return: List of unmet dependency reasons as strings
    """
    dag_id = args.get('dag_id')
    task_id = args.get('task_id')
    execution_date = args.get('execution_date')

    if not all([dag_id, task_id, execution_date]):
        raise ValueError("Missing one or more required args: 'dag_id', 'task_id', 'execution_date'")

    execution_date = parse_execution_date(execution_date)
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)

    if not dag:
        raise ValueError(f"DAG with dag_id '{dag_id}' not found")

    task = dag.get_task(task_id)
    ti = TaskInstance(task=task, execution_date=execution_date)
    ti.refresh_from_db(session=session)

    unmet_deps = []
    for dep_status in ti.get_failed_dep_statuses(session=session, dep_context=None):
        unmet_deps.append(f"{dep_status.dep_name}: {dep_status.reason}")

    return unmet_deps
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the state of a TaskInstance at the command line.
    >>> airflow task_state tutorial sleep 2015-01-01
    success 
ChatGPT said:
from airflow.models import DagBag, TaskInstance
from airflow.utils.session import provide_session
from airflow.utils.dates import parse_execution_date

@provide_session
def get_task_instance_state(args, session=None):
    """
    Returns the state of a TaskInstance at the command line.
    :param args: Arguments containing 'dag_id', 'task_id', and 'execution_date'
    :param session: SQLAlchemy session (provided automatically)
    :return: TaskInstance state as a string
    """
    dag_id = args.get('dag_id')
    task_id = args.get('task_id')
    execution_date = args.get('execution_date')

    if not all([dag_id, task_id, execution_date]):
        raise ValueError("Missing one or more required args: 'dag_id', 'task_id', 'execution_date'")

    execution_date = parse_execution_date(execution_date)
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)

    if not dag:
        raise ValueError(f"DAG with dag_id '{dag_id}' not found")

    task = dag.get_task(task_id)
    ti = TaskInstance(task=task, execution_date=execution_date)
    ti.refresh_from_db(session=session)

    return ti.state
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the state of a DagRun at the command line.
    >>> airflow dag_state tutorial 2015-01-01T00:00:00.000000
    running 
ChatGPT said:
from airflow.models import DagBag, DagRun
from airflow.utils.session import provide_session
from airflow.utils.dates import parse_execution_date

@provide_session
def get_dagrun_state(args, session=None):
    """
    Returns the state of a DagRun at the command line.
    :param args: Arguments containing 'dag_id' and 'execution_date'
    :param session: SQLAlchemy session (provided automatically)
    :return: DagRun state as a string
    """
    dag_id = args.get('dag_id')
    execution_date = args.get('execution_date')

    if not all([dag_id, execution_date]):
        raise ValueError("Missing required args: 'dag_id', 'execution_date'")

    execution_date = parse_execution_date(execution_date)
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)

    if not dag:
        raise ValueError(f"DAG with dag_id '{dag_id}' not found")

    dagrun = session.query(DagRun).filter(
        DagRun.dag_id == dag_id,
        DagRun.execution_date == execution_date
    ).first()

    if not dagrun:
        raise ValueError(f"No DagRun found for dag_id '{dag_id}' at execution_date '{execution_date}'")

    return dagrun.state
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the next execution datetime of a DAG at the command line.
    >>> airflow next_execution tutorial
    2018-08-31 10:38:00 
ChatGPT said:
from airflow.models import DagBag, DagModel
from airflow.utils.session import provide_session
from airflow.utils.types import DagRunType
from airflow.utils.state import State
from airflow.utils import timezone

@provide_session
def get_next_execution(args, session=None):
    """
    Returns the next execution datetime of a DAG at the command line.
    :param args: Arguments containing 'dag_id'
    :param session: SQLAlchemy session (provided automatically)
    :return: Next execution datetime as a string
    """
    dag_id = args.get('dag_id')

    if not dag_id:
        raise ValueError("Missing required arg: 'dag_id'")

    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)

    if not dag:
        raise ValueError(f"DAG with dag_id '{dag_id}' not found")

    dag_model = session.query(DagModel).filter(DagModel.dag_id == dag_id).first()
    last_exec_date = dag_model.get_last_dagrun(session=session).execution_date if dag_model and dag_model.get_last_dagrun(session=session) else None

    next_exec_date = dag.following_schedule(last_exec_date) if last_exec_date else dag.start_date

    return str(next_exec_date)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Runs forever, monitoring the child processes of @gunicorn_master_proc and
    restarting workers occasionally.
    Each iteration of the loop traverses one edge of this state transition
    diagram, where each state (node) represents
    [ num_ready_workers_running / num_workers_running ]. We expect most time to
    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.
    The horizontal transition at ? happens after the new worker parses all the
    dags (so it could take a while!)
       V 
    [n / n] TTIN> [ [n, n+bs) / n + bs ]  ?> [n + bs / n + bs] TTOU
       ^                          ^
       
             v
        [ [0, n) / n ] < start
    We change the number of workers by sending TTIN and TTOU to the gunicorn
    master process, which increases and decreases the number of child workers
    respectively. Gunicorn guarantees that on TTOU workers are terminated
    gracefully and that the oldest worker is terminated.
ChatGPT said:
import os
import signal
import time
import logging
from typing import Optional

logger = logging.getLogger(__name__)

def monitor_gunicorn_workers(gunicorn_master_proc: int, num_workers_expected: int, bs: int, refresh_interval: int = 30):
    """
    Runs forever, monitoring the child processes of `gunicorn_master_proc` and
    restarting workers occasionally using TTIN/TTOU signals to scale.
    
    :param gunicorn_master_proc: PID of the gunicorn master process
    :param num_workers_expected: Desired steady-state number of gunicorn workers
    :param bs: webserver.worker_refresh_batch_size
    :param refresh_interval: Time in seconds between checks
    """
    def get_worker_pids(master_pid: int) -> set:
        try:
            with open(f"/proc/{master_pid}/task/{master_pid}/children") as f:
                return set(map(int, f.read().strip().split()))
        except Exception:
            return set()

    current_workers = get_worker_pids(gunicorn_master_proc)
    while True:
        time.sleep(refresh_interval)
        ready_workers = get_worker_pids(gunicorn_master_proc)

        logger.debug(f"Current workers: {len(current_workers)}, Ready workers: {len(ready_workers)}")

        if len(ready_workers) == num_workers_expected:
            logger.info(f"[{len(ready_workers)} / {len(current_workers)}] - Normal state")
            # Trigger worker refresh
            logger.info("Refreshing workers...")
            for _ in range(bs):
                os.kill(gunicorn_master_proc, signal.SIGTTIN)  # Add workers
            time.sleep(refresh_interval * 2)  # Wait for new workers to start and parse DAGs
            for _ in range(bs):
                os.kill(gunicorn_master_proc, signal.SIGTTOU)  # Remove old workers

        current_workers = ready_workers
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieves connection to Cloud Translate

        :return: Google Cloud Translate client object.
        :rtype: Client 
ChatGPT said:
from google.cloud import translate_v2 as translate

def get_translate_client():
    """
    Retrieves connection to Cloud Translate.
    :return: Google Cloud Translate client object.
    :rtype: translate.Client
    """
    return translate.Client()

You said:
Please generate a Python function that does the following with only the code box and no example usage:

Translate a string or list of strings.

        See https://cloud.google.com/translate/docs/translating-text

        :type values: str or list
        :param values: String or list of strings to translate.

        :type target_language: str
        :param target_language: The language to translate results into. This
                                is required by the API and defaults to
                                the target language of the current instance.

        :type format_: str
        :param format_: (Optional) One of `text or html, to specify
                        if the input text is plain text or HTML.

        :type source_language: str or None
        :param source_language: (Optional) The language of the text to
                                be translated.

        :type model: str or None
        :param model: (Optional) The model used to translate the text, such
                      as `'base' or 'nmt'.

        :rtype: str or list
        :returns: A list of dictionaries for each queried value. Each
                  dictionary typically contains three keys (though not
                  all will be present in all cases)

                  * `detectedSourceLanguage: The detected language (as an
                    ISO 639-1 language code) of the text.
                  * `translatedText: The translation of the text into the
                    target language.
                  * `input: The corresponding input value.
                  * `model: The model used to translate the text.

                  If only a single value is passed, then only a single
                  dictionary will be returned.
        :raises: :class:~exceptions.ValueError if the number of
                 values and translations differ. 

ChatGPT said:

def translate_text(values, target_language, format_='text', source_language=None, model=None):
    """
    Translate a string or list of strings using Google Cloud Translate.

    :type values: str or list
    :param values: String or list of strings to translate.

    :type target_language: str
    :param target_language: The language to translate results into.

    :type format_: str
    :param format_: (Optional) One of ``text`` or ``html``.

    :type source_language: str or None
    :param source_language: (Optional) The language of the text to be translated.

    :type model: str or None
    :param model: (Optional) The model used to translate the text, such as ``'base'`` or ``'nmt'``.

    :rtype: str or list
    :returns: A dictionary or list of dictionaries with translation results.
    :raises: ValueError if the number of values and translations differ.
    """
    client = get_translate_client()

    is_single = False
    if isinstance(values, str):
        values = [values]
        is_single = True

    result = client.translate(
        values,
        target_language=target_language,
        format_=format_,
        source_language=source_language,
        model=model
    )

    if not isinstance(result, list):
        result = [result]

    if len(result) != len(values):
        raise ValueError("Mismatch between number of inputs and translations.")

    return result[0] if is_single else result
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Execute the bash command in a temporary directory
        which will be cleaned afterwards 
ChatGPT said:
import tempfile
import subprocess
import shutil
import os

def execute_bash_in_temp_dir(command):
    """
    Execute the bash command in a temporary directory which will be cleaned afterwards.
    
    :param command: The bash command to execute.
    :type command: str
    :return: CompletedProcess instance containing the execution result.
    :rtype: subprocess.CompletedProcess
    """
    temp_dir = tempfile.mkdtemp()
    try:
        result = subprocess.run(
            command,
            shell=True,
            cwd=temp_dir,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        return result
    finally:
        shutil.rmtree(temp_dir)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieves a resource containing information about a Cloud SQL instance.

        :param instance: Database instance ID. This does not include the project ID.
        :type instance: str
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: A Cloud SQL instance resource.
        :rtype: dict 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def get_cloud_sql_instance(instance, project_id=None):
    """
    Retrieves a resource containing information about a Cloud SQL instance.

    :param instance: Database instance ID. This does not include the project ID.
    :type instance: str
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: A Cloud SQL instance resource.
    :rtype: dict
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlInstancesServiceClient()
    instance_name = f'projects/{project_id}/instances/{instance}'

    instance_resource = client.get(project=project_id, instance=instance)
    return instance_resource.to_dict()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new Cloud SQL instance.

        :param body: Body required by the Cloud SQL insert API, as described in
            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.
        :type body: dict
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def create_cloud_sql_instance(body, project_id=None):
    """
    Creates a new Cloud SQL instance.

    :param body: Body required by the Cloud SQL insert API, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.
    :type body: dict
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlInstancesServiceClient()
    parent = f'projects/{project_id}'

    request = sql_v1beta4.InsertInstanceRequest(
        project=project_id,
        body=body
    )
    
    client.insert(request=request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Updates settings of a Cloud SQL instance.

        Caution: This is not a partial update, so you must include values for
        all the settings that you want to retain.

        :param body: Body required by the Cloud SQL patch API, as described in
            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.
        :type body: dict
        :param instance: Cloud SQL instance ID. This does not include the project ID.
        :type instance: str
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def update_cloud_sql_instance(body, instance, project_id=None):
    """
    Updates settings of a Cloud SQL instance.
    
    Caution: This is not a partial update, so you must include values for
    all the settings that you want to retain.

    :param body: Body required by the Cloud SQL patch API, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.
    :type body: dict
    :param instance: Cloud SQL instance ID. This does not include the project ID.
    :type instance: str
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlInstancesServiceClient()
    instance_name = f'projects/{project_id}/instances/{instance}'

    request = sql_v1beta4.PatchInstanceRequest(
        project=project_id,
        instance=instance,
        body=body
    )

    client.patch(request=request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes a Cloud SQL instance.

        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :param instance: Cloud SQL instance ID. This does not include the project ID.
        :type instance: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def delete_cloud_sql_instance(project_id=None, instance=None):
    """
    Deletes a Cloud SQL instance.

    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :param instance: Cloud SQL instance ID. This does not include the project ID.
    :type instance: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlInstancesServiceClient()
    instance_name = f'projects/{project_id}/instances/{instance}'

    client.delete(project=project_id, instance=instance)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieves a database resource from a Cloud SQL instance.

        :param instance: Database instance ID. This does not include the project ID.
        :type instance: str
        :param database: Name of the database in the instance.
        :type database: str
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: A Cloud SQL database resource, as described in
            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.
        :rtype: dict 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def get_cloud_sql_database(instance, database, project_id=None):
    """
    Retrieves a database resource from a Cloud SQL instance.

    :param instance: Database instance ID. This does not include the project ID.
    :type instance: str
    :param database: Name of the database in the instance.
    :type database: str
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: A Cloud SQL database resource, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.
    :rtype: dict
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlDatabasesServiceClient()
    database_name = f'projects/{project_id}/instances/{instance}/databases/{database}'

    database_resource = client.get(project=project_id, instance=instance, database=database)
    return database_resource.to_dict()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new database inside a Cloud SQL instance.

        :param instance: Database instance ID. This does not include the project ID.
        :type instance: str
        :param body: The request body, as described in
            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.
        :type body: dict
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def create_cloud_sql_database(instance, body, project_id=None):
    """
    Creates a new database inside a Cloud SQL instance.

    :param instance: Database instance ID. This does not include the project ID.
    :type instance: str
    :param body: The request body, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.
    :type body: dict
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlDatabasesServiceClient()
    database_name = f'projects/{project_id}/instances/{instance}/databases'

    request = sql_v1beta4.InsertDatabaseRequest(
        project=project_id,
        instance=instance,
        body=body
    )

    client.insert(request=request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Updates a database resource inside a Cloud SQL instance.

        This method supports patch semantics.
        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.

        :param instance: Database instance ID. This does not include the project ID.
        :type instance: str
        :param database: Name of the database to be updated in the instance.
        :type database: str
        :param body: The request body, as described in
            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.
        :type body: dict
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def update_cloud_sql_database(instance, database, body, project_id=None):
    """
    Updates a database resource inside a Cloud SQL instance.
    
    This method supports patch semantics.
    See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.

    :param instance: Database instance ID. This does not include the project ID.
    :type instance: str
    :param database: Name of the database to be updated in the instance.
    :type database: str
    :param body: The request body, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.
    :type body: dict
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlDatabasesServiceClient()
    database_name = f'projects/{project_id}/instances/{instance}/databases/{database}'

    request = sql_v1beta4.PatchDatabaseRequest(
        project=project_id,
        instance=instance,
        database=database,
        body=body
    )

    client.patch(request=request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes a database from a Cloud SQL instance.

        :param instance: Database instance ID. This does not include the project ID.
        :type instance: str
        :param database: Name of the database to be deleted in the instance.
        :type database: str
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def delete_cloud_sql_database(instance, database, project_id=None):
    """
    Deletes a database from a Cloud SQL instance.

    :param instance: Database instance ID. This does not include the project ID.
    :type instance: str
    :param database: Name of the database to be deleted in the instance.
    :type database: str
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlDatabasesServiceClient()
    database_name = f'projects/{project_id}/instances/{instance}/databases/{database}'

    client.delete(project=project_id, instance=instance, database=database)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump
        or CSV file.

        :param instance: Database instance ID of the Cloud SQL instance. This does not include the
            project ID.
        :type instance: str
        :param body: The request body, as described in
            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body
        :type body: dict
        :param project_id: Project ID of the project that contains the instance. If set
            to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default

def export_cloud_sql_data(instance, body, project_id=None):
    """
    Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump
    or CSV file.

    :param instance: Database instance ID of the Cloud SQL instance. This does not include the
        project ID.
    :type instance: str
    :param body: The request body, as described in
        https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body
    :type body: dict
    :param project_id: Project ID of the project that contains the instance. If set
        to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlInstancesServiceClient()
    request = sql_v1beta4.ExportRequest(
        project=project_id,
        instance=instance,
        body=body
    )

    client.export(request=request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Waits for the named operation to complete - checks status of the
        asynchronous call.

        :param project_id: Project ID of the project that contains the instance.
        :type project_id: str
        :param operation_name: Name of the operation.
        :type operation_name: str
        :return: None 
ChatGPT said:
from google.cloud import sql_v1beta4
from google.auth import default
import time

def wait_for_operation(project_id, operation_name):
    """
    Waits for the named operation to complete - checks status of the
    asynchronous call.

    :param project_id: Project ID of the project that contains the instance.
    :type project_id: str
    :param operation_name: Name of the operation.
    :type operation_name: str
    :return: None
    """
    if project_id is None:
        credentials, project_id = default()

    client = sql_v1beta4.SqlOperationsServiceClient()
    operation_name = f'projects/{project_id}/operations/{operation_name}'

    while True:
        operation = client.get(name=operation_name)
        if operation.status == 'DONE':
            if 'error' in operation:
                raise Exception(f"Operation failed: {operation.error}")
            break
        time.sleep(5)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Starts Cloud SQL Proxy.

        You have to remember to stop the proxy if you started it! 
ChatGPT said:
import subprocess
import os
import signal

def start_cloud_sql_proxy(project_id, instance, proxy_port=3306):
    """
    Starts Cloud SQL Proxy.

    You have to remember to stop the proxy if you started it!

    :param project_id: Project ID of the project containing the Cloud SQL instance.
    :type project_id: str
    :param instance: Database instance ID of the Cloud SQL instance.
    :type instance: str
    :param proxy_port: Port on which to run the proxy (default is 3306).
    :type proxy_port: int
    :return: Process object representing the running Cloud SQL Proxy.
    """
    command = [
        "cloud_sql_proxy",
        "-dir", "/cloudsql",  # default socket directory for connections
        "-project", project_id,
        "-instance", instance,
        "-port", str(proxy_port)
    ]

    # Start the proxy as a subprocess
    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    
    return process
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Stops running proxy.

        You should stop the proxy after you stop using it. 
ChatGPT said:
import os
import signal

def stop_cloud_sql_proxy(process):
    """
    Stops running Cloud SQL Proxy.

    You should stop the proxy after you stop using it.

    :param process: The process object representing the running Cloud SQL Proxy.
    :type process: subprocess.Popen
    :return: None
    """
    if process:
        process.send_signal(signal.SIGINT)
        process.wait()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns version of the Cloud SQL Proxy. 
ChatGPT said:
import subprocess

def get_cloud_sql_proxy_version():
    """
    Returns version of the Cloud SQL Proxy.

    :return: Version string of the Cloud SQL Proxy.
    :rtype: str
    """
    command = ["cloud_sql_proxy", "--version"]
    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if result.returncode == 0:
        return result.stdout.strip()
    else:
        raise Exception(f"Failed to retrieve Cloud SQL Proxy version: {result.stderr.strip()}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Create connection in the Connection table, according to whether it uses
        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.

        :param session: Session of the SQL Alchemy ORM (automatically generated with
                        decorator). 
ChatGPT said:
import random
import string
from sqlalchemy import Table, Column, Integer, String, MetaData
from sqlalchemy.orm import sessionmaker

def create_connection(session, use_proxy=False, use_tcp=False, use_unix_socket=False, use_ssl=False):
    """
    Create connection in the Connection table, according to whether it uses
    proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.

    :param session: Session of the SQL Alchemy ORM (automatically generated with decorator).
    :type session: sqlalchemy.orm.Session
    :param use_proxy: Flag to specify if proxy is used.
    :type use_proxy: bool
    :param use_tcp: Flag to specify if TCP is used.
    :type use_tcp: bool
    :param use_unix_socket: Flag to specify if UNIX socket is used.
    :type use_unix_socket: bool
    :param use_ssl: Flag to specify if SSL is used.
    :type use_ssl: bool
    :return: None
    """
    connection_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
    connection_type = []

    if use_proxy:
        connection_type.append('proxy')
    if use_tcp:
        connection_type.append('tcp')
    if use_unix_socket:
        connection_type.append('unix_socket')
    if use_ssl:
        connection_type.append('ssl')

    connection_type_str = ', '.join(connection_type)

    # Assuming there's a Connection table with the following structure
    metadata = MetaData()
    connection_table = Table(
        'connections', metadata,
        Column('connection_id', String(8), primary_key=True),
        Column('connection_type', String(255)),
    )

    # Insert new connection entry
    session.execute(connection_table.insert().values(connection_id=connection_id, connection_type=connection_type_str))
    session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieves the dynamically created connection from the Connection table.

        :param session: Session of the SQL Alchemy ORM (automatically generated with
                        decorator). 
ChatGPT said:
from sqlalchemy.orm import sessionmaker

def get_connection(session, connection_id):
    """
    Retrieves the dynamically created connection from the Connection table.

    :param session: Session of the SQL Alchemy ORM (automatically generated with decorator).
    :type session: sqlalchemy.orm.Session
    :param connection_id: ID of the connection to retrieve.
    :type connection_id: str
    :return: Connection details or None if not found.
    :rtype: dict or None
    """
    # Assuming there's a Connection table with the following structure
    metadata = MetaData()
    connection_table = Table(
        'connections', metadata,
        Column('connection_id', String(8), primary_key=True),
        Column('connection_type', String(255)),
    )

    # Query to retrieve the connection
    connection = session.execute(connection_table.select().where(connection_table.c.connection_id == connection_id)).fetchone()

    if connection:
        return dict(connection)
    else:
        return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Delete the dynamically created connection from the Connection table.

        :param session: Session of the SQL Alchemy ORM (automatically generated with
                        decorator). 
ChatGPT said:
from sqlalchemy.orm import sessionmaker

def delete_connection(session, connection_id):
    """
    Deletes the dynamically created connection from the Connection table.

    :param session: Session of the SQL Alchemy ORM (automatically generated with decorator).
    :type session: sqlalchemy.orm.Session
    :param connection_id: ID of the connection to delete.
    :type connection_id: str
    :return: None
    """
    # Assuming there's a Connection table with the following structure
    metadata = MetaData()
    connection_table = Table(
        'connections', metadata,
        Column('connection_id', String(8), primary_key=True),
        Column('connection_type', String(255)),
    )

    # Query to delete the connection
    session.execute(connection_table.delete().where(connection_table.c.connection_id == connection_id))
    session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieve Cloud SQL Proxy runner. It is used to manage the proxy
        lifecycle per task.

        :return: The Cloud SQL Proxy runner.
        :rtype: CloudSqlProxyRunner 
ChatGPT said:
class CloudSqlProxyRunner:
    def __init__(self, project_id, instance, proxy_port=3306):
        self.project_id = project_id
        self.instance = instance
        self.proxy_port = proxy_port
        self.process = None

    def start_proxy(self):
        # Logic to start Cloud SQL Proxy using subprocess
        import subprocess
        command = [
            "cloud_sql_proxy",
            "-dir", "/cloudsql",
            "-project", self.project_id,
            "-instance", self.instance,
            "-port", str(self.proxy_port)
        ]
        self.process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return self.process

    def stop_proxy(self):
        # Logic to stop Cloud SQL Proxy
        import signal
        if self.process:
            self.process.send_signal(signal.SIGINT)
            self.process.wait()

def get_cloud_sql_proxy_runner(project_id, instance, proxy_port=3306):
    """
    Retrieve Cloud SQL Proxy runner. It is used to manage the proxy
    lifecycle per task.

    :return: The Cloud SQL Proxy runner.
    :rtype: CloudSqlProxyRunner
    """
    return CloudSqlProxyRunner(project_id, instance, proxy_port)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieve database hook. This is the actual Postgres or MySQL database hook
        that uses proxy or connects directly to the Google Cloud SQL database. 
ChatGPT said:
from airflow.hooks.dbapi_hook import DbApiHook
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.providers.mysql.hooks.mysql import MySqlHook

def get_database_hook(database_type, use_proxy=False, project_id=None, instance=None, **kwargs):
    """
    Retrieve database hook. This is the actual Postgres or MySQL database hook
    that uses proxy or connects directly to the Google Cloud SQL database.

    :param database_type: The type of the database, either 'postgres' or 'mysql'.
    :type database_type: str
    :param use_proxy: Flag indicating whether to use proxy (default: False).
    :type use_proxy: bool
    :param project_id: Project ID for the Google Cloud project.
    :type project_id: str
    :param instance: Database instance ID.
    :type instance: str
    :param kwargs: Additional keyword arguments for connection.
    :return: PostgresHook or MySqlHook based on the database type.
    :rtype: DbApiHook
    """
    if database_type == 'postgres':
        if use_proxy:
            # Implement logic to configure the Postgres hook to use Cloud SQL Proxy
            pass
        return PostgresHook(postgres_conn_id=kwargs.get('postgres_conn_id'))

    elif database_type == 'mysql':
        if use_proxy:
            # Implement logic to configure the MySQL hook to use Cloud SQL Proxy
            pass
        return MySqlHook(mysql_conn_id=kwargs.get('mysql_conn_id'))

    else:
        raise ValueError("Unsupported database type. Supported types are 'postgres' and 'mysql'.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Clean up database hook after it was used. 
ChatGPT said:
def cleanup_database_hook(hook):
    """
    Clean up database hook after it was used.

    :param hook: The database hook to be cleaned up (PostgresHook, MySqlHook, etc.).
    :type hook: DbApiHook
    :return: None
    """
    if hook:
        try:
            hook.get_conn().close()  # Close the connection
        except Exception as e:
            raise Exception(f"Error cleaning up the database hook: {str(e)}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Reserve free TCP port to be used by Cloud SQL Proxy 
ChatGPT said:
import socket

def reserve_free_tcp_port():
    """
    Reserve a free TCP port to be used by Cloud SQL Proxy.

    :return: The reserved TCP port.
    :rtype: int
    """
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind(('localhost', 0))  # Bind to an available port
        port = s.getsockname()[1]
        return port
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Replaces invalid MLEngine job_id characters with '_'.

    This also adds a leading 'z' in case job_id starts with an invalid
    character.

    Args:
        job_id: A job_id str that may have invalid characters.

    Returns:
        A valid job_id representation. 
ChatGPT said:
import re

def replace_invalid_job_id_characters(job_id):
    """
    Replaces invalid MLEngine job_id characters with '_'.
    This also adds a leading 'z' in case job_id starts with an invalid character.

    Args:
        job_id: A job_id str that may have invalid characters.

    Returns:
        A valid job_id representation.
    """
    # Replace invalid characters with '_'
    valid_job_id = re.sub(r'[^a-zA-Z0-9_-]', '_', job_id)

    # Ensure the job_id doesn't start with an invalid character
    if not valid_job_id[0].isalpha():
        valid_job_id = 'z' + valid_job_id

    return valid_job_id
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Extract error code from ftp exception 
ChatGPT said:
import ftplib

def extract_error_code_from_ftp_exception(exception):
    """
    Extracts the error code from an FTP exception.

    Args:
        exception: The FTP exception to extract the error code from.

    Returns:
        str: The FTP error code.
    """
    if isinstance(exception, ftplib.FTPException):
        return str(exception.args[0])  # FTPException stores the error code in the first argument
    else:
        raise ValueError("The exception is not of type ftplib.FTPException")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Integrate plugins to the context 
ChatGPT said:
def integrate_plugins_to_context(context, plugins):
    """
    Integrates the given plugins into the provided context.

    Args:
        context: The context to which plugins should be integrated.
        plugins: A list of plugins to integrate.

    Returns:
        The updated context with the integrated plugins.
    """
    for plugin in plugins:
        if hasattr(plugin, 'initialize'):
            plugin.initialize(context)
        context[plugin.__class__.__name__] = plugin
    return context
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Remove any existing DAG runs for the perf test DAGs. 
ChatGPT said:
from airflow.models import DagRun
from airflow.utils.dates import days_ago

def remove_existing_dag_runs(dag_id):
    """
    Remove any existing DAG runs for the specified DAG.

    Args:
        dag_id: The ID of the DAG whose runs need to be removed.
    """
    DagRun.query.filter(DagRun.dag_id == dag_id, DagRun.execution_date <= days_ago(1)).delete()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Remove any existing task instances for the perf test DAGs. 
ChatGPT said:
from airflow.models import TaskInstance
from airflow.utils.dates import days_ago

def remove_existing_task_instances(dag_id):
    """
    Remove any existing task instances for the specified DAG.

    Args:
        dag_id: The ID of the DAG whose task instances need to be removed.
    """
    TaskInstance.query.filter(TaskInstance.dag_id == dag_id, TaskInstance.execution_date <= days_ago(1)).delete()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Toggle the pause state of the DAGs in the test. 
ChatGPT said:
from airflow.models import DagBag

def toggle_dag_pause_state(dag_id, pause=True):
    """
    Toggle the pause state of the specified DAG.

    Args:
        dag_id: The ID of the DAG to be paused or unpaused.
        pause: A boolean indicating whether to pause (True) or unpause (False) the DAG.
    """
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)
    
    if dag:
        dag.set_is_paused(pause)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Print operational metrics for the scheduler test. 
ChatGPT said:
from airflow.stats import Stats

def print_scheduler_operational_metrics():
    """
    Print operational metrics for the scheduler test.
    """
    metrics = Stats.get_scheduler_metrics()
    for metric, value in metrics.items():
        print(f"{metric}: {value}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Override the scheduler heartbeat to determine when the test is complete 
ChatGPT said:
from airflow.utils.dates import days_ago
from airflow.models import DagRun
from airflow.utils.session import create_session

def override_scheduler_heartbeat(dag_id, completion_callback):
    """
    Override the scheduler heartbeat to determine when the test is complete.
    
    Args:
        dag_id: The ID of the DAG to monitor.
        completion_callback: The callback function to call when the test is complete.
    """
    with create_session() as session:
        while True:
            # Check if the latest dagrun for the specified DAG is completed
            dagrun = session.query(DagRun).filter(DagRun.dag_id == dag_id).order_by(DagRun.execution_date.desc()).first()
            if dagrun and dagrun.state == 'success':
                completion_callback(dagrun)
                break
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Invoke Lambda Function 
ChatGPT said:
import boto3

def invoke_lambda_function(function_name, payload):
    """
    Invoke an AWS Lambda function with the provided payload.

    Args:
        function_name: The name of the Lambda function to invoke.
        payload: The payload to send to the Lambda function.

    Returns:
        The response from the Lambda function invocation.
    """
    client = boto3.client('lambda')
    response = client.invoke(
        FunctionName=function_name,
        InvocationType='RequestResponse',
        Payload=payload
    )
    return response['Payload'].read().decode('utf-8')
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return the task object identified by the given dag_id and task_id. 
ChatGPT said:
from airflow.models import DagBag

def get_task_by_dag_and_task_id(dag_id, task_id):
    """
    Return the task object identified by the given dag_id and task_id.

    Args:
        dag_id: The ID of the DAG.
        task_id: The ID of the task.

    Returns:
        The task object if found, otherwise None.
    """
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)
    if dag:
        return dag.get_task(task_id)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates Operators needed for model evaluation and returns.

    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by
    calling MLEngineBatchPredictionOperator, then summarize and validate
    the result via Cloud Dataflow using DataFlowPythonOperator.

    For details and pricing about Batch prediction, please refer to the website
    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict
    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/

    It returns three chained operators for prediction, summary, and validation,
    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,
    respectively.
    (<prefix> should contain only alphanumeric characters or hyphen.)

    The upstream and downstream can be set accordingly like:
      pred, _, val = create_evaluate_ops(...)
      pred.set_upstream(upstream_op)
      ...
      downstream_op.set_upstream(val)

    Callers will provide two python callables, metric_fn and validate_fn, in
    order to customize the evaluation behavior as they wish.
    - metric_fn receives a dictionary per instance derived from json in the
      batch prediction result. The keys might vary depending on the model.
      It should return a tuple of metrics.
    - validation_fn receives a dictionary of the averaged metrics that metric_fn
      generated over all instances.
      The key/value of the dictionary matches to what's given by
      metric_fn_and_keys arg.
      The dictionary contains an additional metric, 'count' to represent the
      total number of instances received for evaluation.
      The function would raise an exception to mark the task as failed, in a
      case the validation result is not okay to proceed (i.e. to set the trained
      version as default).

    Typical examples are like this:

    def get_metric_fn_and_keys():
        import math  # imports should be outside of the metric_fn below.
        def error_and_squared_error(inst):
            label = float(inst['input_label'])
            classes = float(inst['classes'])  # 0 or 1
            err = abs(classes-label)
            squared_err = math.pow(classes-label, 2)
            return (err, squared_err)  # returns a tuple.
        return error_and_squared_error, ['err', 'mse']  # key order must match.

    def validate_err_and_count(summary):
        if summary['err'] > 0.2:
            raise ValueError('Too high err>0.2; summary=%s' % summary)
        if summary['mse'] > 0.05:
            raise ValueError('Too high mse>0.05; summary=%s' % summary)
        if summary['count'] < 1000:
            raise ValueError('Too few instances<1000; summary=%s' % summary)
        return summary

    For the details on the other BatchPrediction-related arguments (project_id,
    job_id, region, data_format, input_paths, prediction_path, model_uri),
    please refer to MLEngineBatchPredictionOperator too.

    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and
        hyphen are allowed (no underscores), since this will be used as dataflow
        job name, which doesn't allow other characters.
    :type task_prefix: str

    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'
    :type data_format: str

    :param input_paths: a list of input paths to be sent to BatchPrediction.
    :type input_paths: list[str]

    :param prediction_path: GCS path to put the prediction results in.
    :type prediction_path: str

    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:
        - metric_fn is a function that accepts a dictionary (for an instance),
          and returns a tuple of metric(s) that it calculates.
        - metric_keys is a list of strings to denote the key of each metric.
    :type metric_fn_and_keys: tuple of a function and a list[str]

    :param validate_fn: a function to validate whether the averaged metric(s) is
        good enough to push the model.
    :type validate_fn: function

    :param batch_prediction_job_id: the id to use for the Cloud ML Batch
        prediction job. Passed directly to the MLEngineBatchPredictionOperator as
        the job_id argument.
    :type batch_prediction_job_id: str

    :param project_id: the Google Cloud Platform project id in which to execute
        Cloud ML Batch Prediction and Dataflow jobs. If None, then the dag's
        default_args['project_id'] will be used.
    :type project_id: str

    :param region: the Google Cloud Platform region in which to execute Cloud ML
        Batch Prediction and Dataflow jobs. If None, then the dag's
        default_args['region'] will be used.
    :type region: str

    :param dataflow_options: options to run Dataflow jobs. If None, then the
        dag's default_args['dataflow_default_options'] will be used.
    :type dataflow_options: dictionary

    :param model_uri: GCS path of the model exported by Tensorflow using
        tensorflow.estimator.export_savedmodel(). It cannot be used with
        model_name or version_name below. See MLEngineBatchPredictionOperator for
        more detail.
    :type model_uri: str

    :param model_name: Used to indicate a model to use for prediction. Can be
        used in combination with version_name, but cannot be used together with
        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,
        then the dag's default_args['model_name'] will be used.
    :type model_name: str

    :param version_name: Used to indicate a model version to use for prediction,
        in combination with model_name. Cannot be used together with model_uri.
        See MLEngineBatchPredictionOperator for more detail. If None, then the
        dag's default_args['version_name'] will be used.
    :type version_name: str

    :param dag: The DAG to use for all Operators.
    :type dag: airflow.models.DAG

    :returns: a tuple of three operators, (prediction, summary, validation)
    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,
                  PythonOperator) 
ChatGPT said:
from airflow.providers.google.cloud.operators.mlengine import MLEngineBatchPredictionOperator
from airflow.providers.google.cloud.operators.dataflow import DataFlowPythonOperator
from airflow.operators.python import PythonOperator

def create_evaluate_ops(
    task_prefix,
    data_format,
    input_paths,
    prediction_path,
    metric_fn_and_keys,
    validate_fn,
    batch_prediction_job_id,
    project_id,
    region,
    dataflow_options,
    model_uri,
    model_name,
    version_name,
    dag
):
    # Step 1: Set up the Cloud ML Engine Batch Prediction Operator
    prediction_op = MLEngineBatchPredictionOperator(
        task_id=f"{task_prefix}-prediction",
        job_id=batch_prediction_job_id,
        project_id=project_id,
        region=region,
        data_format=data_format,
        input_paths=input_paths,
        output_path=prediction_path,
        model_uri=model_uri,
        model_name=model_name,
        version_name=version_name,
        dataflow_default_options=dataflow_options,
        dag=dag,
    )

    # Step 2: Set up the Cloud Dataflow Summary Operator
    def summarize_metrics(**kwargs):
        # Custom code to summarize and process the metrics
        result = metric_fn_and_keys[0](kwargs)  # metric_fn returns a tuple
        summary = {key: value for key, value in zip(metric_fn_and_keys[1], result)}
        summary['count'] = len(result)
        return summary

    summary_op = DataFlowPythonOperator(
        task_id=f"{task_prefix}-summary",
        py_file='path_to_summary_script.py',  # Reference to the Python file that processes the data
        options=dataflow_options,
        region=region,
        project_id=project_id,
        dag=dag,
        python_callable=summarize_metrics,
        provide_context=True,
    )

    # Step 3: Set up the Validation Operator
    def validate_metrics(**kwargs):
        summary = kwargs['ti'].xcom_pull(task_ids=f"{task_prefix}-summary")
        return validate_fn(summary)

    validation_op = PythonOperator(
        task_id=f"{task_prefix}-validation",
        python_callable=validate_metrics,
        provide_context=True,
        dag=dag,
    )

    # Return all three operators
    prediction_op >> summary_op >> validation_op

    return prediction_op, summary_op, validation_op
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates the directory specified by path, creating intermediate directories
    as necessary. If directory already exists, this is a no-op.

    :param path: The directory to create
    :type path: str
    :param mode: The mode to give to the directory e.g. 0o755, ignores umask
    :type mode: int 
ChatGPT said:
import os

def create_directory(path, mode=0o755):
    os.makedirs(path, mode=mode, exist_ok=True)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

A small helper function to convert a string to a numeric value
    if appropriate

    :param s: the string to be converted
    :type s: str 
ChatGPT said:
def to_numeric(s):
    try:
        return float(s) if '.' in s else int(s)
    except ValueError:
        return s
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get the current date and time in UTC
    :return: 
ChatGPT said:
from datetime import datetime

def get_current_utc_datetime():
    return datetime.utcnow()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets the epoch in the users timezone
    :return: 
ChatGPT said:
import time
import pytz
from datetime import datetime

def get_epoch_in_user_timezone():
    local_timezone = pytz.timezone("Your/Timezone")  # Replace with your desired timezone
    local_time = datetime.now(local_timezone)
    return int(local_time.timestamp())
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the datetime with the default timezone added if timezone
    information was not associated
    :param value: datetime
    :return: datetime with tzinfo 
ChatGPT said:
from datetime import datetime
import pytz

def add_default_timezone(value):
    if value.tzinfo is None:
        default_timezone = pytz.UTC  # You can change this to any default timezone
        value = value.replace(tzinfo=default_timezone)
    return value
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Make a naive datetime.datetime in a given time zone aware.

    :param value: datetime
    :param timezone: timezone
    :return: localized datetime in settings.TIMEZONE or timezone 
ChatGPT said:
from datetime import datetime
import pytz

def make_aware(value, timezone):
    if value.tzinfo is None:
        timezone = pytz.timezone(timezone)
        value = timezone.localize(value)
    return value
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Make an aware datetime.datetime naive in a given time zone.

    :param value: datetime
    :param timezone: timezone
    :return: naive datetime 
ChatGPT said:
from datetime import datetime
import pytz

def make_naive(value, timezone):
    if value.tzinfo is not None:
        timezone = pytz.timezone(timezone)
        value = value.astimezone(timezone).replace(tzinfo=None)
    return value
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified

    :return: datetime.datetime 
ChatGPT said:
from datetime import datetime
import pytz

def datetime_with_timezone(value=None):
    if value is None:
        value = datetime.now()
    
    if value.tzinfo is None:
        value = value.replace(tzinfo=pytz.timezone('UTC'))  # Replace with your default timezone
    
    return value
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Sets the environment variable GOOGLE_APPLICATION_CREDENTIALS with either:

        - The path to the keyfile from the specified connection id
        - A generated file's path if the user specified JSON in the connection id. The
            file is assumed to be deleted after the process dies due to how mkstemp()
            works.

        The environment variable is used inside the gcloud command to determine correct
        service account to use. 
ChatGPT said:
import os
import tempfile
from google.auth import credentials
from google.oauth2 import service_account

def set_google_application_credentials(connection_id):
    # Assume a function get_connection_details(connection_id) exists that retrieves connection details
    connection = get_connection_details(connection_id)
    
    if 'keyfile' in connection:
        keyfile_path = connection['keyfile']
        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = keyfile_path
    elif 'json' in connection:
        # Create a temporary file with the provided JSON credentials
        json_content = connection['json']
        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            temp_file.write(json_content.encode())
            temp_file.close()
            os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = temp_file.name
    else:
        raise ValueError("No valid keyfile or JSON found in connection details")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Fetches a field from extras, and returns it. This is some Airflow
        magic. The google_cloud_platform hook type adds custom UI elements
        to the hook page, which allow admins to specify service_account,
        key_path, etc. They get formatted as shown below. 
ChatGPT said:
from airflow.hooks.base_hook import BaseHook

def fetch_field_from_extras(connection_id, field_name):
    connection = BaseHook.get_connection(connection_id)
    if 'extra' in connection and connection.extra:
        extras = connection.extra_dejson
        if field_name in extras:
            return extras[field_name]
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Establish a connection to druid broker. 
ChatGPT said:
from pydruid.client import PyDruid

def connect_to_druid_broker(broker_url):
    return PyDruid(broker_url)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns http session for use with requests

        :param headers: additional headers to be passed through as a dictionary
        :type headers: dict 
ChatGPT said:
import requests

def get_http_session(headers=None):
    session = requests.Session()
    if headers:
        session.headers.update(headers)
    return session

You said:
Please generate a Python function that does the following with only the code box and no example usage:

Performs the request

        :param endpoint: the endpoint to be called i.e. resource/v1/query?
        :type endpoint: str
        :param data: payload to be uploaded or request parameters
        :type data: dict
        :param headers: additional headers to be passed through as a dictionary
        :type headers: dict
        :param extra_options: additional options to be used when executing the request
            i.e. {'check_response': False} to avoid checking raising exceptions on non
            2XX or 3XX status codes
        :type extra_options: dict 
ChatGPT said:
import requests

def perform_request(endpoint, data=None, headers=None, extra_options=None):
    """
    Performs the HTTP request with the provided endpoint, data, headers, and extra options.

    Args:
        endpoint (str): The endpoint to be called, e.g. resource/v1/query?.
        data (dict): Payload to be uploaded or request parameters.
        headers (dict): Additional headers to be passed through.
        extra_options (dict): Additional options for the request, such as 'check_response'.
        
    Returns:
        response (requests.Response): The HTTP response object from the request.
    """
    # Set default values for headers and extra options if not provided
    headers = headers or {}
    extra_options = extra_options or {}

    # Construct the URL for the request (assuming base URL is predefined)
    base_url = "https://api.example.com/"
    url = base_url + endpoint

    # Perform the request
    response = requests.post(url, data=data, headers=headers)

    # Check if 'check_response' option is set to False in extra options
    if extra_options.get('check_response', True):
        # Raise an exception if the response code is not 2xx or 3xx
        response.raise_for_status()

    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Checks the status code and raise an AirflowException exception on non 2XX or 3XX
        status codes

        :param response: A requests response object
        :type response: requests.response 
ChatGPT said:
from airflow.exceptions import AirflowException

def check_status_code(response):
    """
    Checks the status code of the response and raises an AirflowException
    if the status code is not 2XX or 3XX.

    Args:
        response (requests.Response): The HTTP response object.

    Raises:
        AirflowException: If the status code is not 2XX or 3XX.
    """
    if not (200 <= response.status_code < 400):
        raise AirflowException(f"Request failed with status code {response.status_code}: {response.text}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Grabs extra options like timeout and actually runs the request,
        checking for the result

        :param session: the session to be used to execute the request
        :type session: requests.Session
        :param prepped_request: the prepared request generated in run()
        :type prepped_request: session.prepare_request
        :param extra_options: additional options to be used when executing the request
            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX
            or 3XX status codes
        :type extra_options: dict 
ChatGPT said:
import requests

def run_request_with_extra_options(session, prepped_request, extra_options=None):
    """
    Grabs extra options like timeout and actually runs the request,
    checking for the result.

    Args:
        session (requests.Session): The session to be used to execute the request.
        prepped_request (requests.PreparedRequest): The prepared request generated in run().
        extra_options (dict): Additional options for executing the request, e.g. 
            {'check_response': False} to avoid raising exceptions on non 2XX or 3XX status codes.

    Returns:
        response (requests.Response): The response object from the executed request.
    """
    extra_options = extra_options or {}

    # Get timeout from extra options or default to None
    timeout = extra_options.get('timeout', None)

    # Execute the request
    response = session.send(prepped_request, timeout=timeout)

    # If 'check_response' is True, check the response status code
    if extra_options.get('check_response', True):
        if not (200 <= response.status_code < 400):
            response.raise_for_status()

    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Runs Hook.run() with a Tenacity decorator attached to it. This is useful for
        connectors which might be disturbed by intermittent issues and should not
        instantly fail.

        :param _retry_args: Arguments which define the retry behaviour.
            See Tenacity documentation at https://github.com/jd/tenacity
        :type _retry_args: dict


        :Example::

            hook = HttpHook(http_conn_id='my_conn',method='GET')
            retry_args = dict(
                 wait=tenacity.wait_exponential(),
                 stop=tenacity.stop_after_attempt(10),
                 retry=requests.exceptions.ConnectionError
             )
             hook.run_with_advanced_retry(
                     endpoint='v1/test',
                     _retry_args=retry_args
                 ) 
ChatGPT said:
import tenacity
from airflow.hooks.base_hook import BaseHook

def run_with_advanced_retry(hook, _retry_args, *args, **kwargs):
    """
    Runs Hook.run() with a Tenacity decorator attached to it.
    This is useful for connectors which might be disturbed by intermittent issues 
    and should not instantly fail.

    Args:
        hook (BaseHook): The hook object to be used for running the request.
        _retry_args (dict): Arguments defining the retry behavior, as defined in Tenacity documentation.
        *args: Additional arguments to pass to the hook's run method.
        **kwargs: Additional keyword arguments to pass to the hook's run method.

    Returns:
        The result of the hook's run method.
    """
    
    # Define the retry decorator with the provided arguments
    retry_decorator = tenacity.retry(**_retry_args)
    
    # Define the wrapped function with retry
    @retry_decorator
    def run_with_retry():
        return hook.run(*args, **kwargs)

    # Execute the wrapped function with retry logic
    return run_with_retry()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Contextmanager that will create and teardown a session. 
ChatGPT said:
from contextlib import contextmanager
import requests

@contextmanager
def session_manager():
    """
    Context manager that will create and teardown a session.
    
    Yields:
        requests.Session: A requests session object.
    """
    session = requests.Session()
    try:
        yield session
    finally:
        session.close()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Function decorator that provides a session if it isn't provided.
    If you want to reuse a session or run the function as part of a
    database transaction, you pass it to the function, if not this wrapper
    will create one and close it for you. 
ChatGPT said:
from functools import wraps
import requests

def with_session(func):
    """
    Function decorator that provides a session if it isn't provided.
    If you want to reuse a session or run the function as part of a
    database transaction, you pass it to the function; if not, 
    this wrapper will create one and close it for you.
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        # Check if session is provided as a keyword argument
        session = kwargs.get('session', None)
        
        # If no session is provided, create one
        if session is None:
            session = requests.Session()
            kwargs['session'] = session
            close_session = True
        else:
            close_session = False
        
        try:
            return func(*args, **kwargs)
        finally:
            # Close the session if it was created by the decorator
            if close_session:
                session.close()
    
    return wrapper
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Clear out the database 
ChatGPT said:
import sqlite3

def clear_database(db_name):
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    
    # Get the list of tables in the database
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = cursor.fetchall()
    
    # Delete all rows from each table
    for table in tables:
        cursor.execute(f"DELETE FROM {table[0]}")
    
    # Commit the changes and close the connection
    conn.commit()
    conn.close()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Upload a file to Azure Blob Storage. 
ChatGPT said:
from azure.storage.blob import BlobServiceClient

def upload_to_azure_blob(container_name, blob_name, file_path, connection_string):
    """
    Upload a file to Azure Blob Storage.

    :param container_name: The name of the Azure Blob container.
    :type container_name: str
    :param blob_name: The name of the blob (file) in Azure.
    :type blob_name: str
    :param file_path: The local path to the file that needs to be uploaded.
    :type file_path: str
    :param connection_string: The Azure Storage connection string.
    :type connection_string: str
    """
    blob_service_client = BlobServiceClient.from_connection_string(connection_string)
    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)
    
    with open(file_path, "rb") as data:
        blob_client.upload_blob(data, overwrite=True)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a connection object 
ChatGPT said:
import sqlite3

def get_connection(db_path):
    """
    Returns a connection object to the specified SQLite database.

    :param db_path: Path to the SQLite database file.
    :type db_path: str
    :return: SQLite connection object.
    :rtype: sqlite3.Connection
    """
    return sqlite3.connect(db_path)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Parses some DatabaseError to provide a better error message 
ChatGPT said:
import sqlite3

def parse_database_error(error):
    if isinstance(error, sqlite3.DatabaseError):
        error_msg = str(error)
        if "database disk image is malformed" in error_msg:
            return "The database file is corrupted. Please restore from a backup."
        elif "unable to open database file" in error_msg:
            return "The database file could not be opened. Check file permissions or path."
        elif "no such table" in error_msg:
            return "The table you're trying to access does not exist in the database."
        else:
            return f"Database error occurred: {error_msg}"
    else:
        return "An unknown error occurred."
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get a set of records from Presto 
ChatGPT said:
from prestodb import dbapi

def get_presto_records(host, port, user, query):
    """
    Gets a set of records from a Presto database.

    :param host: The Presto server host.
    :type host: str
    :param port: The Presto server port.
    :type port: int
    :param user: The user for the Presto connection.
    :type user: str
    :param query: The SQL query to execute.
    :type query: str
    :return: A set of records returned by the query.
    :rtype: set
    """
    conn = dbapi.connect(
        host=host,
        port=port,
        user=user,
        catalog='hive',  # Adjust the catalog if needed
        schema='default'  # Adjust the schema if needed
    )
    
    cursor = conn.cursor()
    cursor.execute(query)
    
    # Fetch all results and convert to a set
    records = set(cursor.fetchall())
    
    cursor.close()
    conn.close()
    
    return records
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get a pandas dataframe from a sql query. 
ChatGPT said:
import pandas as pd
import sqlite3

def get_dataframe_from_sql(query, db_path):
    """
    Executes a SQL query and returns the results as a pandas DataFrame.

    :param query: The SQL query to execute.
    :type query: str
    :param db_path: Path to the SQLite database file.
    :type db_path: str
    :return: A pandas DataFrame containing the query results.
    :rtype: pandas.DataFrame
    """
    conn = sqlite3.connect(db_path)
    df = pd.read_sql_query(query, conn)
    conn.close()
    return df
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Execute the statement against Presto. Can be used to create views. 
ChatGPT said:
import prestodb

def execute_presto_statement(statement, presto_host, presto_port, catalog, schema):
    """
    Executes a SQL statement against Presto. Can be used to create views or other queries.

    :param statement: The SQL statement to execute.
    :type statement: str
    :param presto_host: The host of the Presto server.
    :type presto_host: str
    :param presto_port: The port of the Presto server.
    :type presto_port: int
    :param catalog: The catalog to connect to in Presto.
    :type catalog: str
    :param schema: The schema to use in Presto.
    :type schema: str
    """
    conn = prestodb.dbapi.connect(
        host=presto_host,
        port=presto_port,
        catalog=catalog,
        schema=schema
    )
    cursor = conn.cursor()
    cursor.execute(statement)
    conn.commit()
    cursor.close()
    conn.close()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

A generic way to insert a set of tuples into a table.

        :param table: Name of the target table
        :type table: str
        :param rows: The rows to insert into the table
        :type rows: iterable of tuples
        :param target_fields: The names of the columns to fill in the table
        :type target_fields: iterable of strings 
ChatGPT said:
import psycopg2
from psycopg2 import sql

def insert_into_table(conn, table, rows, target_fields):
    """
    A generic way to insert a set of tuples into a table.

    :param conn: The database connection object
    :type conn: psycopg2.extensions.connection
    :param table: Name of the target table
    :type table: str
    :param rows: The rows to insert into the table
    :type rows: iterable of tuples
    :param target_fields: The names of the columns to fill in the table
    :type target_fields: iterable of strings
    """
    cursor = conn.cursor()

    # Construct the SQL query dynamically
    query = sql.SQL("INSERT INTO {table} ({fields}) VALUES ({values})").format(
        table=sql.Identifier(table),
        fields=sql.SQL(', ').join(map(sql.Identifier, target_fields)),
        values=sql.SQL(', ').join(sql.Placeholder() * len(target_fields))
    )

    # Flatten the rows and execute the insert
    for row in rows:
        cursor.execute(query, row)

    conn.commit()
    cursor.close()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return a cosmos db client. 
ChatGPT said:
from azure.cosmos import CosmosClient

def get_cosmos_db_client(endpoint, key):
    client = CosmosClient(endpoint, key)
    return client
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Checks if a collection exists in CosmosDB. 
ChatGPT said:
from azure.cosmos import CosmosClient, exceptions

def collection_exists(client: CosmosClient, database_name: str, collection_name: str) -> bool:
    """
    Checks if a collection exists in CosmosDB.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database
    :type database_name: str
    :param collection_name: The name of the collection
    :type collection_name: str

    :return: True if the collection exists, otherwise False
    :rtype: bool
    """
    try:
        database = client.get_database_client(database_name)
        collection = database.get_container_client(collection_name)
        # Try to access the collection by listing its items
        collection.read_item(id=collection_name, partition_key=collection_name)
        return True
    except exceptions.CosmosResourceNotFoundError:
        return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new collection in the CosmosDB database. 
ChatGPT said:
from azure.cosmos import CosmosClient

def create_collection(client: CosmosClient, database_name: str, collection_name: str, partition_key_path: str):
    """
    Creates a new collection in the CosmosDB database.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database
    :type database_name: str
    :param collection_name: The name of the collection to create
    :type collection_name: str
    :param partition_key_path: The partition key path for the collection
    :type partition_key_path: str
    """
    database = client.get_database_client(database_name)
    
    # Define collection properties
    container_properties = {
        'id': collection_name,
        'partitionKey': {
            'paths': [partition_key_path],
            'kind': 'Hash'
        }
    }
    
    # Create the collection
    database.create_container_if_not_exists(**container_properties)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Checks if a database exists in CosmosDB. 
ChatGPT said:
from azure.cosmos import CosmosClient

def check_database_exists(client: CosmosClient, database_name: str) -> bool:
    """
    Checks if a database exists in CosmosDB.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database to check
    :type database_name: str
    :return: True if the database exists, False otherwise
    :rtype: bool
    """
    try:
        client.get_database_client(database_name)
        return True
    except Exception as e:
        return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new database in CosmosDB. 
ChatGPT said:
from azure.cosmos import CosmosClient

def create_database(client: CosmosClient, database_name: str):
    """
    Creates a new database in CosmosDB.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database to create
    :type database_name: str
    """
    try:
        database = client.create_database_if_not_exists(database_name)
        return database
    except Exception as e:
        raise Exception(f"An error occurred while creating the database: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes an existing database in CosmosDB. 
ChatGPT said:
from azure.cosmos import CosmosClient

def delete_database(client: CosmosClient, database_name: str):
    """
    Deletes an existing database in CosmosDB.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database to delete
    :type database_name: str
    """
    try:
        database = client.get_database_client(database_name)
        database.delete()
    except Exception as e:
        raise Exception(f"An error occurred while deleting the database: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes an existing collection in the CosmosDB database. 
ChatGPT said:
from azure.cosmos import CosmosClient

def delete_collection(client: CosmosClient, database_name: str, collection_name: str):
    """
    Deletes an existing collection in the CosmosDB database.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database that contains the collection
    :type database_name: str
    :param collection_name: The name of the collection to delete
    :type collection_name: str
    """
    try:
        database = client.get_database_client(database_name)
        container = database.get_container_client(collection_name)
        container.delete()
    except Exception as e:
        raise Exception(f"An error occurred while deleting the collection: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Inserts a new document (or updates an existing one) into an existing
        collection in the CosmosDB database. 
ChatGPT said:
from azure.cosmos import CosmosClient

def upsert_document(client: CosmosClient, database_name: str, collection_name: str, document: dict):
    """
    Inserts a new document (or updates an existing one) into an existing collection in the CosmosDB database.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database that contains the collection
    :type database_name: str
    :param collection_name: The name of the collection to insert/update the document into
    :type collection_name: str
    :param document: The document to insert or update
    :type document: dict
    """
    try:
        database = client.get_database_client(database_name)
        container = database.get_container_client(collection_name)
        container.upsert_item(document)
    except Exception as e:
        raise Exception(f"An error occurred while upserting the document: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Insert a list of new documents into an existing collection in the CosmosDB database. 
ChatGPT said:
from azure.cosmos import CosmosClient

def insert_documents(client: CosmosClient, database_name: str, collection_name: str, documents: list):
    """
    Inserts a list of new documents into an existing collection in the CosmosDB database.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database that contains the collection
    :type database_name: str
    :param collection_name: The name of the collection to insert the documents into
    :type collection_name: str
    :param documents: The list of documents to insert
    :type documents: list
    """
    try:
        database = client.get_database_client(database_name)
        container = database.get_container_client(collection_name)
        for document in documents:
            container.create_item(document)
    except Exception as e:
        raise Exception(f"An error occurred while inserting the documents: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Delete an existing document out of a collection in the CosmosDB database. 
ChatGPT said:
from azure.cosmos import CosmosClient

def delete_document(client: CosmosClient, database_name: str, collection_name: str, document_id: str, partition_key: str):
    """
    Deletes an existing document out of a collection in the CosmosDB database.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database that contains the collection
    :type database_name: str
    :param collection_name: The name of the collection
    :type collection_name: str
    :param document_id: The ID of the document to delete
    :type document_id: str
    :param partition_key: The partition key value for the document
    :type partition_key: str
    """
    try:
        database = client.get_database_client(database_name)
        container = database.get_container_client(collection_name)
        container.delete_item(item=document_id, partition_key=partition_key)
    except Exception as e:
        raise Exception(f"An error occurred while deleting the document: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get a document from an existing collection in the CosmosDB database. 
ChatGPT said:
from azure.cosmos import CosmosClient

def get_document(client: CosmosClient, database_name: str, collection_name: str, document_id: str, partition_key: str) -> dict:
    """
    Gets a document from an existing collection in the CosmosDB database.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database that contains the collection
    :type database_name: str
    :param collection_name: The name of the collection
    :type collection_name: str
    :param document_id: The ID of the document to retrieve
    :type document_id: str
    :param partition_key: The partition key value for the document
    :type partition_key: str
    :return: The document as a dictionary
    :rtype: dict
    """
    try:
        database = client.get_database_client(database_name)
        container = database.get_container_client(collection_name)
        return container.read_item(item=document_id, partition_key=partition_key)
    except Exception as e:
        raise Exception(f"An error occurred while retrieving the document: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get a list of documents from an existing collection in the CosmosDB database via SQL query. 
ChatGPT said:
from azure.cosmos import CosmosClient

def query_documents(client: CosmosClient, database_name: str, collection_name: str, query: str, parameters: list = None) -> list:
    """
    Gets a list of documents from an existing collection in the CosmosDB database via SQL query.

    :param client: Cosmos DB client instance
    :type client: CosmosClient
    :param database_name: The name of the database that contains the collection
    :type database_name: str
    :param collection_name: The name of the collection to query
    :type collection_name: str
    :param query: The SQL query string
    :type query: str
    :param parameters: Optional list of parameters for the query
    :type parameters: list of dict, optional
    :return: List of documents matching the query
    :rtype: list
    """
    try:
        database = client.get_database_client(database_name)
        container = database.get_container_client(collection_name)
        query_definition = {'query': query}
        if parameters:
            query_definition['parameters'] = parameters
        items = container.query_items(
            query=query_definition['query'],
            parameters=query_definition.get('parameters', []),
            enable_cross_partition_query=True
        )
        return list(items)
    except Exception as e:
        raise Exception(f"An error occurred while querying documents: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return python code of a given dag_id. 
ChatGPT said:
from airflow.models import DagBag

def get_dag_python_code(dag_id: str) -> str:
    """
    Return python code of a given dag_id.

    :param dag_id: The DAG ID
    :type dag_id: str
    :return: The Python code of the DAG
    :rtype: str
    """
    dag_bag = DagBag()
    dag = dag_bag.get_dag(dag_id)
    if dag and dag.fileloc:
        with open(dag.fileloc, 'r') as file:
            return file.read()
    raise ValueError(f"DAG with id '{dag_id}' not found or has no associated file.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the Cloud Function with the given name.

        :param name: Name of the function.
        :type name: str
        :return: A Cloud Functions object representing the function.
        :rtype: dict 
ChatGPT said:
from google.cloud import functions_v1

def get_cloud_function(name: str) -> dict:
    """
    Returns the Cloud Function with the given name.

    :param name: Name of the function.
    :type name: str
    :return: A Cloud Functions object representing the function.
    :rtype: dict
    """
    client = functions_v1.CloudFunctionsServiceClient()
    try:
        function = client.get_function(request={"name": name})
        return function.__class__.to_dict(function)
    except Exception as e:
        raise Exception(f"Failed to retrieve Cloud Function '{name}': {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new function in Cloud Function in the location specified in the body.

        :param location: The location of the function.
        :type location: str
        :param body: The body required by the Cloud Functions insert API.
        :type body: dict
        :param project_id: Optional, Google Cloud Project project_id where the function belongs.
            If set to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: None 
ChatGPT said:
from google.cloud import functions_v1

def create_cloud_function(location: str, body: dict, project_id: str = None) -> None:
    """
    Creates a new function in Cloud Function in the location specified in the body.

    :param location: The location of the function.
    :type location: str
    :param body: The body required by the Cloud Functions insert API.
    :type body: dict
    :param project_id: Optional, Google Cloud Project project_id where the function belongs.
                      If set to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: None
    """
    client = functions_v1.CloudFunctionsServiceClient()
    parent = f"projects/{project_id}/locations/{location}" if project_id else location
    try:
        operation = client.create_function(request={"location": parent, "function": body})
        operation.result()  # Wait for the operation to complete
    except Exception as e:
        raise Exception(f"Failed to create Cloud Function: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Updates Cloud Functions according to the specified update mask.

        :param name: The name of the function.
        :type name: str
        :param body: The body required by the cloud function patch API.
        :type body: dict
        :param update_mask: The update mask - array of fields that should be patched.
        :type update_mask: [str]
        :return: None 
ChatGPT said:
from google.cloud import functions_v1
from google.protobuf import field_mask_pb2

def update_cloud_function(name: str, body: dict, update_mask: list[str]) -> None:
    """
    Updates Cloud Functions according to the specified update mask.

    :param name: The name of the function.
    :type name: str
    :param body: The body required by the cloud function patch API.
    :type body: dict
    :param update_mask: The update mask - array of fields that should be patched.
    :type update_mask: list[str]
    :return: None
    """
    client = functions_v1.CloudFunctionsServiceClient()
    mask = field_mask_pb2.FieldMask(paths=update_mask)
    try:
        operation = client.update_function(request={"function": body, "update_mask": mask})
        operation.result()  # Wait for the operation to complete
    except Exception as e:
        raise Exception(f"Failed to update Cloud Function '{name}': {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Uploads zip file with sources.

        :param location: The location where the function is created.
        :type location: str
        :param zip_path: The path of the valid .zip file to upload.
        :type zip_path: str
        :param project_id: Optional, Google Cloud Project project_id where the function belongs.
            If set to None or missing, the default project_id from the GCP connection is used.
        :type project_id: str
        :return: The upload URL that was returned by generateUploadUrl method. 
ChatGPT said:
from google.cloud import functions_v1

def upload_function_source(location: str, zip_path: str, project_id: str = None) -> str:
    """
    Uploads zip file with sources.

    :param location: The location where the function is created.
    :type location: str
    :param zip_path: The path of the valid .zip file to upload.
    :type zip_path: str
    :param project_id: Optional, Google Cloud Project project_id where the function belongs.
                       If set to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: The upload URL that was returned by generateUploadUrl method.
    """
    import requests

    client = functions_v1.CloudFunctionsServiceClient()
    parent = f"projects/{project_id}/locations/{location}" if project_id else location

    try:
        response = client.generate_upload_url(request={"parent": parent})
        upload_url = response.upload_url

        with open(zip_path, 'rb') as f:
            headers = {"content-type": "application/zip"}
            upload_response = requests.put(upload_url, data=f, headers=headers)
            upload_response.raise_for_status()

        return upload_url
    except Exception as e:
        raise Exception(f"Failed to upload function source: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes the specified Cloud Function.

        :param name: The name of the function.
        :type name: str
        :return: None 
ChatGPT said:
from google.cloud import functions_v1

def delete_cloud_function(name: str) -> None:
    """
    Deletes the specified Cloud Function.

    :param name: The name of the function.
    :type name: str
    :return: None
    """
    client = functions_v1.CloudFunctionsServiceClient()
    try:
        operation = client.delete_function(request={"name": name})
        operation.result()  # Wait for the operation to complete
    except Exception as e:
        raise Exception(f"Failed to delete Cloud Function '{name}': {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Waits for the named operation to complete - checks status of the
        asynchronous call.

        :param operation_name: The name of the operation.
        :type operation_name: str
        :return: The response returned by the operation.
        :rtype: dict
        :exception: AirflowException in case error is returned. 
ChatGPT said:
from google.cloud import functions_v1
from airflow.exceptions import AirflowException

def wait_for_operation(operation_name: str) -> dict:
    """
    Waits for the named operation to complete - checks status of the asynchronous call.

    :param operation_name: The name of the operation.
    :type operation_name: str
    :return: The response returned by the operation.
    :rtype: dict
    :exception: AirflowException in case error is returned.
    """
    client = functions_v1.CloudFunctionsServiceClient()
    operation = client.transport.operations_client.get_operation(operation_name)

    while not operation.done:
        operation = client.transport.operations_client.get_operation(operation_name)

    if operation.error.message:
        raise AirflowException(f"Operation failed: {operation.error.message}")

    return operation.response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Publishes messages to a Pub/Sub topic.

        :param project: the GCP project ID in which to publish
        :type project: str
        :param topic: the Pub/Sub topic to which to publish; do not
            include the `projects/{project}/topics/ prefix.
        :type topic: str
        :param messages: messages to publish; if the data field in a
            message is set, it should already be base64 encoded.
        :type messages: list of PubSub messages; see
            http://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage 
ChatGPT said:
from google.cloud import pubsub_v1
from google.protobuf.json_format import MessageToDict

def publish_messages_to_pubsub(project: str, topic: str, messages: list) -> None:
    """
    Publishes messages to a Pub/Sub topic.

    :param project: the GCP project ID in which to publish
    :type project: str
    :param topic: the Pub/Sub topic to which to publish; do not include the ``projects/{project}/topics/`` prefix.
    :type topic: str
    :param messages: messages to publish; if the data field in a message is set, it should already be base64 encoded.
    :type messages: list of PubSub messages; see http://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage
    """
    publisher = pubsub_v1.PublisherClient()
    topic_path = publisher.topic_path(project, topic)

    # Create a list of Pub/Sub messages
    pubsub_messages = [pubsub_v1.PubsubMessage(data=message['data']) for message in messages]

    # Publish the messages
    future = publisher.publish(topic_path, *[msg.data for msg in pubsub_messages])

    # Wait for the messages to be published
    future.result()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a Pub/Sub topic, if it does not already exist.

        :param project: the GCP project ID in which to create
            the topic
        :type project: str
        :param topic: the Pub/Sub topic name to create; do not
            include the `projects/{project}/topics/ prefix.
        :type topic: str
        :param fail_if_exists: if set, raise an exception if the topic
            already exists
        :type fail_if_exists: bool 
ChatGPT said:
from google.cloud import pubsub_v1
from google.api_core.exceptions import AlreadyExists

def create_pubsub_topic(project: str, topic: str, fail_if_exists: bool = False) -> None:
    """
    Creates a Pub/Sub topic, if it does not already exist.

    :param project: the GCP project ID in which to create the topic
    :type project: str
    :param topic: the Pub/Sub topic name to create; do not include the ``projects/{project}/topics/`` prefix.
    :type topic: str
    :param fail_if_exists: if set, raise an exception if the topic already exists
    :type fail_if_exists: bool
    """
    publisher = pubsub_v1.PublisherClient()
    topic_path = publisher.topic_path(project, topic)

    try:
        # Attempt to create the topic
        publisher.create_topic(name=topic_path)
    except AlreadyExists:
        if fail_if_exists:
            raise
        # Topic already exists, no action needed
        pass
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes a Pub/Sub topic if it exists.

        :param project: the GCP project ID in which to delete the topic
        :type project: str
        :param topic: the Pub/Sub topic name to delete; do not
            include the `projects/{project}/topics/ prefix.
        :type topic: str
        :param fail_if_not_exists: if set, raise an exception if the topic
            does not exist
        :type fail_if_not_exists: bool 
ChatGPT said:
from google.cloud import pubsub_v1
from google.api_core.exceptions import NotFound

def delete_pubsub_topic(project: str, topic: str, fail_if_not_exists: bool = False) -> None:
    """
    Deletes a Pub/Sub topic if it exists.

    :param project: the GCP project ID in which to delete the topic
    :type project: str
    :param topic: the Pub/Sub topic name to delete; do not include the ``projects/{project}/topics/`` prefix.
    :type topic: str
    :param fail_if_not_exists: if set, raise an exception if the topic does not exist
    :type fail_if_not_exists: bool
    """
    publisher = pubsub_v1.PublisherClient()
    topic_path = publisher.topic_path(project, topic)

    try:
        # Attempt to delete the topic
        publisher.delete_topic(name=topic_path)
    except NotFound:
        if fail_if_not_exists:
            raise
        # Topic does not exist, no action needed
        pass
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a Pub/Sub subscription, if it does not already exist.

        :param topic_project: the GCP project ID of the topic that the
            subscription will be bound to.
        :type topic_project: str
        :param topic: the Pub/Sub topic name that the subscription will be bound
            to create; do not include the `projects/{project}/subscriptions/
            prefix.
        :type topic: str
        :param subscription: the Pub/Sub subscription name. If empty, a random
            name will be generated using the uuid module
        :type subscription: str
        :param subscription_project: the GCP project ID where the subscription
            will be created. If unspecified, `topic_project will be used.
        :type subscription_project: str
        :param ack_deadline_secs: Number of seconds that a subscriber has to
            acknowledge each message pulled from the subscription
        :type ack_deadline_secs: int
        :param fail_if_exists: if set, raise an exception if the topic
            already exists
        :type fail_if_exists: bool
        :return: subscription name which will be the system-generated value if
            the `subscription parameter is not supplied
        :rtype: str 
ChatGPT said:
from google.cloud import pubsub_v1
from google.api_core.exceptions import AlreadyExists
import uuid

def create_pubsub_subscription(topic_project: str, topic: str, subscription: str = None,
                                subscription_project: str = None, ack_deadline_secs: int = 60, 
                                fail_if_exists: bool = False) -> str:
    """
    Creates a Pub/Sub subscription, if it does not already exist.

    :param topic_project: the GCP project ID of the topic that the subscription will be bound to.
    :type topic_project: str
    :param topic: the Pub/Sub topic name that the subscription will be bound to create; do not include
                  the ``projects/{project}/topics/`` prefix.
    :type topic: str
    :param subscription: the Pub/Sub subscription name. If empty, a random name will be generated using uuid.
    :type subscription: str
    :param subscription_project: the GCP project ID where the subscription will be created.
                                 If unspecified, ``topic_project`` will be used.
    :type subscription_project: str
    :param ack_deadline_secs: Number of seconds that a subscriber has to acknowledge each message pulled
                               from the subscription.
    :type ack_deadline_secs: int
    :param fail_if_exists: if set, raise an exception if the topic already exists
    :type fail_if_exists: bool
    :return: subscription name which will be the system-generated value if the ``subscription`` parameter 
             is not supplied.
    :rtype: str
    """
    if not subscription:
        subscription = str(uuid.uuid4())

    if not subscription_project:
        subscription_project = topic_project

    subscriber = pubsub_v1.SubscriberClient()
    topic_path = subscriber.topic_path(topic_project, topic)
    subscription_path = subscriber.subscription_path(subscription_project, subscription)

    try:
        # Try to create the subscription
        subscriber.create_subscription(name=subscription_path, topic=topic_path, ack_deadline_seconds=ack_deadline_secs)
    except AlreadyExists:
        if fail_if_exists:
            raise
        # Subscription already exists, no action needed
        pass

    return subscription
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes a Pub/Sub subscription, if it exists.

        :param project: the GCP project ID where the subscription exists
        :type project: str
        :param subscription: the Pub/Sub subscription name to delete; do not
            include the `projects/{project}/subscriptions/ prefix.
        :type subscription: str
        :param fail_if_not_exists: if set, raise an exception if the topic
            does not exist
        :type fail_if_not_exists: bool 
ChatGPT said:
from google.cloud import pubsub_v1
from google.api_core.exceptions import NotFound

def delete_pubsub_subscription(project: str, subscription: str, fail_if_not_exists: bool = False):
    """
    Deletes a Pub/Sub subscription, if it exists.

    :param project: the GCP project ID where the subscription exists
    :type project: str
    :param subscription: the Pub/Sub subscription name to delete; do not include the ``projects/{project}/subscriptions/`` prefix.
    :type subscription: str
    :param fail_if_not_exists: if set, raise an exception if the subscription does not exist
    :type fail_if_not_exists: bool
    """
    subscriber = pubsub_v1.SubscriberClient()
    subscription_path = subscriber.subscription_path(project, subscription)

    try:
        subscriber.delete_subscription(subscription_path)
    except NotFound:
        if fail_if_not_exists:
            raise
        # Subscription does not exist, no action needed
        pass
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Pulls up to `max_messages messages from Pub/Sub subscription.

        :param project: the GCP project ID where the subscription exists
        :type project: str
        :param subscription: the Pub/Sub subscription name to pull from; do not
            include the 'projects/{project}/topics/' prefix.
        :type subscription: str
        :param max_messages: The maximum number of messages to return from
            the Pub/Sub API.
        :type max_messages: int
        :param return_immediately: If set, the Pub/Sub API will immediately
            return if no messages are available. Otherwise, the request will
            block for an undisclosed, but bounded period of time
        :type return_immediately: bool
        :return: A list of Pub/Sub ReceivedMessage objects each containing
            an `ackId property and a message property, which includes
            the base64-encoded message content. See
            https://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions/pull#ReceivedMessage 
ChatGPT said:
from google.cloud import pubsub_v1

def pull_pubsub_messages(project: str, subscription: str, max_messages: int, return_immediately: bool = False):
    """
    Pulls up to ``max_messages`` messages from Pub/Sub subscription.

    :param project: the GCP project ID where the subscription exists
    :type project: str
    :param subscription: the Pub/Sub subscription name to pull from; do not include the 'projects/{project}/topics/' prefix.
    :type subscription: str
    :param max_messages: The maximum number of messages to return from the Pub/Sub API.
    :type max_messages: int
    :param return_immediately: If set, the Pub/Sub API will immediately return if no messages are available.
        Otherwise, the request will block for an undisclosed, but bounded period of time
    :type return_immediately: bool
    :return: A list of Pub/Sub ReceivedMessage objects each containing
        an ``ackId`` property and a ``message`` property, which includes
        the base64-encoded message content.
    :rtype: list of ReceivedMessage
    """
    subscriber = pubsub_v1.SubscriberClient()
    subscription_path = subscriber.subscription_path(project, subscription)

    # Pull messages from the subscription
    response = subscriber.pull(
        subscription_path,
        max_messages=max_messages,
        return_immediately=return_immediately
    )
    
    return response.received_messages
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Pulls up to `max_messages messages from Pub/Sub subscription.

        :param project: the GCP project name or ID in which to create
            the topic
        :type project: str
        :param subscription: the Pub/Sub subscription name to delete; do not
            include the 'projects/{project}/topics/' prefix.
        :type subscription: str
        :param ack_ids: List of ReceivedMessage ackIds from a previous pull
            response
        :type ack_ids: list 
ChatGPT said:
from google.cloud import pubsub_v1

def acknowledge_pubsub_messages(project: str, subscription: str, ack_ids: list):
    """
    Acknowledges up to ``ack_ids`` messages from Pub/Sub subscription.

    :param project: the GCP project name or ID in which to create the topic
    :type project: str
    :param subscription: the Pub/Sub subscription name to delete; do not include the 'projects/{project}/topics/' prefix.
    :type subscription: str
    :param ack_ids: List of ReceivedMessage ackIds from a previous pull response
    :type ack_ids: list
    """
    subscriber = pubsub_v1.SubscriberClient()
    subscription_path = subscriber.subscription_path(project, subscription)

    # Acknowledge the messages using the provided ack_ids
    subscriber.acknowledge(
        subscription_path,
        ack_ids
    )
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Wrapper around the private _get_dep_statuses method that contains some global
        checks for all dependencies.

        :param ti: the task instance to get the dependency status for
        :type ti: airflow.models.TaskInstance
        :param session: database session
        :type session: sqlalchemy.orm.session.Session
        :param dep_context: the context for which this dependency should be evaluated for
        :type dep_context: DepContext 
ChatGPT said:
from airflow.models import TaskInstance
from sqlalchemy.orm import sessionmaker

def get_dependency_status(ti: TaskInstance, session: sessionmaker, dep_context):
    """
    Wrapper around the private _get_dep_statuses method that contains some global checks for all dependencies.

    :param ti: the task instance to get the dependency status for
    :type ti: airflow.models.TaskInstance
    :param session: database session
    :type session: sqlalchemy.orm.session.Session
    :param dep_context: the context for which this dependency should be evaluated for
    :type dep_context: DepContext
    """
    # Perform any global checks here if needed before getting dependency statuses
    # For example, you might want to check the task instance status, etc.

    # Call the private _get_dep_statuses method or your own logic to check the status
    dep_statuses = ti._get_dep_statuses(session=session, dep_context=dep_context)
    
    return dep_statuses
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns whether or not this dependency is met for a given task instance. A
        dependency is considered met if all of the dependency statuses it reports are
        passing.

        :param ti: the task instance to see if this dependency is met for
        :type ti: airflow.models.TaskInstance
        :param session: database session
        :type session: sqlalchemy.orm.session.Session
        :param dep_context: The context this dependency is being checked under that stores
            state that can be used by this dependency.
        :type dep_context: BaseDepContext 
ChatGPT said:
from airflow.models import TaskInstance
from sqlalchemy.orm import sessionmaker

def is_dependency_met(ti: TaskInstance, session: sessionmaker, dep_context):
    """
    Returns whether or not this dependency is met for a given task instance. A
    dependency is considered met if all of the dependency statuses it reports are
    passing.

    :param ti: the task instance to see if this dependency is met for
    :type ti: airflow.models.TaskInstance
    :param session: database session
    :type session: sqlalchemy.orm.session.Session
    :param dep_context: The context this dependency is being checked under that stores
        state that can be used by this dependency.
    :type dep_context: BaseDepContext
    """
    # Fetch the dependency statuses using the private method or any logic you have for this
    dep_statuses = ti._get_dep_statuses(session=session, dep_context=dep_context)

    # Check if all dependency statuses are passing
    return all(status == "passed" for status in dep_statuses)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns an iterable of strings that explain why this dependency wasn't met.

        :param ti: the task instance to see if this dependency is met for
        :type ti: airflow.models.TaskInstance
        :param session: database session
        :type session: sqlalchemy.orm.session.Session
        :param dep_context: The context this dependency is being checked under that stores
            state that can be used by this dependency.
        :type dep_context: BaseDepContext 
ChatGPT said:
from airflow.models import TaskInstance
from sqlalchemy.orm import sessionmaker

def get_dependency_not_met_reasons(ti: TaskInstance, session: sessionmaker, dep_context):
    """
    Returns an iterable of strings that explain why this dependency wasn't met.

    :param ti: the task instance to see if this dependency is met for
    :type ti: airflow.models.TaskInstance
    :param session: database session
    :type session: sqlalchemy.orm.session.Session
    :param dep_context: The context this dependency is being checked under that stores
        state that can be used by this dependency.
    :type dep_context: BaseDepContext
    """
    # Fetch the dependency statuses using the private method or any logic you have for this
    dep_statuses = ti._get_dep_statuses(session=session, dep_context=dep_context)

    # Iterate over the statuses and find the ones that are not met
    not_met_reasons = []
    for status, reason in dep_statuses.items():
        if status != "passed":
            not_met_reasons.append(f"Dependency failed due to: {reason}")

    return not_met_reasons
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Parses a config file for s3 credentials. Can currently
    parse boto, s3cmd.conf and AWS SDK config formats

    :param config_file_name: path to the config file
    :type config_file_name: str
    :param config_format: config type. One of "boto", "s3cmd" or "aws".
        Defaults to "boto"
    :type config_format: str
    :param profile: profile name in AWS type config file
    :type profile: str 
ChatGPT said:
import configparser
import os

def parse_s3_credentials(config_file_name: str, config_format: str = "boto", profile: str = None):
    """
    Parses a config file for S3 credentials. Supports boto, s3cmd.conf, and AWS SDK config formats.

    :param config_file_name: path to the config file
    :type config_file_name: str
    :param config_format: config type. One of "boto", "s3cmd" or "aws".
        Defaults to "boto"
    :type config_format: str
    :param profile: profile name in AWS type config file
    :type profile: str
    :return: Dictionary of S3 credentials
    :rtype: dict
    """
    credentials = {}
    
    if not os.path.exists(config_file_name):
        raise FileNotFoundError(f"The config file '{config_file_name}' does not exist.")
    
    if config_format == "boto":
        # Parsing a boto config format
        config = configparser.ConfigParser()
        config.read(config_file_name)
        
        section = profile if profile else "Credentials"
        if section not in config:
            raise ValueError(f"Profile '{section}' not found in the config.")
        
        credentials['aws_access_key_id'] = config.get(section, 'aws_access_key_id', fallback=None)
        credentials['aws_secret_access_key'] = config.get(section, 'aws_secret_access_key', fallback=None)
        credentials['region'] = config.get(section, 'region', fallback=None)
    
    elif config_format == "s3cmd":
        # Parsing an s3cmd config file format
        config = configparser.ConfigParser()
        config.read(config_file_name)
        
        section = profile if profile else "default"
        if section not in config:
            raise ValueError(f"Profile '{section}' not found in the config.")
        
        credentials['aws_access_key_id'] = config.get(section, 'access_key', fallback=None)
        credentials['aws_secret_access_key'] = config.get(section, 'secret_key', fallback=None)
    
    elif config_format == "aws":
        # Parsing an AWS SDK config file format
        config = configparser.ConfigParser()
        config.read(config_file_name)
        
        section = f"profile {profile}" if profile else "default"
        if section not in config:
            raise ValueError(f"Profile '{section}' not found in the config.")
        
        credentials['aws_access_key_id'] = config.get(section, 'aws_access_key_id', fallback=None)
        credentials['aws_secret_access_key'] = config.get(section, 'aws_secret_access_key', fallback=None)
        credentials['region'] = config.get(section, 'region', fallback=None)
    
    else:
        raise ValueError(f"Unsupported config format: '{config_format}'. Choose 'boto', 's3cmd', or 'aws'.")
    
    return credentials
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get the underlying botocore.Credentials object.

        This contains the following authentication attributes: access_key, secret_key and token. 
ChatGPT said:
import boto3
from botocore.exceptions import NoCredentialsError

def get_botocore_credentials():
    """
    Get the underlying `botocore.Credentials` object.

    This contains the following authentication attributes: access_key, secret_key, and token.

    :return: botocore.Credentials object
    :rtype: botocore.credentials.Credentials
    :raises NoCredentialsError: If no credentials are found
    """
    session = boto3.Session()
    
    # Attempt to get credentials using the session
    credentials = session.get_credentials()
    
    if credentials is None:
        raise NoCredentialsError("No credentials found.")
    
    return credentials
You said:
Please generate a Python function that does the following with only the code box and no example usage:

If the IAM role is a role name, get the Amazon Resource Name (ARN) for the role.
        If IAM role is already an IAM role ARN, no change is made.

        :param role: IAM role name or ARN
        :return: IAM role ARN 
ChatGPT said:
import boto3

def get_iam_role_arn(role):
    """
    If the IAM role is a role name, get the Amazon Resource Name (ARN) for the role.
    If IAM role is already an IAM role ARN, no change is made.

    :param role: IAM role name or ARN
    :return: IAM role ARN
    :rtype: str
    """
    if role.startswith("arn:aws:iam::"):
        return role  # Already an ARN, no change needed
    
    iam_client = boto3.client('iam')
    response = iam_client.get_role(RoleName=role)
    return response['Role']['Arn']
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns verticaql connection object 
ChatGPT said:
import vertica_python

def get_vertica_connection(host, port, user, password, database):
    """
    Returns a Vertica connection object.

    :param host: Vertica server host
    :type host: str
    :param port: Vertica server port
    :type port: int
    :param user: Vertica username
    :type user: str
    :param password: Vertica password
    :type password: str
    :param database: Vertica database name
    :type database: str
    :return: Vertica connection object
    :rtype: vertica_python.vertica.cursor.Cursor
    """
    conn_info = {
        'host': host,
        'port': port,
        'user': user,
        'password': password,
        'database': database,
        'autocommit': True
    }
    connection = vertica_python.connect(**conn_info)
    return connection
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Walks the tree of loggers and tries to set the context for each handler
    :param logger: logger
    :param value: value to set 
ChatGPT said:
import logging

def set_context_for_loggers(logger, value):
    """
    Walks the tree of loggers and tries to set the context for each handler.

    :param logger: logger to traverse
    :type logger: logging.Logger
    :param value: value to set for each handler
    :type value: any
    """
    for handler in logger.handlers:
        if hasattr(handler, 'setContext'):
            handler.setContext(value)

    # Recursively apply to any child loggers
    for child_logger_name in logging.root.manager.loggerDict:
        child_logger = logging.getLogger(child_logger_name)
        set_context_for_loggers(child_logger, value)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Do whatever it takes to actually log the specified logging record
        :param message: message to log 
ChatGPT said:
import logging

def log_message(message):
    """
    Do whatever it takes to actually log the specified logging record.

    :param message: message to log
    :type message: str
    """
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.debug(message)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Ensure all logging output has been flushed 
ChatGPT said:
import logging

def flush_logging_output():
    """
    Ensure all logging output has been flushed.
    """
    for handler in logging.getLogger().handlers:
        handler.flush()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

If the path contains a folder with a .zip suffix, then
    the folder is treated as a zip archive and path to zip is returned. 
ChatGPT said:
import os

def get_zip_path_from_folder(path):
    """
    If the path contains a folder with a .zip suffix, then the folder is treated as a zip archive 
    and path to the zip is returned.
    
    :param path: The folder path to check.
    :type path: str
    :return: The path to the zip file if a folder with .zip suffix exists, else the original path.
    :rtype: str
    """
    if os.path.isdir(path) and path.endswith('.zip'):
        return path
    return path
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Traverse a directory and look for Python files.

    :param directory: the directory to traverse
    :type directory: unicode
    :param safe_mode: whether to use a heuristic to determine whether a file
        contains Airflow DAG definitions
    :return: a list of paths to Python files in the specified directory
    :rtype: list[unicode] 
ChatGPT said:
import os

def find_python_files(directory, safe_mode=False):
    """
    Traverse a directory and look for Python files.
    
    :param directory: the directory to traverse
    :type directory: unicode
    :param safe_mode: whether to use a heuristic to determine whether a file contains Airflow DAG definitions
    :return: a list of paths to Python files in the specified directory
    :rtype: list[unicode]
    """
    python_files = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                if safe_mode:
                    with open(file_path, 'r') as f:
                        content = f.read()
                        if 'DAG' in content:
                            python_files.append(file_path)
                else:
                    python_files.append(file_path)
    return python_files
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Construct a TaskInstance from the database based on the primary key

        :param session: DB session.
        :param lock_for_update: if True, indicates that the database should
            lock the TaskInstance (issuing a FOR UPDATE clause) until the
            session is committed. 
ChatGPT said:
from airflow.models import TaskInstance

def get_task_instance_by_pk(session, task_instance_id, lock_for_update=False):
    """
    Construct a TaskInstance from the database based on the primary key.
    
    :param session: DB session.
    :param task_instance_id: The primary key (ID) of the TaskInstance.
    :param lock_for_update: if True, indicates that the database should
        lock the TaskInstance (issuing a FOR UPDATE clause) until the
        session is committed.
    :return: The TaskInstance object retrieved from the database.
    :rtype: airflow.models.TaskInstance
    """
    query = session.query(TaskInstance).filter(TaskInstance.id == task_instance_id)
    
    if lock_for_update:
        query = query.with_for_update()
    
    task_instance = query.one_or_none()
    
    return task_instance
You said:
Please generate a Python function that does the following with only the code box and no example usage:

:param dag_id: DAG ID
        :type dag_id: unicode
        :return: if the given DAG ID exists in the bag, return the BaseDag
        corresponding to that ID. Otherwise, throw an Exception
        :rtype: airflow.utils.dag_processing.SimpleDag 
ChatGPT said:
from airflow.utils.dag_processing import SimpleDag
from airflow.exceptions import DagNotFound

def get_dag_by_id(dag_id):
    """
    Returns the BaseDag corresponding to the given DAG ID if it exists.

    :param dag_id: DAG ID
    :type dag_id: unicode
    :return: If the given DAG ID exists in the bag, return the BaseDag
        corresponding to that ID. Otherwise, throw an Exception.
    :rtype: airflow.utils.dag_processing.SimpleDag
    :raises: DagNotFound: If the DAG ID does not exist.
    """
    dag_bag = SimpleDag.get_dag_bag()
    
    if dag_id in dag_bag.dags:
        return dag_bag.dags[dag_id]
    else:
        raise DagNotFound(f"DAG with ID {dag_id} not found.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Launch DagFileProcessorManager processor and start DAG parsing loop in manager. 
ChatGPT said:
from airflow.utils.dag_processing import DagFileProcessorManager

def launch_dag_file_processor_manager():
    """
    Launches the DagFileProcessorManager and starts the DAG parsing loop in the manager.
    """
    dag_file_processor_manager = DagFileProcessorManager()
    dag_file_processor_manager.start()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Harvest DAG parsing results from result queue and sync metadata from stat queue.
        :return: List of parsing result in SimpleDag format. 
ChatGPT said:
from airflow.utils.dag_processing import DagFileProcessorManager

def harvest_dag_parsing_results():
    """
    Harvests DAG parsing results from the result queue and syncs metadata from the stat queue.
    :return: List of parsing results in SimpleDag format.
    """
    dag_file_processor_manager = DagFileProcessorManager()
    dag_file_processor_manager.sync()
    return dag_file_processor_manager.results
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Heartbeat DAG file processor and start it if it is not alive.
        :return: 
ChatGPT said:
from airflow.utils.dag_processing import DagFileProcessorManager

def heartbeat_dag_file_processor():
    """
    Heartbeats the DAG file processor and starts it if it is not alive.
    :return: None
    """
    dag_file_processor_manager = DagFileProcessorManager()
    if not dag_file_processor_manager.is_alive():
        dag_file_processor_manager.start()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Sync metadata from stat queue and only keep the latest stat.
        :return: 
ChatGPT said:
from airflow.utils.dag_processing import DagFileProcessorManager

def sync_metadata_from_stat_queue():
    """
    Sync metadata from the stat queue and only keep the latest stat.
    :return: None
    """
    dag_file_processor_manager = DagFileProcessorManager()
    stats = dag_file_processor_manager.get_stat_queue()
    
    # Keep only the latest stat
    latest_stat = stats[-1] if stats else None
    
    if latest_stat:
        dag_file_processor_manager.sync_metadata(latest_stat)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Send termination signal to DAG parsing processor manager
        and expect it to terminate all DAG file processors. 
ChatGPT said:
from airflow.utils.dag_processing import DagFileProcessorManager

def send_termination_signal_to_dag_processor_manager():
    """
    Send termination signal to DAG parsing processor manager
    and expect it to terminate all DAG file processors.
    :return: None
    """
    dag_file_processor_manager = DagFileProcessorManager()
    dag_file_processor_manager.terminate_processors()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Terminate (and then kill) the manager process launched.
        :return: 
ChatGPT said:
import os
import signal

def terminate_and_kill_manager_process(manager_pid):
    """
    Terminate (and then kill) the manager process launched.
    :param manager_pid: The process ID of the manager to terminate.
    :type manager_pid: int
    :return: None
    """
    try:
        # Sending termination signal to the manager process
        os.kill(manager_pid, signal.SIGTERM)
        
        # Waiting for the process to terminate gracefully
        os.waitpid(manager_pid, 0)
        
        # If the process is still running, force kill it
        os.kill(manager_pid, signal.SIGKILL)
    except ProcessLookupError:
        pass  # In case the process doesn't exist
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Helper method to clean up DAG file processors to avoid leaving orphan processes. 
ChatGPT said:
import os
import signal
import psutil

def cleanup_dag_file_processors(process_name):
    """
    Helper method to clean up DAG file processors to avoid leaving orphan processes.
    :param process_name: The name of the process to look for and clean up.
    :type process_name: str
    :return: None
    """
    # Iterate through all running processes
    for proc in psutil.process_iter(['pid', 'name']):
        try:
            # Check if the process name matches the one to clean up
            if process_name in proc.info['name']:
                # Send SIGTERM to terminate the process gracefully
                proc.terminate()
                proc.wait(timeout=3)  # Wait for the process to terminate
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            pass  # Ignore processes that no longer exist or cannot be accessed
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Use multiple processes to parse and generate tasks for the
        DAGs in parallel. By processing them in separate processes,
        we can get parallelism and isolation from potentially harmful
        user code. 
ChatGPT said:
import multiprocessing
from airflow.models import DagBag

def parse_dags_in_parallel(dag_file_paths):
    """
    Use multiple processes to parse and generate tasks for the DAGs in parallel.
    By processing them in separate processes, we can get parallelism and isolation from potentially harmful user code.
    
    :param dag_file_paths: List of paths to the DAG files to be processed.
    :type dag_file_paths: list[str]
    :return: A list of parsed DAG objects.
    :rtype: list[airflow.models.DAG]
    """
    def parse_dag_file(dag_file_path):
        """
        Helper function to parse a single DAG file.
        :param dag_file_path: Path to the DAG file to parse.
        :type dag_file_path: str
        :return: Parsed DAG object.
        :rtype: airflow.models.DAG
        """
        dag_bag = DagBag(dag_folder=dag_file_path)
        return dag_bag.dags

    # Create a pool of worker processes to parse the DAG files in parallel
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        result = pool.map(parse_dag_file, dag_file_paths)

    # Flatten the result list and return it
    parsed_dags = [dag for sublist in result for dag in sublist]
    return parsed_dags
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Parse DAG files repeatedly in a standalone loop. 
ChatGPT said:
import time
from airflow.models import DagBag

def parse_dags_repeatedly(dag_file_paths, parse_interval=60):
    """
    Parse DAG files repeatedly in a standalone loop.
    
    :param dag_file_paths: List of paths to the DAG files to be parsed.
    :type dag_file_paths: list[str]
    :param parse_interval: Time interval (in seconds) between each parsing iteration.
    :type parse_interval: int
    """
    while True:
        for dag_file_path in dag_file_paths:
            dag_bag = DagBag(dag_folder=dag_file_path)
            # You can implement any additional processing on the parsed DAGs here
            print(f"Parsed DAGs from {dag_file_path}: {dag_bag.dags.keys()}")
        
        # Wait for the specified interval before parsing the DAG files again
        time.sleep(parse_interval)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Parse DAG files in a loop controlled by DagParsingSignal.
        Actual DAG parsing loop will run once upon receiving one
        agent heartbeat message and will report done when finished the loop. 
ChatGPT said:
import time
from airflow.utils.dag_processing import DagParsingSignal
from airflow.models import DagBag

def parse_dags_with_signal(dag_file_paths, heartbeat_signal, parse_interval=60):
    """
    Parse DAG files in a loop controlled by DagParsingSignal.
    The DAG parsing loop will run once upon receiving an agent heartbeat message
    and will report done when finished the loop.
    
    :param dag_file_paths: List of paths to the DAG files to be parsed.
    :type dag_file_paths: list[str]
    :param heartbeat_signal: The signal to control the DAG parsing loop.
    :type heartbeat_signal: DagParsingSignal
    :param parse_interval: Time interval (in seconds) between each parsing iteration.
    :type parse_interval: int
    """
    while True:
        # Wait for the heartbeat signal to continue processing
        heartbeat_signal.wait_for_heartbeat()
        
        # Begin parsing DAG files after receiving the heartbeat
        for dag_file_path in dag_file_paths:
            dag_bag = DagBag(dag_folder=dag_file_path)
            # You can implement any additional processing on the parsed DAGs here
            print(f"Parsed DAGs from {dag_file_path}: {dag_bag.dags.keys()}")
        
        # Report that parsing is done
        print("DAG parsing loop finished.")
        
        # Wait for the specified interval before starting the next loop
        time.sleep(parse_interval)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Refresh file paths from dag dir if we haven't done it for too long. 
ChatGPT said:
import os
import time

def refresh_dag_file_paths(dag_dir, last_refresh_time, refresh_interval=3600):
    """
    Refresh file paths from the DAG directory if we haven't done it for too long.
    
    :param dag_dir: The directory where the DAG files are located.
    :type dag_dir: str
    :param last_refresh_time: The last time the DAG file paths were refreshed (in timestamp format).
    :type last_refresh_time: float
    :param refresh_interval: The interval (in seconds) to wait before refreshing the DAG file paths.
    :type refresh_interval: int
    :return: List of current DAG file paths if refreshed, otherwise an empty list.
    :rtype: list[str]
    """
    current_time = time.time()
    
    if current_time - last_refresh_time > refresh_interval:
        # If the refresh interval has passed, refresh the file paths
        dag_file_paths = [os.path.join(dag_dir, f) for f in os.listdir(dag_dir) if f.endswith('.py')]
        last_refresh_time = current_time
        return dag_file_paths
    else:
        return []
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Occasionally print out stats about how fast the files are getting processed 
ChatGPT said:
import time

def print_processing_stats(start_time, processed_files_count, print_interval=60):
    """
    Print out stats about how fast the files are getting processed.

    :param start_time: The time when the processing started (in timestamp format).
    :type start_time: float
    :param processed_files_count: The number of files that have been processed so far.
    :type processed_files_count: int
    :param print_interval: The interval (in seconds) to print the stats.
    :type print_interval: int
    """
    current_time = time.time()
    if current_time - start_time >= print_interval:
        elapsed_time = current_time - start_time
        processing_speed = processed_files_count / elapsed_time if elapsed_time > 0 else 0
        print(f"Processed {processed_files_count} files in {elapsed_time:.2f} seconds ({processing_speed:.2f} files/second)")
        start_time = current_time
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Clears import errors for files that no longer exist.

        :param session: session for ORM operations
        :type session: sqlalchemy.orm.session.Session 
ChatGPT said:
def clear_import_errors_for_missing_files(session):
    """
    Clears import errors for files that no longer exist.

    :param session: session for ORM operations
    :type session: sqlalchemy.orm.session.Session
    """
    from sqlalchemy.orm import sessionmaker
    from your_project.models import FileImportError  # Replace with the correct model import

    # Query for import errors related to missing files
    import_errors = session.query(FileImportError).filter(FileImportError.file_exists == False).all()

    for error in import_errors:
        # Clear the import error if the file doesn't exist anymore
        if not os.path.exists(error.file_path):  # Replace with actual logic to check file existence
            session.delete(error)
    
    session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Print out stats about how files are getting processed.

        :param known_file_paths: a list of file paths that may contain Airflow
            DAG definitions
        :type known_file_paths: list[unicode]
        :return: None 
ChatGPT said:
def print_file_processing_stats(known_file_paths):
    """
    Print out stats about how files are getting processed.

    :param known_file_paths: a list of file paths that may contain Airflow
        DAG definitions
    :type known_file_paths: list[unicode]
    :return: None
    """
    total_files = len(known_file_paths)
    processed_files = 0
    failed_files = 0

    for file_path in known_file_paths:
        try:
            # Assuming some logic to process the file
            process_file(file_path)
            processed_files += 1
        except Exception as e:
            failed_files += 1
            print(f"Failed to process {file_path}: {e}")

    print(f"Total files: {total_files}")
    print(f"Processed files: {processed_files}")
    print(f"Failed files: {failed_files}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

:param file_path: the path to the file that's being processed
        :type file_path: unicode
        :return: the PID of the process processing the given file or None if
            the specified file is not being processed
        :rtype: int 
ChatGPT said:
def get_file_processing_pid(file_path):
    """
    Returns the PID of the process processing the given file or None if the
    specified file is not being processed.

    :param file_path: the path to the file that's being processed
    :type file_path: unicode
    :return: the PID of the process processing the given file or None if
        the specified file is not being processed
    :rtype: int
    """
    # Assuming a dictionary or a database that tracks file processing and their corresponding PIDs
    file_processing_map = get_file_processing_map()  # Placeholder for actual map fetch logic

    return file_processing_map.get(file_path, None)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

:param file_path: the path to the file that's being processed
        :type file_path: unicode
        :return: the current runtime (in seconds) of the process that's
            processing the specified file or None if the file is not currently
            being processed 
ChatGPT said:
import os
import time

def get_file_processing_runtime(file_path):
    """
    Returns the current runtime (in seconds) of the process that's processing the specified file
    or None if the file is not currently being processed.

    :param file_path: the path to the file that's being processed
    :type file_path: unicode
    :return: the current runtime (in seconds) of the process that's
        processing the specified file or None if the file is not currently
        being processed
    :rtype: float or None
    """
    # Assuming a dictionary or some mechanism to track process start times
    file_process_map = get_file_process_map()  # Placeholder for actual map fetch logic
    
    start_time = file_process_map.get(file_path, None)
    
    if start_time:
        return time.time() - start_time
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

:param file_path: the path to the file that's being processed
        :type file_path: unicode
        :return: the start time of the process that's processing the
            specified file or None if the file is not currently being processed
        :rtype: datetime 
ChatGPT said:
from datetime import datetime

def get_file_processing_start_time(file_path):
    """
    Returns the start time of the process that's processing the specified file
    or None if the file is not currently being processed.

    :param file_path: the path to the file that's being processed
    :type file_path: unicode
    :return: the start time of the process that's processing the
        specified file or None if the file is not currently being processed
    :rtype: datetime or None
    """
    # Assuming a dictionary or some mechanism to track process start times
    file_process_map = get_file_process_map()  # Placeholder for actual map fetch logic
    
    start_time = file_process_map.get(file_path, None)
    
    if start_time:
        return datetime.fromtimestamp(start_time)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Update this with a new set of paths to DAG definition files.

        :param new_file_paths: list of paths to DAG definition files
        :type new_file_paths: list[unicode]
        :return: None 
ChatGPT said:
def update_dag_file_paths(new_file_paths):
    """
    Update the set of paths to DAG definition files.

    :param new_file_paths: list of paths to DAG definition files
    :type new_file_paths: list[unicode]
    :return: None
    """
    # Assuming there's a global or session variable holding the file paths
    global dag_file_paths  # Placeholder for actual global or session variable
    
    dag_file_paths = set(new_file_paths)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Sleeps until all the processors are done. 
ChatGPT said:
import time

def wait_for_processors_to_finish(processors):
    """
    Sleeps until all the processors are done.

    :param processors: List of processor objects that need to finish
    :type processors: list
    :return: None
    """
    while any(processor.is_alive() for processor in processors):
        time.sleep(1)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

This should be periodically called by the manager loop. This method will
        kick off new processes to process DAG definition files and read the
        results from the finished processors.

        :return: a list of SimpleDags that were produced by processors that
            have finished since the last time this was called
        :rtype: list[airflow.utils.dag_processing.SimpleDag] 
ChatGPT said:
def process_dag_files(manager, processors):
    """
    Periodically called by the manager loop to process DAG definition files and 
    read the results from the finished processors.

    :param manager: The manager that controls the loop and the processors.
    :type manager: object
    :param processors: List of processor objects responsible for processing DAG files.
    :type processors: list
    :return: A list of SimpleDags produced by processors that have finished since the last call.
    :rtype: list[airflow.utils.dag_processing.SimpleDag]
    """
    finished_dags = []

    # Check the processors that have finished and read their results
    for processor in processors:
        if not processor.is_alive():
            # Assuming processor has a `get_results` method to fetch the produced SimpleDag
            finished_dags.extend(processor.get_results())
            processor.cleanup()  # Optionally clean up the processor after it finishes

    return finished_dags
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Find zombie task instances, which are tasks haven't heartbeated for too long.
        :return: Zombie task instances in SimpleTaskInstance format. 
ChatGPT said:
def find_zombie_task_instances(session, max_heartbeat_interval):
    """
    Find zombie task instances, which are tasks that haven't heartbeated for too long.

    :param session: Database session to query the task instances.
    :type session: sqlalchemy.orm.session.Session
    :param max_heartbeat_interval: Maximum allowed heartbeat interval in seconds.
    :type max_heartbeat_interval: int
    :return: A list of zombie task instances in SimpleTaskInstance format.
    :rtype: list[airflow.utils.task_instance.SimpleTaskInstance]
    """
    from datetime import datetime, timedelta

    # Get the current time
    current_time = datetime.now()

    # Query task instances that haven't heartbeated for too long
    zombie_task_instances = session.query(TaskInstance).filter(
        TaskInstance.state == 'running',
        TaskInstance.heartbeat < current_time - timedelta(seconds=max_heartbeat_interval)
    ).all()

    # Convert to SimpleTaskInstance format (assuming a method exists for this)
    return [SimpleTaskInstance(task_instance) for task_instance in zombie_task_instances]
You said:
Please generate a Python function that does the following with only the code box and no example usage:

:return: whether all file paths have been processed max_runs times 
ChatGPT said:
def all_file_paths_processed(session, file_paths, max_runs):
    """
    Checks if all file paths have been processed max_runs times.

    :param session: Database session to query the processing status.
    :type session: sqlalchemy.orm.session.Session
    :param file_paths: List of file paths to check the processing status for.
    :type file_paths: list[str]
    :param max_runs: The number of times each file should have been processed.
    :type max_runs: int
    :return: True if all file paths have been processed max_runs times, False otherwise.
    :rtype: bool
    """
    from sqlalchemy.orm import aliased

    # Check if each file path has been processed max_runs times
    processed_counts = session.query(
        FileProcessing.file_path,
        func.count(FileProcessing.run_id).label('processed_count')
    ).filter(FileProcessing.file_path.in_(file_paths)) \
     .group_by(FileProcessing.file_path) \
     .all()

    # Check if all file paths meet the processing requirement
    return all(count >= max_runs for _, count in processed_counts)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Kill all child processes on exit since we don't want to leave
        them as orphaned. 
ChatGPT said:
import os
import signal
import sys
import atexit

def kill_child_processes_on_exit():
    """
    Registers a function to kill all child processes on exit to avoid leaving orphaned processes.
    """
    def terminate_children():
        # Get the PID of the current process
        parent_pid = os.getpid()

        # Walk through all processes and terminate children
        for pid in os.popen('pgrep -P {}'.format(parent_pid)).read().splitlines():
            try:
                os.kill(int(pid), signal.SIGTERM)
            except ProcessLookupError:
                pass  # Process might have already been terminated

    # Register the function to be called on normal exit
    atexit.register(terminate_children)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Opens a ssh connection to the remote host.

        :rtype: paramiko.client.SSHClient 
ChatGPT said:
import paramiko

def open_ssh_connection(hostname, port=22, username=None, password=None, key_filepath=None):
    """
    Opens an SSH connection to a remote host using the provided credentials.

    :param hostname: The hostname or IP address of the remote host
    :type hostname: str
    :param port: The port for the SSH connection, default is 22
    :type port: int
    :param username: The username for authentication
    :type username: str
    :param password: The password for authentication (optional)
    :type password: str
    :param key_filepath: The path to the private key file for authentication (optional)
    :type key_filepath: str
    :rtype: paramiko.client.SSHClient
    :return: The SSHClient object representing the connection
    """
    ssh = paramiko.SSHClient()
    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())  # Automatically add host key if missing
    
    if key_filepath:
        # Use private key for authentication
        ssh.connect(hostname, port=port, username=username, key_filename=key_filepath)
    else:
        # Use password-based authentication
        ssh.connect(hostname, port=port, username=username, password=password)
    
    return ssh
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a tunnel between two hosts. Like ssh -L <LOCAL_PORT>:host:<REMOTE_PORT>.

        :param remote_port: The remote port to create a tunnel to
        :type remote_port: int
        :param remote_host: The remote host to create a tunnel to (default localhost)
        :type remote_host: str
        :param local_port:  The local port to attach the tunnel to
        :type local_port: int

        :return: sshtunnel.SSHTunnelForwarder object 
ChatGPT said:
from sshtunnel import SSHTunnelForwarder

def create_ssh_tunnel(remote_host='localhost', remote_port=22, local_port=3306, ssh_host=None, ssh_user=None, ssh_key=None):
    """
    Creates an SSH tunnel between a local machine and a remote host, forwarding the specified remote port to a local port.

    :param remote_port: The remote port to create a tunnel to
    :type remote_port: int
    :param remote_host: The remote host to create a tunnel to (default localhost)
    :type remote_host: str
    :param local_port: The local port to attach the tunnel to
    :type local_port: int
    :param ssh_host: The SSH host for the connection (to forward the tunnel)
    :type ssh_host: str
    :param ssh_user: The SSH user for authentication
    :type ssh_user: str
    :param ssh_key: The private SSH key to use for authentication
    :type ssh_key: str

    :return: SSHTunnelForwarder object
    """
    tunnel = SSHTunnelForwarder(
        (ssh_host, 22),
        ssh_username=ssh_user,
        ssh_pkey=ssh_key,
        remote_bind_address=(remote_host, remote_port),
        local_bind_address=('0.0.0.0', local_port)
    )
    tunnel.start()
    return tunnel
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a transfer job that runs periodically.

        :param body: (Required) A request body, as described in
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/patch#request-body
        :type body: dict
        :return: transfer job.
            See:
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs#TransferJob
        :rtype: dict 
ChatGPT said:
from google.cloud import storage
from googleapiclient.discovery import build

def create_transfer_job(body):
    """
    Creates a transfer job that runs periodically.

    :param body: A request body, as described in
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/patch#request-body
    :type body: dict
    :return: Transfer job.
        See: https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs#TransferJob
    :rtype: dict
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Create the transfer job
    request = service.transferJobs().create(body=body)
    response = request.execute()

    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets the latest state of a long-running operation in Google Storage
        Transfer Service.

        :param job_name: (Required) Name of the job to be fetched
        :type job_name: str
        :param project_id: (Optional) the ID of the project that owns the Transfer
            Job. If set to None or missing, the default project_id from the GCP
            connection is used.
        :type project_id: str
        :return: Transfer Job
        :rtype: dict 
ChatGPT said:
from googleapiclient.discovery import build

def get_transfer_job_state(job_name, project_id=None):
    """
    Gets the latest state of a long-running operation in Google Storage
    Transfer Service.

    :param job_name: Name of the job to be fetched
    :type job_name: str
    :param project_id: the ID of the project that owns the Transfer Job.
        If set to None or missing, the default project_id from the GCP connection is used.
    :type project_id: str
    :return: Transfer Job
    :rtype: dict
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request
    if project_id:
        name = f'projects/{project_id}/transferJobs/{job_name}'
    else:
        name = f'projects/{project_id}/transferJobs/{job_name}'

    # Get the transfer job state
    request = service.transferJobs().get(name=name)
    response = request.execute()

    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Lists long-running operations in Google Storage Transfer
        Service that match the specified filter.

        :param filter: (Required) A request filter, as described in
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/list#body.QUERY_PARAMETERS.filter
        :type filter: dict
        :return: List of Transfer Jobs
        :rtype: list[dict] 
ChatGPT said:
from googleapiclient.discovery import build

def list_transfer_jobs(filter):
    """
    Lists long-running operations in Google Storage Transfer
    Service that match the specified filter.

    :param filter: A request filter, as described in
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/list#body.QUERY_PARAMETERS.filter
    :type filter: dict
    :return: List of Transfer Jobs
    :rtype: list[dict]
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request with the filter
    request = service.transferJobs().list(filter=filter)
    response = request.execute()

    # Return the list of transfer jobs
    return response.get('transferJobs', [])
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Updates a transfer job that runs periodically.

        :param job_name: (Required) Name of the job to be updated
        :type job_name: str
        :param body: A request body, as described in
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/patch#request-body
        :type body: dict
        :return: If successful, TransferJob.
        :rtype: dict 
ChatGPT said:
from googleapiclient.discovery import build

def update_transfer_job(job_name, body):
    """
    Updates a transfer job that runs periodically.

    :param job_name: Name of the job to be updated
    :type job_name: str
    :param body: A request body, as described in
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/patch#request-body
    :type body: dict
    :return: If successful, TransferJob.
    :rtype: dict
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request to update the transfer job
    request = service.transferJobs().patch(
        jobName=job_name,
        body=body
    )
    response = request.execute()

    # Return the updated transfer job
    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes a transfer job. This is a soft delete. After a transfer job is
        deleted, the job and all the transfer executions are subject to garbage
        collection. Transfer jobs become eligible for garbage collection
        30 days after soft delete.

        :param job_name: (Required) Name of the job to be deleted
        :type job_name: str
        :param project_id: (Optional) the ID of the project that owns the Transfer
            Job. If set to None or missing, the default project_id from the GCP
            connection is used.
        :type project_id: str
        :rtype: None 
ChatGPT said:
from googleapiclient.discovery import build

def delete_transfer_job(job_name, project_id=None):
    """
    Deletes a transfer job. This is a soft delete. After a transfer job is
    deleted, the job and all the transfer executions are subject to garbage
    collection. Transfer jobs become eligible for garbage collection
    30 days after soft delete.

    :param job_name: Name of the job to be deleted
    :type job_name: str
    :param project_id: (Optional) the ID of the project that owns the Transfer
        Job. If set to None or missing, the default project_id from the GCP
        connection is used.
    :type project_id: str
    :rtype: None
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request to delete the transfer job
    request = service.transferJobs().delete(jobName=job_name)
    
    # Execute the request
    request.execute()

    # No return as it is a deletion operation
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Cancels an transfer operation in Google Storage Transfer Service.

        :param operation_name: Name of the transfer operation.
        :type operation_name: str
        :rtype: None 
ChatGPT said:
from googleapiclient.discovery import build

def cancel_transfer_operation(operation_name):
    """
    Cancels a transfer operation in Google Storage Transfer Service.

    :param operation_name: Name of the transfer operation.
    :type operation_name: str
    :rtype: None
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request to cancel the transfer operation
    request = service.operations().cancel(name=operation_name)

    # Execute the request
    request.execute()

    # No return as it is a cancellation operation
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :return: transfer operation
            See:
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/Operation
        :rtype: dict 
ChatGPT said:
from googleapiclient.discovery import build

def get_transfer_operation(operation_name):
    """
    Gets a transfer operation in Google Storage Transfer Service.

    :param operation_name: (Required) Name of the transfer operation.
    :type operation_name: str
    :return: Transfer operation details.
        See: https://cloud.google.com/storage-transfer/docs/reference/rest/v1/Operation
    :rtype: dict
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request to get the transfer operation
    request = service.operations().get(name=operation_name)

    # Execute the request and return the response
    response = request.execute()
    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets an transfer operation in Google Storage Transfer Service.

        :param filter: (Required) A request filter, as described in
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/list#body.QUERY_PARAMETERS.filter
            With one additional improvement:

            * project_id is optional if you have a project id defined
              in the connection
              See: :ref:howto/connection:gcp

        :type filter: dict
        :return: transfer operation
        :rtype: list[dict] 
ChatGPT said:
from googleapiclient.discovery import build

def list_transfer_operations(filter, project_id=None):
    """
    Lists transfer operations in Google Storage Transfer Service based on the provided filter.

    :param filter: (Required) A request filter, as described in
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs/list#body.QUERY_PARAMETERS.filter
    :type filter: dict
    :param project_id: (Optional) the ID of the project that owns the Transfer Job. If set to None or missing,
        the default project_id from the GCP connection is used.
    :type project_id: str
    :return: List of transfer operations
    :rtype: list[dict]
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Check if project_id is provided, otherwise use the default from the connection
    if not project_id:
        # In a real-world scenario, you would pull this from your GCP connection configuration
        raise ValueError("Project ID is required if not defined in the connection")

    # Prepare the request to list transfer operations with the filter
    request = service.transferJobs().list(
        projectId=project_id,
        filter=filter
    )

    # Execute the request and return the response
    response = request.execute()
    return response.get('transferJobs', [])
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Pauses an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :rtype: None 
ChatGPT said:
from googleapiclient.discovery import build

def pause_transfer_operation(operation_name):
    """
    Pauses a transfer operation in Google Storage Transfer Service.

    :param operation_name: (Required) Name of the transfer operation.
    :type operation_name: str
    :rtype: None
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request to pause the transfer operation
    request = service.operations().pause(
        name=operation_name
    )

    # Execute the request to pause the operation
    request.execute()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Resumes an transfer operation in Google Storage Transfer Service.

        :param operation_name: (Required) Name of the transfer operation.
        :type operation_name: str
        :rtype: None 
ChatGPT said:
from googleapiclient.discovery import build

def resume_transfer_operation(operation_name):
    """
    Resumes a transfer operation in Google Storage Transfer Service.

    :param operation_name: (Required) Name of the transfer operation.
    :type operation_name: str
    :rtype: None
    """
    # Initialize the storage transfer client
    service = build('storagetransfer', 'v1')

    # Prepare the request to resume the transfer operation
    request = service.operations().resume(
        name=operation_name
    )

    # Execute the request to resume the operation
    request.execute()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Waits until the job reaches the expected state.

        :param job: Transfer job
            See:
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs#TransferJob
        :type job: dict
        :param expected_statuses: State that is expected
            See:
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferOperations#Status
        :type expected_statuses: set[str]
        :param timeout:
        :type timeout: time in which the operation must end in seconds
        :rtype: None 
ChatGPT said:
import time
from googleapiclient.discovery import build

def wait_for_transfer_job_status(job, expected_statuses, timeout):
    """
    Waits until the job reaches the expected state.

    :param job: Transfer job
        See:
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferJobs#TransferJob
    :type job: dict
    :param expected_statuses: State that is expected
        See:
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferOperations#Status
    :type expected_statuses: set[str]
    :param timeout: Time in which the operation must end in seconds
    :type timeout: int
    :rtype: None
    """
    service = build('storagetransfer', 'v1')

    start_time = time.time()
    while True:
        # Get the current status of the job
        request = service.transferJobs().get(
            jobName=job['name']
        )
        current_job = request.execute()

        # Check if the job is in the expected status
        if current_job['status'] in expected_statuses:
            break

        # Check if the timeout has been exceeded
        if time.time() - start_time > timeout:
            raise TimeoutError(f"Timeout reached while waiting for job to reach expected state.")

        # Wait for a short time before checking the status again
        time.sleep(5)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Checks whether the operation list has an operation with the
        expected status, then returns true
        If it encounters operations in FAILED or ABORTED state
        throw :class:airflow.exceptions.AirflowException.

        :param operations: (Required) List of transfer operations to check.
        :type operations: list[dict]
        :param expected_statuses: (Required) status that is expected
            See:
            https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferOperations#Status
        :type expected_statuses: set[str]
        :return: If there is an operation with the expected state
            in the operation list, returns true,
        :raises: airflow.exceptions.AirflowException If it encounters operations
            with a state in the list,
        :rtype: bool 
ChatGPT said:
from airflow.exceptions import AirflowException

def check_transfer_operations_status(operations, expected_statuses):
    """
    Checks whether the operation list has an operation with the
    expected status, then returns true.
    If it encounters operations in FAILED or ABORTED state,
    raises an AirflowException.

    :param operations: List of transfer operations to check.
    :type operations: list[dict]
    :param expected_statuses: Status that is expected
        See:
        https://cloud.google.com/storage-transfer/docs/reference/rest/v1/transferOperations#Status
    :type expected_statuses: set[str]
    :return: If there is an operation with the expected state in the operation list, returns true.
    :raises: airflow.exceptions.AirflowException If it encounters operations with a state in the list.
    :rtype: bool
    """
    for operation in operations:
        status = operation.get('status')

        if status in {'FAILED', 'ABORTED'}:
            raise AirflowException(f"Operation failed or aborted: {operation.get('name')}")

        if status in expected_statuses:
            return True

    return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns all task reschedules for the task instance and try number,
        in ascending order.

        :param task_instance: the task instance to find task reschedules for
        :type task_instance: airflow.models.TaskInstance 
ChatGPT said:
from airflow.models import TaskInstance

def get_task_reschedules(task_instance):
    """
    Returns all task reschedules for the task instance and try number,
    in ascending order.

    :param task_instance: the task instance to find task reschedules for
    :type task_instance: airflow.models.TaskInstance
    :return: list of task reschedules in ascending order
    :rtype: list[airflow.models.TaskInstance]
    """
    reschedules = TaskInstance.query.filter(
        TaskInstance.dag_id == task_instance.dag_id,
        TaskInstance.task_id == task_instance.task_id,
        TaskInstance.execution_date == task_instance.execution_date,
        TaskInstance.try_number > task_instance.try_number
    ).order_by(TaskInstance.try_number).all()
    
    return reschedules
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Kubernetes only supports lowercase alphanumeric characters and "-" and "." in
        the pod name
        However, there are special rules about how "-" and "." can be used so let's
        only keep
        alphanumeric chars  see here for detail:
        https://kubernetes.io/docs/concepts/overview/working-with-objects/names/

        :param string: The requested Pod name
        :return: `str Pod name stripped of any unsafe characters 
ChatGPT said:
import re

def sanitize_pod_name(string):
    """
    Sanitizes the pod name to comply with Kubernetes naming conventions.
    Kubernetes only supports lowercase alphanumeric characters and "-" and ".",
    but there are special rules about their usage. This function strips
    the pod name of any unsafe characters and ensures compliance.

    :param string: The requested Pod name
    :type string: str
    :return: Pod name stripped of any unsafe characters
    :rtype: str
    """
    sanitized_string = re.sub(r'[^a-z0-9.-]', '', string.lower())
    return sanitized_string
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Kubernetes pod names must be <= 253 chars and must pass the following regex for
        validation
        "^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$"

        :param safe_dag_id: a dag_id with only alphanumeric characters
        :param safe_task_id: a task_id with only alphanumeric characters
        :param random_uuid: a uuid
        :return: `str valid Pod name of appropriate length 
ChatGPT said:
import re
import uuid

def generate_kubernetes_pod_name(safe_dag_id, safe_task_id, random_uuid=None):
    """
    Generates a valid Kubernetes pod name using a sanitized DAG ID, task ID, and a random UUID.
    The pod name must comply with Kubernetes naming conventions and must be <= 253 characters.

    :param safe_dag_id: a DAG ID with only alphanumeric characters
    :param safe_task_id: a task ID with only alphanumeric characters
    :param random_uuid: a UUID (optional)
    :return: Valid Kubernetes pod name of appropriate length
    :rtype: str
    """
    if random_uuid is None:
        random_uuid = str(uuid.uuid4()).replace('-', '')

    base_pod_name = f"{safe_dag_id}-{safe_task_id}-{random_uuid}"

    # Truncate if the length exceeds Kubernetes' max length for pod names
    base_pod_name = base_pod_name[:253]

    # Ensure the name complies with the regex pattern
    if not re.match(r"^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$", base_pod_name):
        raise ValueError(f"Invalid pod name generated: {base_pod_name}")
    
    return base_pod_name
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Valid label values must be 63 characters or less and must be empty or begin and
        end with an alphanumeric character ([a-z0-9A-Z]) with dashes (-), underscores (_),
        dots (.), and alphanumerics between.

        If the label value is then greater than 63 chars once made safe, or differs in any
        way from the original value sent to this function, then we need to truncate to
        53chars, and append it with a unique hash. 
ChatGPT said:
import re
import hashlib

def generate_safe_label_value(label_value):
    """
    Validates and sanitizes label values for Kubernetes compatibility.
    If the label value is greater than 63 characters or does not match the 
    required format, truncate it to 53 characters and append a unique hash.

    :param label_value: The label value to be sanitized
    :type label_value: str
    :return: Safe label value
    :rtype: str
    """
    # Regex for valid label value format: alphanumeric, dashes, underscores, and dots
    valid_label_regex = re.compile(r'^[a-zA-Z0-9]([a-zA-Z0-9-_\.]*[a-zA-Z0-9])?$')

    # Make the label safe by replacing unsafe characters
    safe_label_value = re.sub(r'[^a-zA-Z0-9-_\.]', '-', label_value)

    # Check if the label is valid
    if not valid_label_regex.match(safe_label_value):
        raise ValueError(f"Invalid label value: {label_value}")

    # Check length of label value
    if len(safe_label_value) > 63:
        # If the value is too long, truncate to 53 characters and append a hash
        truncated_label = safe_label_value[:53]
        hash_value = hashlib.md5(safe_label_value.encode('utf-8')).hexdigest()[:10]
        safe_label_value = f"{truncated_label}-{hash_value}"

    return safe_label_value
You said:
Please generate a Python function that does the following with only the code box and no example usage:

If the airflow scheduler restarts with pending "Queued" tasks, the tasks may or
        may not
        have been launched Thus, on starting up the scheduler let's check every
        "Queued" task to
        see if it has been launched (ie: if there is a corresponding pod on kubernetes)

        If it has been launched then do nothing, otherwise reset the state to "None" so
        the task
        will be rescheduled

        This will not be necessary in a future version of airflow in which there is
        proper support
        for State.LAUNCHED 
ChatGPT said:
from airflow.models import TaskInstance
from airflow.utils.state import State
from kubernetes.client import CoreV1Api

def reset_queued_tasks_if_not_launched(session, kubernetes_api: CoreV1Api):
    """
    Checks every task in "Queued" state to see if it has been launched by checking 
    the corresponding Kubernetes pod. If the pod is not found, the task state is reset
    to "None" to allow for rescheduling.

    :param session: The current database session
    :param kubernetes_api: An instance of CoreV1Api to interact with Kubernetes API
    :return: None
    """
    # Query tasks that are in "Queued" state
    queued_tasks = session.query(TaskInstance).filter(TaskInstance.state == State.QUEUED).all()

    for task in queued_tasks:
        # Check if the task has been launched by checking for the corresponding pod in Kubernetes
        pod_name = f"{task.dag_id}-{task.task_id}-{task.execution_date.isoformat()}"
        pod = kubernetes_api.read_namespaced_pod(name=pod_name, namespace="default", _try_to_parse_response=False)

        if pod.status.phase != 'Running':  # If pod is not found or not running, reset task state to None
            task.state = State.NONE
            session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the number of slots open at the moment 
ChatGPT said:
def get_open_slots(slots_total, slots_used):
    """
    Returns the number of open slots by subtracting the number of used slots
    from the total available slots.

    :param slots_total: The total number of slots available
    :type slots_total: int
    :param slots_used: The number of slots that are currently in use
    :type slots_used: int
    :return: The number of open slots
    :rtype: int
    """
    return slots_total - slots_used
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Expands (potentially nested) env vars by repeatedly applying
    expandvars and expanduser until interpolation stops having
    any effect. 
ChatGPT said:
import os

def expand_env_vars(value):
    """
    Expands (potentially nested) env vars by repeatedly applying
    `expandvars` and `expanduser` until interpolation stops having any effect.

    :param value: The value to expand, potentially containing environment variables
    :type value: str
    :return: The expanded value with all environment variables and user directories resolved
    :rtype: str
    """
    previous_value = None
    while value != previous_value:
        previous_value = value
        value = os.path.expandvars(os.path.expanduser(value))
    return value

You said:
Please generate a Python function that does the following with only the code box and no example usage:

Runs command and returns stdout 
ChatGPT said:
import subprocess

def run_command(command):
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    return result.stdout
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Generates a configuration from the provided template + variables defined in
    current scope
    :param template: a config content templated with {{variables}} 
ChatGPT said:
def generate_config(template):
    from string import Template
    import inspect

    frame = inspect.currentframe().f_back
    variables = frame.f_locals
    return Template(template).safe_substitute(variables)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Remove an option if it exists in config from a file or
        default config. If both of config have the same option, this removes
        the option in both configs unless remove_default=False. 
ChatGPT said:
import configparser

def remove_option(config, default_config, section, option, remove_default=True):
    if config.has_option(section, option):
        config.remove_option(section, option)
    if remove_default and default_config.has_option(section, option):
        default_config.remove_option(section, option)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the section as a dict. Values are converted to int, float, bool
        as required.

        :param section: section from the config
        :rtype: dict 
ChatGPT said:
def get_typed_section(config, section):
    result = {}
    if not config.has_section(section):
        return result
    for key, value in config.items(section):
        if value.lower() in ('true', 'false'):
            result[key] = config.getboolean(section, key)
        else:
            try:
                result[key] = config.getint(section, key)
            except ValueError:
                try:
                    result[key] = config.getfloat(section, key)
                except ValueError:
                    result[key] = value
    return result
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns the current configuration as an OrderedDict of OrderedDicts.
        :param display_source: If False, the option value is returned. If True,
            a tuple of (option_value, source) is returned. Source is either
            'airflow.cfg', 'default', 'env var', or 'cmd'.
        :type display_source: bool
        :param display_sensitive: If True, the values of options set by env
            vars and bash commands will be displayed. If False, those options
            are shown as '< hidden >'
        :type display_sensitive: bool
        :param raw: Should the values be output as interpolated values, or the
            "raw" form that can be fed back in to ConfigParser
        :type raw: bool 
ChatGPT said:
from collections import OrderedDict

def get_current_config(config, sources, display_source=False, display_sensitive=False, raw=True):
    config_data = OrderedDict()
    for section in config.sections():
        section_data = OrderedDict()
        for option in config.options(section):
            value = config.get(section, option, raw=raw)
            source = sources.get((section, option), 'default')
            if not display_sensitive and source in ('env var', 'cmd'):
                value = '< hidden >'
            if display_source:
                section_data[option] = (value, source)
            else:
                section_data[option] = value
        config_data[section] = section_data
    return config_data
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Allocate IDs for incomplete keys.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/allocateIds

        :param partial_keys: a list of partial keys.
        :type partial_keys: list
        :return: a list of full keys.
        :rtype: list 
ChatGPT said:
from google.cloud import datastore

def allocate_ids(partial_keys):
    client = datastore.Client()
    return client.allocate_ids(partial_keys)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Begins a new transaction.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/beginTransaction

        :return: a transaction handle.
        :rtype: str 
ChatGPT said:
from google.cloud import datastore

def begin_transaction():
    client = datastore.Client()
    with client.transaction() as transaction:
        return transaction.id
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Commit a transaction, optionally creating, deleting or modifying some entities.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/commit

        :param body: the body of the commit request.
        :type body: dict
        :return: the response body of the commit request.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore

def commit_transaction(body):
    client = datastore.Client()
    return client._datastore_api.commit(
        project_id=client.project,
        mode=body.get("mode", "TRANSACTIONAL"),
        transaction=body.get("transaction"),
        mutations=body.get("mutations", [])
    )
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Lookup some entities by key.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/lookup

        :param keys: the keys to lookup.
        :type keys: list
        :param read_consistency: the read consistency to use. default, strong or eventual.
                                 Cannot be used with a transaction.
        :type read_consistency: str
        :param transaction: the transaction to use, if any.
        :type transaction: str
        :return: the response body of the lookup request.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore

def lookup_entities(keys, read_consistency=None, transaction=None):
    client = datastore.Client()
    read_options = {}
    if transaction:
        read_options['transaction'] = transaction
    elif read_consistency:
        read_options['read_consistency'] = read_consistency.upper()

    return client._datastore_api.lookup(
        project_id=client.project,
        read_options=read_options,
        keys=keys
    )
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Roll back a transaction.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/rollback

        :param transaction: the transaction to roll back.
        :type transaction: str 
ChatGPT said:
from google.cloud import datastore_v1

def rollback_transaction(transaction):
    client = datastore_v1.DatastoreClient()
    request = datastore_v1.RollbackRequest(
        project_id=client.project_path().split('/')[-1],
        transaction=transaction
    )
    return client.rollback(request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Run a query for entities.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/runQuery

        :param body: the body of the query request.
        :type body: dict
        :return: the batch of query results.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore

def run_query(body):
    client = datastore.Client()
    query = datastore.Query(**body)
    return client._datastore_api.run_query(
        project_id=client.project,
        query=query
    )
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets the latest state of a long-running operation.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/data/rest/v1/projects.operations/get

        :param name: the name of the operation resource.
        :type name: str
        :return: a resource operation instance.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore_v1

def get_operation_state(name):
    client = datastore_v1.DatastoreClient()
    request = datastore_v1.GetOperationRequest(name=name)
    return client.get_operation(request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes the long-running operation.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/data/rest/v1/projects.operations/delete

        :param name: the name of the operation resource.
        :type name: str
        :return: none if successful.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore_v1

def delete_operation(name):
    client = datastore_v1.DatastoreClient()
    request = datastore_v1.DeleteOperationRequest(name=name)
    client.delete_operation(request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Poll backup operation state until it's completed.

        :param name: the name of the operation resource
        :type name: str
        :param polling_interval_in_seconds: The number of seconds to wait before calling another request.
        :type polling_interval_in_seconds: int
        :return: a resource operation instance.
        :rtype: dict 
ChatGPT said:
import time
from google.cloud import datastore_v1

def poll_backup_operation(name, polling_interval_in_seconds=10):
    client = datastore_v1.DatastoreClient()
    while True:
        operation = client.get_operation(name)
        if operation.done:
            return operation
        time.sleep(polling_interval_in_seconds)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Export entities from Cloud Datastore to Cloud Storage for backup.

        .. note::
            Keep in mind that this requests the Admin API not the Data API.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/admin/rest/v1/projects/export

        :param bucket: The name of the Cloud Storage bucket.
        :type bucket: str
        :param namespace: The Cloud Storage namespace path.
        :type namespace: str
        :param entity_filter: Description of what data from the project is included in the export.
        :type entity_filter: dict
        :param labels: Client-assigned labels.
        :type labels: dict of str
        :return: a resource operation instance.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore_admin_v1

def export_entities(bucket, namespace, entity_filter=None, labels=None):
    client = datastore_admin_v1.DatastoreAdminClient()
    project_id = client.project
    output_uri_prefix = f"gs://{bucket}/{namespace}"

    request = datastore_admin_v1.ExportEntitiesRequest(
        project_id=project_id,
        output_uri_prefix=output_uri_prefix,
        entity_filter=entity_filter,
        labels=labels
    )

    return client.export_entities(request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Import a backup from Cloud Storage to Cloud Datastore.

        .. note::
            Keep in mind that this requests the Admin API not the Data API.

        .. seealso::
            https://cloud.google.com/datastore/docs/reference/admin/rest/v1/projects/import

        :param bucket: The name of the Cloud Storage bucket.
        :type bucket: str
        :param file: the metadata file written by the projects.export operation.
        :type file: str
        :param namespace: The Cloud Storage namespace path.
        :type namespace: str
        :param entity_filter: specify which kinds/namespaces are to be imported.
        :type entity_filter: dict
        :param labels: Client-assigned labels.
        :type labels: dict of str
        :return: a resource operation instance.
        :rtype: dict 
ChatGPT said:
from google.cloud import datastore_admin_v1

def import_entities(bucket, file, namespace, entity_filter=None, labels=None):
    client = datastore_admin_v1.DatastoreAdminClient()
    project_id = client.project
    input_url = f"gs://{bucket}/{namespace}/{file}"

    request = datastore_admin_v1.ImportEntitiesRequest(
        project_id=project_id,
        input_url=input_url,
        entity_filter=entity_filter,
        labels=labels
    )

    return client.import_entities(request)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Publish a message to a topic or an endpoint.

        :param target_arn: either a TopicArn or an EndpointArn
        :type target_arn: str
        :param message: the default message you want to send
        :param message: str 
ChatGPT said:
import boto3

def publish_message(target_arn, message):
    sns_client = boto3.client('sns')
    response = sns_client.publish(
        TargetArn=target_arn,
        Message=message
    )
    return response
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Fetch the hostname using the callable from the config or using
    socket.getfqdn as a fallback. 
ChatGPT said:
import socket

def get_hostname(config):
    return config.get('hostname', socket.getfqdn())
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Retrieves connection to Cloud Natural Language service.

        :return: Cloud Natural Language service object
        :rtype: google.cloud.language_v1.LanguageServiceClient 
ChatGPT said:
from google.cloud import language_v1

def get_natural_language_client():
    return language_v1.LanguageServiceClient()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Finds named entities in the text along with entity types,
        salience, mentions for each entity, and other properties.

        :param document: Input document.
            If a dict is provided, it must be of the same form as the protobuf message Document
        :type document: dict or class google.cloud.language_v1.types.Document
        :param encoding_type: The encoding type used by the API to calculate offsets.
        :type encoding_type: google.cloud.language_v1.types.EncodingType
        :param retry: A retry object used to retry requests. If None is specified, requests will not be
            retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            retry is specified, the timeout applies to each individual attempt.
        :type timeout: float
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: sequence[tuple[str, str]]]
        :rtype: google.cloud.language_v1.types.AnalyzeEntitiesResponse 
ChatGPT said:
from google.cloud import language_v1

def analyze_entities(document, encoding_type=language_v1.EncodingType.UTF8, retry=None, timeout=None, metadata=None):
    client = language_v1.LanguageServiceClient()
    request = {
        'document': document,
        'encoding_type': encoding_type
    }
    return client.analyze_entities(request=request, retry=retry, timeout=timeout, metadata=metadata)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

A convenience method that provides all the features that analyzeSentiment,
        analyzeEntities, and analyzeSyntax provide in one call.

        :param document: Input document.
            If a dict is provided, it must be of the same form as the protobuf message Document
        :type document: dict or google.cloud.language_v1.types.Document
        :param features: The enabled features.
            If a dict is provided, it must be of the same form as the protobuf message Features
        :type features: dict or google.cloud.language_v1.enums.Features
        :param encoding_type: The encoding type used by the API to calculate offsets.
        :type encoding_type: google.cloud.language_v1.types.EncodingType
        :param retry: A retry object used to retry requests. If None is specified, requests will not be
            retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            retry is specified, the timeout applies to each individual attempt.
        :type timeout: float
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: sequence[tuple[str, str]]]
        :rtype: google.cloud.language_v1.types.AnnotateTextResponse 
ChatGPT said:
from google.cloud import language_v1

def annotate_text(document, features, encoding_type=language_v1.EncodingType.UTF8, retry=None, timeout=None, metadata=None):
    client = language_v1.LanguageServiceClient()
    request = {
        'document': document,
        'features': features,
        'encoding_type': encoding_type
    }
    return client.annotate_text(request=request, retry=retry, timeout=timeout, metadata=metadata)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Classifies a document into categories.

        :param document: Input document.
            If a dict is provided, it must be of the same form as the protobuf message Document
        :type document: dict or class google.cloud.language_v1.types.Document
        :param retry: A retry object used to retry requests. If None is specified, requests will not be
            retried.
        :type retry: google.api_core.retry.Retry
        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if
            retry is specified, the timeout applies to each individual attempt.
        :type timeout: float
        :param metadata: Additional metadata that is provided to the method.
        :type metadata: sequence[tuple[str, str]]]
        :rtype: google.cloud.language_v1.types.AnalyzeEntitiesResponse 
ChatGPT said:
from google.cloud import language_v1

def classify_text(document, retry=None, timeout=None, metadata=None):
    client = language_v1.LanguageServiceClient()
    request = {
        'document': document
    }
    return client.classify_text(request=request, retry=retry, timeout=timeout, metadata=metadata)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return the task object identified by the given dag_id and task_id. 
ChatGPT said:
from airflow.models import DagBag

def get_task(dag_id, task_id):
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)
    if dag:
        return dag.get_task(task_id)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets template fields for specific operator class.

    :param fullname: Full path to operator class.
        For example: `airflow.contrib.operators.gcp_vision_operator.CloudVisionProductSetCreateOperator
    :return: List of template field
    :rtype: list[str] 
ChatGPT said:
from airflow.utils import get_operator_class

def get_template_fields_for_operator(fullname):
    operator_class = get_operator_class(fullname)
    if operator_class:
        return operator_class.template_fields
    return []
You said:
Please generate a Python function that does the following with only the code box and no example usage:

A role that allows you to include a list of template fields in the middle of the text. This is especially
    useful when writing guides describing how to use the operator.
    The result is a list of fields where each field is shorted in the literal block.

    Sample usage::

    :template-fields:airflow.contrib.operators.gcp_natural_language_operator.CloudLanguageAnalyzeSentimentOperator

    For further information look at:

    * [http://docutils.sourceforge.net/docs/howto/rst-roles.html](Creating reStructuredText Interpreted
      Text Roles) 
ChatGPT said:
from airflow.utils import get_operator_class

def get_template_fields_literal_block(fullname):
    operator_class = get_operator_class(fullname)
    if operator_class:
        fields = operator_class.template_fields
        return '\n'.join([f'``{field}``' for field in fields])
    return ''
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Properly close pooled database connections 
ChatGPT said:
import psycopg2
from psycopg2 import pool

def close_pooled_connections(connection_pool):
    connection_pool.closeall()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Ensures that certain subfolders of AIRFLOW_HOME are on the classpath 
ChatGPT said:
import os
import sys

def ensure_subfolders_on_classpath(subfolders):
    airflow_home = os.getenv('AIRFLOW_HOME', '/opt/airflow')
    for subfolder in subfolders:
        subfolder_path = os.path.join(airflow_home, subfolder)
        if os.path.isdir(subfolder_path) and subfolder_path not in sys.path:
            sys.path.append(subfolder_path)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets the returned Celery result from the Airflow task
        ID provided to the sensor, and returns True if the
        celery result has been finished execution.

        :param context: Airflow's execution context
        :type context: dict
        :return: True if task has been executed, otherwise False
        :rtype: bool 
ChatGPT said:
from airflow.utils.state import State

def check_celery_task_execution(context):
    task_instance = context['task_instance']
    task_id = task_instance.task_id
    celery_result = task_instance.xcom_pull(task_ids=task_id)
    
    if celery_result and celery_result.state == State.SUCCESS:
        return True
    return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return true if the ticket cache contains "conf" information as is found
    in ticket caches of Kerberos 1.8.1 or later. This is incompatible with the
    Sun Java Krb5LoginModule in Java6, so we need to take an action to work
    around it. 
ChatGPT said:
from kerberos import checkTicketCache

def has_conf_in_ticket_cache():
    ticket_cache = checkTicketCache()
    if 'conf' in ticket_cache:
        return True
    return False
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Transforms a SQLAlchemy model instance into a dictionary 
ChatGPT said:
def model_to_dict(instance):
    return {column.name: getattr(instance, column.name) for column in instance.__table__.columns}
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Yield successive chunks of a given size from a list of items 
ChatGPT said:
def chunked(iterable, chunk_size):
    for i in range(0, len(iterable), chunk_size):
        yield iterable[i:i + chunk_size]
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Reduce the given list of items by splitting it into chunks
    of the given size and passing each chunk through the reducer 
ChatGPT said:
def reduce_chunks(iterable, chunk_size, reducer):
    result = None
    for chunk in chunked(iterable, chunk_size):
        if result is None:
            result = chunk
        else:
            result = reducer(result, chunk)
    return result
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Given a number of tasks, builds a dependency chain.

    chain(task_1, task_2, task_3, task_4)

    is equivalent to

    task_1.set_downstream(task_2)
    task_2.set_downstream(task_3)
    task_3.set_downstream(task_4) 
ChatGPT said:
def chain(*tasks):
    for i in range(len(tasks) - 1):
        tasks[i].set_downstream(tasks[i + 1])
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a pretty ascii table from tuples

    If namedtuple are used, the table will have headers 
ChatGPT said:
from tabulate import tabulate

def pretty_ascii_table(data):
    if data and isinstance(data[0], tuple) and hasattr(data[0], '_fields'):
        headers = data[0]._fields
    else:
        headers = None
    
    return tabulate(data, headers=headers, tablefmt='grid')
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Tries really hard to terminate all children (including grandchildren). Will send
    sig (SIGTERM) to the process group of pid. If any process is alive after timeout
    a SIGKILL will be send.

    :param log: log handler
    :param pid: pid to kill
    :param sig: signal type
    :param timeout: how much time a process has to terminate 
ChatGPT said:
import os
import signal
import time
import psutil

def terminate_all_children(log, pid, sig=signal.SIGTERM, timeout=30):
    try:
        parent = psutil.Process(pid)
        parent.terminate()  # Send SIGTERM to the parent process
        log.info(f"Sent {sig} to process {pid} and its children.")
        
        # Wait for the process to terminate within the timeout
        end_time = time.time() + timeout
        while time.time() < end_time:
            if not parent.is_running():
                log.info(f"Process {pid} and its children terminated.")
                return
            time.sleep(1)
        
        # If still running after timeout, send SIGKILL
        parent.kill()
        log.warning(f"Sent SIGKILL to process {pid} and its children after timeout.")
    except psutil.NoSuchProcess:
        log.error(f"Process {pid} does not exist.")
    except Exception as e:
        log.error(f"Failed to terminate process {pid}: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Given task instance, try_number, filename_template, return the rendered log
    filename

    :param ti: task instance
    :param try_number: try_number of the task
    :param filename_template: filename template, which can be jinja template or
        python string template 
ChatGPT said:
from airflow.utils.template import render_template

def render_log_filename(ti, try_number, filename_template):
    try:
        rendered_filename = render_template(filename_template, ti=ti, try_number=try_number)
        return rendered_filename
    except Exception as e:
        raise ValueError(f"Failed to render log filename: {e}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return the task object identified by the given dag_id and task_id. 
ChatGPT said:
from airflow.models import DagBag

def get_task(dag_id, task_id):
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)
    if dag:
        return dag.get_task(task_id)
    return None
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Integrate plugins to the context 
ChatGPT said:
from airflow.plugins_manager import AirflowPlugin

def integrate_plugins_to_context(context):
    plugins = AirflowPlugin.load_plugins()
    for plugin in plugins:
        if hasattr(plugin, 'add_to_context'):
            plugin.add_to_context(context)
    return context
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a Google Cloud Dataproc service object. 
ChatGPT said:
from google.cloud import dataproc_v1

def get_dataproc_client():
    return dataproc_v1.ClusterControllerClient()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Awaits for Google Cloud Dataproc Operation to complete. 
ChatGPT said:
import time
from google.cloud import dataproc_v1

def await_dataproc_operation(operation_name):
    client = dataproc_v1.ClusterControllerClient()
    operation = client.get_operation(name=operation_name)

    while not operation.done():
        time.sleep(10)  # Wait for 10 seconds before checking again
        operation = client.get_operation(name=operation_name)

    if operation.error:
        raise Exception(f"Operation failed: {operation.error.message}")
    
    return operation.result()  # Return the result of the operation
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Coerces content or all values of content if it is a dict to a string. The
    function will throw if content contains non-string or non-numeric types.

    The reason why we have this function is because the `self.json field must be a
    dict with only string values. This is because `render_template will fail
    for numerical values. 
ChatGPT said:
def coerce_to_string(content):
    if isinstance(content, dict):
        for key, value in content.items():
            content[key] = coerce_to_string(value)
        return content
    elif isinstance(content, (str, int, float)):
        return str(content)
    else:
        raise ValueError("Content contains non-string or non-numeric types.")

You said:
Please generate a Python function that does the following with only the code box and no example usage:

Handles the Airflow + Databricks lifecycle logic for a Databricks operator

    :param operator: Databricks operator being handled
    :param context: Airflow context 
ChatGPT said:
def handle_databricks_operator_lifecycle(operator, context):
    """
    Handles the lifecycle logic for a Databricks operator in an Airflow DAG.

    :param operator: Databricks operator being handled
    :param context: Airflow context
    """
    from airflow.utils.state import State
    from airflow.exceptions import AirflowException

    ti = context.get('ti')
    dag_run = context.get('dag_run')
    log = operator.log

    try:
        log.info("Starting Databricks operator execution.")
        operator.pre_execute(context)
        result = operator.execute(context)
        operator.post_execute(context, result=result)

        ti.set_state(State.SUCCESS)
        log.info("Databricks operator executed successfully.")
    except Exception as e:
        ti.set_state(State.FAILED)
        log.error(f"Databricks operator execution failed: {e}", exc_info=True)
        raise AirflowException("Databricks operator lifecycle handling failed") from e
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Run an pig script using the pig cli

        >>> ph = PigCliHook()
        >>> result = ph.run_cli("ls /;")
        >>> ("hdfs://" in result)
        True 
ChatGPT said:
def run_pig_script_via_cli(script: str) -> str:
    """
    Runs a Pig script using the Pig CLI.

    :param script: Pig script to be executed as a string
    :return: Output of the Pig CLI command execution
    """
    from airflow.providers.apache.pig.hooks.pig import PigCliHook

    hook = PigCliHook()
    return hook.run_cli(script)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Fetch and return the state of the given celery task. The scope of this function is
    global so that it can be called by subprocesses in the pool.

    :param celery_task: a tuple of the Celery task key and the async Celery object used
        to fetch the task's state
    :type celery_task: tuple(str, celery.result.AsyncResult)
    :return: a tuple of the Celery task key and the Celery state of the task
    :rtype: tuple[str, str] 
ChatGPT said:
def fetch_celery_task_state(celery_task):
    """
    Fetch and return the state of the given Celery task.

    :param celery_task: a tuple of the Celery task key and the async Celery object used
        to fetch the task's state
    :type celery_task: tuple(str, celery.result.AsyncResult)
    :return: a tuple of the Celery task key and the Celery state of the task
    :rtype: tuple[str, str]
    """
    task_key, async_result = celery_task
    return task_key, async_result.state
You said:
Please generate a Python function that does the following with only the code box and no example usage:

How many Celery tasks should each worker process send.

        :return: Number of tasks that should be sent per process
        :rtype: int 
ChatGPT said:
def get_celery_tasks_per_process() -> int:
    """
    Determine how many Celery tasks should be sent per worker process.

    :return: Number of tasks that should be sent per process
    :rtype: int
    """
    from airflow.configuration import conf

    return conf.getint('celery', 'worker_tasks_per_child', fallback=1)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

How many Celery tasks should be sent to each worker process.

        :return: Number of tasks that should be used per process
        :rtype: int 
ChatGPT said:
def get_tasks_per_worker_process() -> int:
    """
    Get the number of Celery tasks that should be sent to each worker process.

    :return: Number of tasks that should be used per process
    :rtype: int
    """
    from airflow.configuration import conf

    return conf.getint('celery', 'tasks_per_worker_process', fallback=1)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Like a Python builtin dict object, setdefault returns the current value
        for a key, and if it isn't there, stores the default value and returns it.

        :param key: Dict key for this Variable
        :type key: str
        :param default: Default value to set and return if the variable
            isn't already in the DB
        :type default: Mixed
        :param deserialize_json: Store this as a JSON encoded value in the DB
            and un-encode it when retrieving a value
        :return: Mixed 
ChatGPT said:
def variable_setdefault(key, default=None, deserialize_json=False):
    """
    Like a Python builtin dict object, setdefault returns the current value
    for a key, and if it isn't there, stores the default value and returns it.

    :param key: Dict key for this Variable
    :type key: str
    :param default: Default value to set and return if the variable
        isn't already in the DB
    :type default: Mixed
    :param deserialize_json: Store this as a JSON encoded value in the DB
        and un-encode it when retrieving a value
    :return: Mixed
    """
    from airflow.models import Variable

    try:
        return Variable.get(key, deserialize_json=deserialize_json)
    except KeyError:
        Variable.set(key, default, serialize_json=deserialize_json)
        return default
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a Google MLEngine service object. 
ChatGPT said:
def get_google_ml_engine_service():
    """
    Returns a Google MLEngine service object.

    :return: Google MLEngine service object
    :rtype: googleapiclient.discovery.Resource
    """
    from googleapiclient.discovery import build

    return build('ml', 'v1')
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Launches a MLEngine job and wait for it to reach a terminal state.

        :param project_id: The Google Cloud project id within which MLEngine
            job will be launched.
        :type project_id: str

        :param job: MLEngine Job object that should be provided to the MLEngine
            API, such as: ::

                {
                  'jobId': 'my_job_id',
                  'trainingInput': {
                    'scaleTier': 'STANDARD_1',
                    ...
                  }
                }

        :type job: dict

        :param use_existing_job_fn: In case that a MLEngine job with the same
            job_id already exist, this method (if provided) will decide whether
            we should use this existing job, continue waiting for it to finish
            and returning the job object. It should accepts a MLEngine job
            object, and returns a boolean value indicating whether it is OK to
            reuse the existing job. If 'use_existing_job_fn' is not provided,
            we by default reuse the existing MLEngine job.
        :type use_existing_job_fn: function

        :return: The MLEngine job object if the job successfully reach a
            terminal state (which might be FAILED or CANCELLED state).
        :rtype: dict 
ChatGPT said:
def launch_and_wait_ml_engine_job(project_id, job, use_existing_job_fn=None):
    """
    Launches a MLEngine job and waits for it to reach a terminal state.

    :param project_id: The Google Cloud project id within which MLEngine
        job will be launched.
    :type project_id: str
    :param job: MLEngine Job object to be submitted.
    :type job: dict
    :param use_existing_job_fn: Optional function to decide if an existing job should be reused.
    :type use_existing_job_fn: function
    :return: The final MLEngine job object.
    :rtype: dict
    """
    import time
    from googleapiclient.errors import HttpError
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    job_id = job['jobId']
    job_name = f'projects/{project_id}/jobs/{job_id}'

    try:
        request = ml.projects().jobs().create(parent=f'projects/{project_id}', body=job)
        response = request.execute()
    except HttpError as e:
        if e.resp.status == 409:  # Job already exists
            existing_job = ml.projects().jobs().get(name=job_name).execute()
            if use_existing_job_fn is None or use_existing_job_fn(existing_job):
                response = existing_job
            else:
                raise
        else:
            raise

    # Poll the job status until it reaches a terminal state
    while True:
        job_status = ml.projects().jobs().get(name=job_name).execute()
        state = job_status.get('state')
        if state in ('SUCCEEDED', 'FAILED', 'CANCELLED'):
            return job_status
        time.sleep(10)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets a MLEngine job based on the job name.

        :return: MLEngine job object if succeed.
        :rtype: dict

        Raises:
            googleapiclient.errors.HttpError: if HTTP error is returned from server 
ChatGPT said:
def get_ml_engine_job(project_id, job_id):
    """
    Gets a MLEngine job based on the job name.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param job_id: The job ID of the MLEngine job.
    :type job_id: str
    :return: MLEngine job object if succeed.
    :rtype: dict
    :raises: googleapiclient.errors.HttpError
    """
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    job_name = f'projects/{project_id}/jobs/{job_id}'
    return ml.projects().jobs().get(name=job_name).execute()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Waits for the Job to reach a terminal state.

        This method will periodically check the job state until the job reach
        a terminal state.

        Raises:
            googleapiclient.errors.HttpError: if HTTP error is returned when getting
            the job 
ChatGPT said:
def wait_for_ml_engine_job_completion(project_id, job_id):
    """
    Waits for the MLEngine job to reach a terminal state.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param job_id: The job ID of the MLEngine job.
    :type job_id: str
    :raises: googleapiclient.errors.HttpError
    """
    import time
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    job_name = f'projects/{project_id}/jobs/{job_id}'

    while True:
        job = ml.projects().jobs().get(name=job_name).execute()
        state = job.get('state')
        if state in ('SUCCEEDED', 'FAILED', 'CANCELLED'):
            break
        time.sleep(10)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates the Version on Google Cloud ML Engine.

        Returns the operation if the version was created successfully and
        raises an error otherwise. 
ChatGPT said:
def create_ml_engine_version(project_id, model_id, version):
    """
    Creates the Version on Google Cloud ML Engine.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param model_id: The model ID in Google Cloud ML Engine.
    :type model_id: str
    :param version: The version configuration to be created.
    :type version: dict
    :return: The operation if the version was created successfully.
    :rtype: googleapiclient.discovery.Resource
    :raises: googleapiclient.errors.HttpError
    """
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    name = f'projects/{project_id}/models/{model_id}'

    request = ml.projects().models().versions().create(parent=name, body=version)
    return request.execute()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Sets a version to be the default. Blocks until finished. 
ChatGPT said:
def set_ml_engine_version_default(project_id, model_id, version_id):
    """
    Sets a version to be the default. Blocks until finished.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param model_id: The model ID in Google Cloud ML Engine.
    :type model_id: str
    :param version_id: The version ID to be set as default.
    :type version_id: str
    :raises: googleapiclient.errors.HttpError
    """
    import time
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    version_name = f'projects/{project_id}/models/{model_id}/versions/{version_id}'

    request = ml.projects().models().versions().setDefault(name=version_name)
    operation = request.execute()

    # Block until the operation is complete
    while not operation.get('done', False):
        time.sleep(5)
        operation = ml.projects().operations().get(name=operation['name']).execute()

    if 'error' in operation:
        raise Exception(f"Error setting version {version_id} as default: {operation['error']}")
    return operation
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Lists all available versions of a model. Blocks until finished. 
ChatGPT said:
def list_ml_engine_model_versions(project_id, model_id):
    """
    Lists all available versions of a model. Blocks until finished.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param model_id: The model ID in Google Cloud ML Engine.
    :type model_id: str
    :return: List of versions for the model.
    :rtype: list
    :raises: googleapiclient.errors.HttpError
    """
    import time
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    model_name = f'projects/{project_id}/models/{model_id}'

    request = ml.projects().models().versions().list(parent=model_name)
    response = request.execute()

    while not response.get('nextPageToken', None):
        time.sleep(5)
        response = ml.projects().models().versions().list(parent=model_name).execute()

    return response.get('versions', [])
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Deletes the given version of a model. Blocks until finished. 
ChatGPT said:
def delete_ml_engine_version(project_id, model_id, version_id):
    """
    Deletes the given version of a model. Blocks until finished.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param model_id: The model ID in Google Cloud ML Engine.
    :type model_id: str
    :param version_id: The version ID to be deleted.
    :type version_id: str
    :raises: googleapiclient.errors.HttpError
    """
    import time
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    version_name = f'projects/{project_id}/models/{model_id}/versions/{version_id}'

    request = ml.projects().models().versions().delete(name=version_name)
    operation = request.execute()

    # Block until the operation is complete
    while not operation.get('done', False):
        time.sleep(5)
        operation = ml.projects().operations().get(name=operation['name']).execute()

    if 'error' in operation:
        raise Exception(f"Error deleting version {version_id}: {operation['error']}")
    return operation
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Create a Model. Blocks until finished. 
ChatGPT said:
from pydantic import BaseModel
import time

class MyModel(BaseModel):
    field1: str
    field2: int
    field3: bool

def create_model_blocking(field1: str, field2: int, field3: bool):
    # Simulate a blocking operation (e.g., long-running task)
    time.sleep(5)  # This blocks for 5 seconds
    return MyModel(field1=field1, field2=field2, field3=field3)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Gets a Model. Blocks until finished. 
ChatGPT said:
def get_ml_engine_model(project_id, model_id):
    """
    Gets a Model. Blocks until finished.

    :param project_id: The Google Cloud project id.
    :type project_id: str
    :param model_id: The model ID in Google Cloud ML Engine.
    :type model_id: str
    :return: The model object.
    :rtype: dict
    :raises: googleapiclient.errors.HttpError
    """
    from googleapiclient.discovery import build

    ml = build('ml', 'v1')
    model_name = f'projects/{project_id}/models/{model_id}'

    request = ml.projects().models().get(name=model_name)
    return request.execute()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Executes command received and stores result state in queue.
        :param key: the key to identify the TI
        :type key: tuple(dag_id, task_id, execution_date)
        :param command: the command to execute
        :type command: str 
ChatGPT said:
def execute_command_and_store_result(key, command, queue):
    """
    Executes the command received and stores the result state in the queue.

    :param key: the key to identify the TI (tuple of dag_id, task_id, execution_date)
    :type key: tuple
    :param command: the command to execute
    :type command: str
    :param queue: the queue where the result state will be stored
    :type queue: Queue
    """
    import subprocess
    from datetime import datetime

    try:
        # Execute the command
        result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        output = result.stdout.decode('utf-8')
        error = result.stderr.decode('utf-8')

        # Determine the result state
        if result.returncode == 0:
            state = 'SUCCESS'
        else:
            state = f'FAILED: {error}'

    except Exception as e:
        output = ''
        state = f'FAILED: {str(e)}'

    # Store the result state in the queue
    queue.put({
        'key': key,
        'state': state,
        'output': output,
        'timestamp': datetime.utcnow().isoformat()
    })
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Write batch items to dynamodb table with provisioned throughout capacity. 
ChatGPT said:
def write_batch_to_dynamodb(table_name, items, dynamodb_client):
    """
    Write batch items to DynamoDB table with provisioned throughput capacity.

    :param table_name: The name of the DynamoDB table.
    :type table_name: str
    :param items: A list of items to write to the table.
    :type items: list
    :param dynamodb_client: The DynamoDB client instance.
    :type dynamodb_client: boto3.client
    """
    from boto3.dynamodb.conditions import Key
    import boto3

    with dynamodb_client.batch_writer(table_name=table_name) as batch:
        for item in items:
            batch.put_item(Item=item)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Integrate plugins to the context. 
ChatGPT said:
def integrate_plugins_to_context(context, plugins):
    """
    Integrates plugins into the provided context.

    :param context: The context to integrate plugins into.
    :type context: dict
    :param plugins: A list of plugin objects or functions to be added to the context.
    :type plugins: list
    """
    for plugin in plugins:
        if callable(plugin):
            context[plugin.__name__] = plugin
        else:
            context[type(plugin).__name__] = plugin
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new instance of the configured executor if none exists and returns it 
ChatGPT said:
def create_executor_if_none_exists(executor_config, existing_executor=None):
    """
    Creates a new instance of the configured executor if none exists and returns it.

    :param executor_config: Configuration for the executor.
    :type executor_config: dict
    :param existing_executor: Existing executor instance (if any).
    :type existing_executor: object or None
    :return: Executor instance.
    :rtype: object
    """
    if existing_executor is None:
        from airflow.executors import get_executor
        return get_executor(executor_config)
    return existing_executor
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Creates a new instance of the named executor.
    In case the executor name is not know in airflow,
    look for it in the plugins 
ChatGPT said:
def create_named_executor(executor_name, plugins=None):
    """
    Creates a new instance of the named executor.
    In case the executor name is not known in Airflow, looks for it in the plugins.

    :param executor_name: The name of the executor to create.
    :type executor_name: str
    :param plugins: Optional list of plugins to search for the executor.
    :type plugins: list or None
    :return: Executor instance.
    :rtype: object
    """
    from airflow.executors import get_executor

    try:
        # Try to get the executor from Airflow's built-in executors
        return get_executor({'executor': executor_name})
    except ValueError:
        if plugins:
            # Search for executor in plugins if not found in Airflow
            for plugin in plugins:
                if hasattr(plugin, 'executor') and plugin.executor == executor_name:
                    return plugin.executor()
        raise ValueError(f"Executor named '{executor_name}' not found in Airflow or plugins.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Handles error callbacks when using Segment with segment_debug_mode set to True 
ChatGPT said:
def handle_segment_error_callback(error, segment_debug_mode=False):
    """
    Handles error callbacks when using Segment with segment_debug_mode set to True.

    :param error: The error that occurred.
    :type error: Exception
    :param segment_debug_mode: Flag to indicate if debug mode is enabled.
    :type segment_debug_mode: bool
    """
    if segment_debug_mode:
        # Print detailed error information in debug mode
        import traceback
        print("Debug Mode: Segment Error Callback")
        print(f"Error: {str(error)}")
        traceback.print_exc()
    else:
        # Log a generic error message in non-debug mode
        print(f"An error occurred: {str(error)}")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Launches the pod synchronously and waits for completion.
        Args:
            pod (Pod):
            startup_timeout (int): Timeout for startup of the pod (if pod is pending for
             too long, considers task a failure 
ChatGPT said:
def launch_pod_synchronously(pod, startup_timeout=600):
    """
    Launches the pod synchronously and waits for completion.

    Args:
        pod (Pod): The pod to launch.
        startup_timeout (int): Timeout for startup of the pod (in seconds). If the pod
            is pending for too long, considers the task a failure.
    """
    import time
    from kubernetes.client import V1PodStatus

    # Launch the pod
    pod_creation = pod.create()

    start_time = time.time()
    while time.time() - start_time < startup_timeout:
        # Check the pod status
        pod_status = pod.get_status()

        if pod_status.phase == V1PodStatus.RUNNING:
            print("Pod is running.")
            return pod_status
        elif pod_status.phase in [V1PodStatus.FAILED, V1PodStatus.SUCCEEDED]:
            print(f"Pod completed with status: {pod_status.phase}")
            return pod_status
        
        # Wait before checking the status again
        time.sleep(5)

    # If we reach here, the pod didn't start in time
    raise TimeoutError(f"Pod did not start within {startup_timeout} seconds.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a mssql connection object 
ChatGPT said:
import pyodbc

def get_mssql_connection(server, database, username, password):
    """
    Returns a MSSQL connection object.

    :param server: The server address for the MSSQL database.
    :type server: str
    :param database: The name of the database to connect to.
    :type database: str
    :param username: The username for authentication.
    :type username: str
    :param password: The password for authentication.
    :type password: str
    :return: MSSQL connection object.
    :rtype: pyodbc.Connection
    """
    connection_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'
    return pyodbc.connect(connection_string)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Call the SparkSubmitHook to run the provided spark job 
ChatGPT said:
from airflow.providers.apache.spark.hooks.spark_submit import SparkSubmitHook

def run_spark_job(spark_conn_id, application, conf=None, jars=None, py_files=None, files=None, archives=None):
    """
    Call the SparkSubmitHook to run the provided Spark job.

    :param spark_conn_id: The connection ID to use for Spark.
    :type spark_conn_id: str
    :param application: The path to the Spark application (jar, python, etc.).
    :type application: str
    :param conf: Spark configuration options.
    :type conf: dict, optional
    :param jars: Additional jars to be passed to the Spark job.
    :type jars: str, optional
    :param py_files: Python files to be distributed with the Spark job.
    :type py_files: str, optional
    :param files: Additional files to be distributed with the Spark job.
    :type files: str, optional
    :param archives: Archives to be distributed with the Spark job.
    :type archives: str, optional
    :return: The result of the Spark job execution.
    :rtype: any
    """
    hook = SparkSubmitHook(
        spark_conn_id=spark_conn_id,
        application=application,
        conf=conf,
        jars=jars,
        py_files=py_files,
        files=files,
        archives=archives
    )
    return hook.submit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Trigger a new dag run for a Dag with an execution date of now unless
    specified in the data. 
ChatGPT said:
from airflow.models import DagRun
from datetime import datetime
from airflow.utils.dates import days_ago

def trigger_dag_run(dag, execution_date=None):
    """
    Trigger a new DAG run for a Dag with an execution date of now unless specified in the data.

    :param dag: The DAG object for which to trigger the run.
    :type dag: airflow.models.DAG
    :param execution_date: The execution date for the DAG run. Defaults to the current time if not provided.
    :type execution_date: datetime, optional
    :return: The triggered DagRun object.
    :rtype: airflow.models.DagRun
    """
    if execution_date is None:
        execution_date = datetime.now()

    dag_run = DagRun(
        dag_id=dag.dag_id,
        execution_date=execution_date,
        state='running'
    )
    
    dag_run.dag = dag
    dag_run.verify_integrity()
    dag_run.save()
    
    return dag_run
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Delete all DB records related to the specified Dag. 
ChatGPT said:
from airflow.models import DagRun, TaskInstance
from sqlalchemy.orm import Session

def delete_dag_records(dag_id, session: Session):
    """
    Delete all DB records related to the specified DAG.

    :param dag_id: The DAG ID for which to delete records.
    :type dag_id: str
    :param session: The SQLAlchemy session to perform the deletion.
    :type session: sqlalchemy.orm.Session
    """
    # Delete task instances related to the DAG
    session.query(TaskInstance).filter(TaskInstance.dag_id == dag_id).delete(synchronize_session='fetch')

    # Delete DAG runs related to the DAG
    session.query(DagRun).filter(DagRun.dag_id == dag_id).delete(synchronize_session='fetch')

    # Commit the changes to the database
    session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a list of Dag Runs for a specific DAG ID.
    :query param state: a query string parameter '?state=queued|running|success...'
    :param dag_id: String identifier of a DAG
    :return: List of DAG runs of a DAG with requested state,
    or all runs if the state is not specified 
ChatGPT said:
from airflow.models import DagRun
from sqlalchemy.orm import Session

def get_dag_runs(dag_id, state=None, session: Session):
    """
    Returns a list of Dag Runs for a specific DAG ID.

    :param dag_id: String identifier of a DAG.
    :type dag_id: str
    :param state: Optional state filter ('queued', 'running', 'success', etc.).
    :type state: str, optional
    :param session: The SQLAlchemy session to query the database.
    :type session: sqlalchemy.orm.Session
    :return: List of DAG runs of a DAG with requested state, or all runs if the state is not specified.
    :rtype: list
    """
    query = session.query(DagRun).filter(DagRun.dag_id == dag_id)

    if state:
        query = query.filter(DagRun.state == state)

    return query.all()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Return python code of a given dag_id. 
ChatGPT said:
from airflow.models import DagBag

def get_dag_python_code(dag_id):
    """
    Returns the Python code of a given DAG ID.

    :param dag_id: The DAG ID for which to return the Python code.
    :type dag_id: str
    :return: The Python code of the specified DAG.
    :rtype: str
    """
    dag_bag = DagBag()
    dag = dag_bag.get_dag(dag_id)

    if dag is None:
        raise ValueError(f"DAG with id {dag_id} not found.")

    # Return the Python code used to define the DAG
    with open(dag.fileloc, 'r') as file:
        return file.read()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a JSON with a task's public instance variables. 
ChatGPT said:
import json

def get_task_public_instance_variables(task):
    """
    Returns a JSON with a task's public instance variables.

    :param task: The task object for which to return public instance variables.
    :type task: airflow.models.BaseOperator
    :return: JSON string representing the task's public instance variables.
    :rtype: str
    """
    public_vars = {key: value for key, value in task.__dict__.items() if not key.startswith('_')}
    return json.dumps(public_vars)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

(Un)pauses a dag 
ChatGPT said:
from airflow.models import DagBag
from airflow.utils.state import State

def pause_or_unpause_dag(dag_id, pause=True):
    """
    (Un)pauses a DAG.

    :param dag_id: The DAG ID to (un)pause.
    :type dag_id: str
    :param pause: Whether to pause (True) or unpause (False) the DAG.
    :type pause: bool
    """
    dagbag = DagBag()
    dag = dagbag.get_dag(dag_id)

    if not dag:
        raise ValueError(f"DAG with id {dag_id} not found.")

    if pause:
        dag.set_dagrun_state(State.NONE)
    else:
        dag.set_dagrun_state(State.RUNNING)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a JSON with a task instance's public instance variables.
    The format for the exec_date is expected to be
    "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15". This will
    of course need to have been encoded for URL in the request. 
ChatGPT said:
import json
from datetime import datetime

def get_task_instance_public_variables(task_instance):
    """
    Returns a JSON with a task instance's public instance variables.

    :param task_instance: The task instance object for which to return public instance variables.
    :type task_instance: airflow.models.TaskInstance
    :return: JSON string representing the task instance's public instance variables.
    :rtype: str
    """
    public_vars = {key: value for key, value in task_instance.__dict__.items() if not key.startswith('_')}
    
    # Format execution date to the required format if it exists
    if 'execution_date' in public_vars:
        public_vars['execution_date'] = public_vars['execution_date'].strftime('%Y-%m-%dT%H:%M:%S')
    
    return json.dumps(public_vars)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Returns a JSON with a dag_run's public instance variables.
    The format for the exec_date is expected to be
    "YYYY-mm-DDTHH:MM:SS", for example: "2016-11-16T11:34:15". This will
    of course need to have been encoded for URL in the request. 
ChatGPT said:
import json

def get_dag_run_public_variables(dag_run):
    """
    Returns a JSON with a dag_run's public instance variables.

    :param dag_run: The DagRun object for which to return public instance variables.
    :type dag_run: airflow.models.DagRun
    :return: JSON string representing the dag_run's public instance variables.
    :rtype: str
    """
    public_vars = {key: value for key, value in dag_run.__dict__.items() if not key.startswith('_')}
    
    # Format execution date to the required format if it exists
    if 'execution_date' in public_vars:
        public_vars['execution_date'] = public_vars['execution_date'].strftime('%Y-%m-%dT%H:%M:%S')
    
    return json.dumps(public_vars)
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Get all pools. 
ChatGPT said:
from airflow.models import Pool

def get_all_pools(session):
    """
    Get all pools.

    :param session: The SQLAlchemy session to query the database.
    :type session: sqlalchemy.orm.Session
    :return: List of all pools.
    :rtype: list
    """
    return session.query(Pool).all()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Create a pool. 
ChatGPT said:
from airflow.models import Pool

def create_pool(pool_name, pool_slots, pool_description, session):
    """
    Create a new pool.

    :param pool_name: The name of the pool.
    :type pool_name: str
    :param pool_slots: The number of slots for the pool.
    :type pool_slots: int
    :param pool_description: The description of the pool.
    :type pool_description: str
    :param session: The SQLAlchemy session to add the new pool.
    :type session: sqlalchemy.orm.Session
    """
    new_pool = Pool(
        pool=pool_name,
        slots=pool_slots,
        description=pool_description
    )
    session.add(new_pool)
    session.commit()
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Delete pool. 
ChatGPT said:
from airflow.models import Pool

def delete_pool(pool_name, session):
    """
    Delete a pool by its name.

    :param pool_name: The name of the pool to delete.
    :type pool_name: str
    :param session: The SQLAlchemy session to perform the deletion.
    :type session: sqlalchemy.orm.Session
    """
    pool_to_delete = session.query(Pool).filter(Pool.pool == pool_name).first()
    
    if pool_to_delete:
        session.delete(pool_to_delete)
        session.commit()
    else:
        raise ValueError(f"Pool with name '{pool_name}' not found.")
You said:
Please generate a Python function that does the following with only the code box and no example usage:

Create a new container group

        :param resource_group: the name of the resource group
        :type resource_group: str
        :param name: the name of the container group
        :type name: str
        :param container_group: the properties of the container group
        :type container_group: azure.mgmt.containerinstance.models.ContainerGroup 
ChatGPT said:
from azure.mgmt.containerinstance import ContainerInstanceManagementClient
from azure.identity import DefaultAzureCredential

def create_container_group(resource_group, name, container_group):
    """
    Create a new container group.

    :param resource_group: the name of the resource group
    :type resource_group: str
    :param name: the name of the container group
    :type name: str
    :param container_group: the properties of the container group
    :type container_group: azure.mgmt.containerinstance.models.ContainerGroup
    """
    credential = DefaultAzureCredential()
    client = ContainerInstanceManagementClient(credential, "<subscription_id>")

    # Create the container group
    client.container_groups.begin_create_or_update(resource_group, name, container_group)